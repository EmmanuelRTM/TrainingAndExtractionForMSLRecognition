{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries' importation and installation "
      ],
      "metadata": {
        "id": "wnvbI5e53Dx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLpOpVyXLf-W",
        "outputId": "7f34984a-df61-4b72-c232-22b0d8b635c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.1 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe #Install MediaPipe\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "fmZp16tOkBGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries to support in the use of data, display graphs, etc.\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import mediapipe as mp\n",
        "import copy\n",
        "from natsort import natsorted\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import time\n",
        "import joblib #ensure it's joblib v1.2.0 if not please update \n",
        "from google.colab import drive #To mount Google drive\n",
        "from google.colab.patches import cv2_imshow #to allow cv2 to show images and frames\n",
        "\n",
        "#Import libraries from scikit-learn for static signs recognition\n",
        "import sklearn\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.utils import shuffle\n",
        "import sklearn.ensemble\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.metrics import plot_confusion_matrix \n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "#from sklearn.model_selection import model_selection\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "\n",
        "#Import libraries from Tenorflow for dynamic/continous signs recognition\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#Import libraries to use javascript to display webcam video\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import html\n"
      ],
      "metadata": {
        "id": "nxAQBte6nhRs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke1XFQk46Ow0"
      },
      "source": [
        "# Setup Mediapipe Funcs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Z5TP4pps6Ow1"
      },
      "outputs": [],
      "source": [
        "##Folllowing code was adapted from Renotte, N. (2020). ActionDetectionforSignLanguage. GitHub. https://github.com/nicknochnack/ActionDetectionforSignLanguage\n",
        "#Also, Mediapipe documentation was used for support: https://github.com/google/mediapipe/blob/master/docs/solutions/holistic.md\n",
        "\n",
        "mp_holistic = mp.solutions.holistic # Holistic model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f5UJG1I96Ow2"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable to Improve Perf.\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
        "    return image, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ai8gM2ix6Ow4"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    '''\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             ) \n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    '''\n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw right hand connections  \n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mirHMpsJ6Ow5"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "    #Extraction of pose landmarks coordiantes\n",
        "    #pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "\n",
        "    #Extraction of face landmarks coordiantes\n",
        "    #face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
        "\n",
        "    #Extraction of hands landmarks coordiantes\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    \n",
        "    #return np.concatenate([pose, face, lh, rh]) #this is the complete return\n",
        "    return np.concatenate([lh, rh]) # return of left and right hand landmarks coordinates only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO7LdKjF6Ow6"
      },
      "source": [
        "## Setup Folders for Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFrBscPcNNTh",
        "outputId": "0ac58421-eca8-46ed-e119-26643ccd4db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive within the folder that the database is located, in this case it was called \"Base de Datos\"\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysn4g-shCszG",
        "outputId": "b3dc58e9-ae61-48f5-a2b9-b9718ff3b1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edited_captures  images  key_points  raw_videos\n"
          ]
        }
      ],
      "source": [
        "#Verify its location and available existing folders\n",
        "!ls \"/content/drive/My Drive/Base de datos\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA7UY9dUYR3D"
      },
      "source": [
        "## Folder paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0iJtMbKFkYAV"
      },
      "outputs": [],
      "source": [
        "# Path for exported data, numpy arrays\n",
        "\n",
        "#DATA_PATH for MP Points\n",
        "DATA_PATH_MP_Video = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/MP_Data_videos') \n",
        "DATA_PATH_MP_Image = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/MP_Data_images') \n",
        "\n",
        "#DATA_PATH for keypoints (coordinates) for Medipipe Holistic Landmarks\n",
        "DATA_PATH_KEYP_Video = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos')\n",
        "DATA_PATH_KEYP_Image = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VIXCXaJMzeE"
      },
      "source": [
        "##Main variables for folders designation, feautures extraction and modeling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rFDqI0MxY-Fz"
      },
      "outputs": [],
      "source": [
        "#Declaration of variables to use for path declaration, folder detection, and for labeling\n",
        "number_of_cycles= np.array(['1','2','3','4','5'])\n",
        "\n",
        "side_hand= np.array(['Derecha','Izquierda'])\n",
        "\n",
        "dinamyc_alphabets =  np.array(['9',\n",
        "'10',\n",
        "'j',\n",
        "'k',\n",
        "'ll',\n",
        "'ñ',\n",
        "'q',\n",
        "'rr',\n",
        "'x',\n",
        "'z',])\n",
        "dinamyc_alphabets=sorted(dinamyc_alphabets)\n",
        "\n",
        "static_alphabets= np.array(['1',\n",
        "'2',\n",
        "'3',\n",
        "'4',\n",
        "'5',\n",
        "'6',\n",
        "'7',\n",
        "'8',\n",
        "'a',\n",
        "'b',\n",
        "'c',\n",
        "'d',\n",
        "'e',\n",
        "'f',\n",
        "'g',\n",
        "'h',\n",
        "'i',\n",
        "'l',\n",
        "'m',\n",
        "'n',\n",
        "'o',\n",
        "'p',\n",
        "'r',\n",
        "'s',\n",
        "'t',\n",
        "'u',\n",
        "'v',\n",
        "'w',\n",
        "'y',])\n",
        "static_alphabets=sorted(static_alphabets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main Folders Creation\n"
      ],
      "metadata": {
        "id": "e0IgSxpvoZFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3odCUAaEAH3o"
      },
      "outputs": [],
      "source": [
        "#The follwoing code support on folder creation for MP data points and keypoints, please exchange directory when neccesary according if it is startic (image) signs or dynamic/continous (video) signs\n",
        "\n",
        "# Created 110 DataPaths for images/video\n",
        "no_sequences= 1 # 1 is for image , 60 30 for video\n",
        "\n",
        "#exchange static_alphabet(s) for dinamyc_alphabets for video\n",
        "\n",
        "for static_alphabet in static_alphabets: \n",
        "    for sequence in range(no_sequences):\n",
        "        try: \n",
        "          \n",
        "            new_directionwtf= os.path.join(DATA_PATH_MP_Image, static_alphabet, str(sequence))\n",
        "            os.makedirs(new_directionwtf)\n",
        "           #print(static_alphabet,\"   \" , new_directionwtf)\n",
        "        except:\n",
        "            #print(\"failed to create: \", static_alphabet, \"   \", sequence)\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es0mIBnoAH-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b4b945a-15c3-4062-97ee-72e3451a2ed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to create:  1     0\n",
            "failed to create:  2     0\n",
            "failed to create:  3     0\n",
            "failed to create:  4     0\n",
            "failed to create:  5     0\n",
            "failed to create:  6     0\n",
            "failed to create:  7     0\n",
            "failed to create:  8     0\n",
            "failed to create:  a     0\n",
            "failed to create:  b     0\n",
            "failed to create:  c     0\n",
            "failed to create:  d     0\n",
            "failed to create:  e     0\n",
            "failed to create:  f     0\n",
            "failed to create:  g     0\n",
            "failed to create:  h     0\n",
            "failed to create:  i     0\n",
            "failed to create:  l     0\n",
            "failed to create:  m     0\n",
            "failed to create:  n     0\n",
            "failed to create:  o     0\n",
            "failed to create:  p     0\n",
            "failed to create:  r     0\n",
            "failed to create:  s     0\n",
            "failed to create:  t     0\n",
            "failed to create:  u     0\n",
            "failed to create:  v     0\n",
            "failed to create:  w     0\n",
            "failed to create:  y     0\n"
          ]
        }
      ],
      "source": [
        "# Created 110 DataPaths for Keypoints of MP for images/video\n",
        "for static_alphabet in static_alphabets: \n",
        "    for sequence in range(no_sequences):\n",
        "        try: \n",
        "            os.makedirs(os.path.join(DATA_PATH_KEYP_Image, static_alphabet, str(sequence)))\n",
        "        except:\n",
        "          print(\"failed to create: \", static_alphabet, \"   \", sequence)\n",
        "          pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_sequences_video = 110 # number of videos per class\n",
        "\n",
        "sequence_length_video = 30 # number of frames to take intoa ccount per video\n",
        "\n",
        "sequence_length=30 # number of framesn(frames per one sec)\n"
      ],
      "metadata": {
        "id": "vnzHYr9E8kGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataPaths for Keypoints of videos\n",
        "for action in dinamyc_alphabets: \n",
        "    for sequence in range(no_sequences_video):\n",
        "        try: \n",
        "            os.makedirs(os.path.join(DATA_PATH_KEYP_Video, action, str(sequence)))\n",
        "        except:\n",
        "          print(\"error \", action , \" \", sequence)\n",
        "          pass"
      ],
      "metadata": {
        "id": "WAKhE2db7rl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataPaths for Videos\n",
        "for action in dinamyc_alphabets: \n",
        "    for sequence in range(no_sequences_video):\n",
        "        try: \n",
        "            os.makedirs(os.path.join(DATA_PATH_MP_Video, action, str(sequence)))\n",
        "        except:\n",
        "          print(\"error \", action , \" \", sequence)\n",
        "          pass"
      ],
      "metadata": {
        "id": "l9ocYaPp7sey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mediapipe Holistic Implementation"
      ],
      "metadata": {
        "id": "WI2PMl9wtEDd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hCT1uLOnnQz"
      },
      "source": [
        "##Extraction of landmarks for a person for static signs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#created list to save the directories that will generate an error if not saved properly\n",
        "bad_static_directories=[]"
      ],
      "metadata": {
        "id": "4Nd7gdBQvtWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF3B_p2xnrK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30050ed1-13e3-4682-da45-e985f8b7a91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        }
      ],
      "source": [
        "#### The following code is created to extract and save landmarks' coordinates for videos per persona\n",
        "\n",
        "#VIDEO_DATA_PATH=os.path.join(r'D:\\signara\\Signara-main\\Sign To Text\\utils\\video_data')\n",
        "#VIDEO_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha') \n",
        "#IMAGE_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_6/Imagenes') \n",
        "IMAGE_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_1') #Peronas 7, 8, 9 , 1_, 3<<<<<<<<\n",
        "\n",
        "\n",
        "#Every persona produces 10 signs of every class, in order to label them and save them, we label them and save them according to an order into folders, in this case sequence variable will help us with the order of the saved signs per persona\n",
        "#the current number '0' of the sample it begins at P4, C1, Derecha, every static sign and will go through to every cycle of that person in every hand\n",
        "#sequence=0 # Persona 4 is sample 0 t 9, therfore sequence = 0\n",
        "#sequence = 10 #for persona 5 from sample 10 to 19  \n",
        "#sequence = 20 # for persona 6 from 20 to 29\n",
        "#sequence = 30 # for persona 7 from 30 to 39\n",
        "#sequence = 40 # for persona 8 from 40 to 49\n",
        "#sequence = 50 # for persona 9 from 50 to 59 ** Ciclo 3_5 der e Izq\n",
        "#sequence = 60 # for persona 10 from 60 to 69\n",
        "#sequence = 70 # for persona 11 from 70 to 79\n",
        "#sequence = 80 # for persona 3 from 80 to 89 ***Muchas diferencias de los nombres de imagens\n",
        "#sequence = 90 # for persona 2 from 90 to 99 ***Muchas diferencias de los nombres de imagens\n",
        "sequence = 100 # for persona 1 from 100 to 109\n",
        "\n",
        "sequence_length=1 # number of frames, and if it's image is one only, opposite case 60 (frames per one sec)\n",
        "\n",
        "side_hand= np.array(['Derecha','Izquierda']) #For all the other Personas\n",
        "\n",
        "#side_hand=np.array(['Izquierda']) #to control errors per hand\n",
        "#i=1 #to control errors per cycle\n",
        "\n",
        "# Set mediapipe model \n",
        "\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "    \n",
        "    for i in number_of_cycles:\n",
        "\n",
        "      for j in side_hand:\n",
        "        #path to read the folder of each cycle\n",
        "        current_cycle_path= str('P1_Ciclo_') + str(i) + str('_5_')+str(j) #for persona 11, 1, 2, 5??\n",
        "        #current_cycle_path = str('Ciclo_') + str(i) + str('_5_')+str(j) #for persona 4 & 6, & others\n",
        "        #current_cycle_path = str('Ciclo_') + str(i) + str('_5_')+str('Derecha') #for persona 3\n",
        "\n",
        "        #path to rad the images\n",
        "        IMAGE_DATA_PATH_CURRENT_CYCLE = os.path.join(IMAGE_DATA_PATH, \"Imagenes\", current_cycle_path  ) # persona 11, 1, 2? probable\n",
        "        #IMAGE_DATA_PATH_CURRENT_CYCLE = os.path.join(IMAGE_DATA_PATH, current_cycle_path, \"Imagenes\" ) #for persona 7,8, 9 , 1_, 3, 5 <<<<<<<<\n",
        "        #to start the alphabet list for the naming\n",
        "        aux= 0\n",
        "\n",
        "         #for persona 7 & 8 & 9 & 1_ , 3<<<<\n",
        "\n",
        "        #if j == \"Izquierda\":\n",
        "         # current_cycle_path= str('Ciclo_') + str(i) + str('_5_')+str('Izq')\n",
        "\n",
        "\n",
        "        for k in static_alphabets:\n",
        "          #path to read  sign by sign\n",
        "          #CURRENT_STATIC_NAMED_ACTION = str('P1_')+str(current_cycle_path)+str('_')+str(k) # for persona may be 4 & 6\n",
        "          #CURRENT_STATIC_NAMED_ACTION = str('Ss_')+str(current_cycle_path)+str('_')+str(k) # for personas 7, 8, 9 , 1_, 3<<<<\n",
        "          CURRENT_STATIC_NAMED_ACTION = str(current_cycle_path)+str('_')+str(k)  #for persona 5, 11, 1, 2?\n",
        "          #CURRENT_STATIC_NAMED_ACTION = str('Ss_P3_')+str(current_cycle_path)+str('_')+str(k)  #for persona 3\n",
        "\n",
        "          #path to refer to a certain image of sign\n",
        "          jpg_path = os.path.join(IMAGE_DATA_PATH_CURRENT_CYCLE, CURRENT_STATIC_NAMED_ACTION + str('.jpg'))\n",
        "          #print(os.path.exists(jpg_path))\n",
        "\n",
        "          if not os.path.exists(jpg_path):\n",
        "            jpg_path = os.path.join(IMAGE_DATA_PATH_CURRENT_CYCLE, CURRENT_STATIC_NAMED_ACTION)\n",
        "\n",
        "          if not os.path.exists(jpg_path):\n",
        "            print(\"False  \", jpg_path)\n",
        "            bad_static_directories.append(jpg_path)\n",
        "\n",
        "          for frame_num in range(sequence_length):\n",
        "            \n",
        "            #print(CURRENT_STATIC_NAMED_ACTION)\n",
        "            #use of cv2 to read each image\n",
        "            if os.path.exists(jpg_path):\n",
        "              #print(jpg_path)\n",
        "              \n",
        "              frame = cv2.imread(jpg_path)\n",
        "\n",
        "              # Make detections\n",
        "              try:\n",
        "                #print(mp4_path)\n",
        "                image, results = mediapipe_detection(frame, holistic)\n",
        "              except:\n",
        "                pass;\n",
        "\n",
        "              #print(results)\n",
        "\n",
        "              # Draw landmarks\n",
        "              draw_styled_landmarks(image, results)\n",
        "\n",
        "              #Extract landmark\n",
        "              keypoints = extract_keypoints(results)\n",
        "\n",
        "              #Create path to save the landmark\n",
        "              npy_path = os.path.join(DATA_PATH_KEYP_Image, k, str(sequence), str(frame_num))\n",
        "              #print(npy_path,'\\n' )\n",
        "              #aux=aux+1\n",
        "\n",
        "              #Save the cooridnate of the landmarks\n",
        "              np.save(npy_path, keypoints)\n",
        "              \n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        sequence=sequence+1 # se incrementa el número de muestra\n",
        "\n",
        "#cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(sequence)\n",
        "#print(bad_directories)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Display which directories couldn't be saved\n",
        "bad_static_directories\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FVWyOS6_E3v",
        "outputId": "8723f9ff-98e9-41df-80bf-c748253b1a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test if a certain driectory was saved\n",
        "os.path.exists('/content/drive/My Drive/Base de datos/edited_captures/persona_3/Ciclo_1_5_Derecha/Imagenes/Ss_P3_Ciclo_1_5_Derecha_0.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgrEh9NbYI6X",
        "outputId": "90d22000-faad-4818-84fb-51db9cf40c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extraction of landmarks for a person for continous/dynamic signs\n"
      ],
      "metadata": {
        "id": "FZns7yqqjFd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#created list to save the directories that will generate an error if not saved properly\n",
        "bad_directories=[]"
      ],
      "metadata": {
        "id": "5UnNjQH4j6Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### The following code is created to extract and save landmarks' coordinates for videos per persona\n",
        "\n",
        "#IMAGE_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_6/Imagenes') \n",
        "VIDEO_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_4') #Persona can be changed\n",
        "\n",
        "#Every persona produces 10 signs of every class, in order to label them and save them, we label them and save them according to an order into folders, in this case sequence variable will help us with the order of the saved signs per persona\n",
        "#the current number '0' of the sample it begins at P4, C1, Derecha, every static sign and will go through to every cycle of that person in every hand\n",
        "sequence=0 # Persona 4 is sample 0 t 9, therfore sequence = 0\n",
        "#sequence = 10 #for persona 5 from sample 10 to 19  \n",
        "#sequence = 20 # for persona 6 from 20 to 29\n",
        "#sequence = 30 # for persona 7 from 30 to 39\n",
        "#sequence = 40 # for persona 8 from 40 to 49\n",
        "#sequence = 50 # for persona 9 from 50 to 59\n",
        "#sequence = 60 # for persona 10 from 60 to 69\n",
        "#sequence = 70 # for persona 11 from 70 to 79\n",
        "# sequence = 80 # for persona 3 from 80 to 89 ***Derechas are lacking with an underscore\n",
        "# sequence = 90 # for persona 2 from 90 to 99 ***Final left is lacking, (may change it with the last right hand)\n",
        "# sequence = 100 # for persona 1 from 100 to 109 ***lot of changes\n",
        "\n",
        "sequence_length=30 # number of framesn(frames per one sec)\n",
        "\n",
        "#side_hand= np.array(['derecha','izquierda']) #For Persona 1 only\n",
        "side_hand= np.array(['Derecha','Izquierda']) #For all the other Personas\n",
        "\n",
        "#side_hand=np.array(['Izquierda']) #to control errors per hand\n",
        "#i=1 #to control errors per cycle\n",
        "\n",
        "# Set mediapipe model \n",
        "\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "    \n",
        "    for i in number_of_cycles:\n",
        "\n",
        "      for j in side_hand:\n",
        "\n",
        "        #format to read every file and folder according to the person\n",
        "\n",
        "        #current_cycle_path= str('P5_Ciclo_') + str(i) + str('_5_')+str(j) #for persona 5\n",
        "        current_cycle_path= str('Ciclo_') + str(i) + str('_5_')+str(j) #for persona 4 & 6\n",
        "        #if j == 'Derecha':#for persona 3 only\n",
        "         # current_cycle_path= str('Ciclo ') + str(i) + str('_5_')+str(j)\n",
        "\n",
        "        #format to create/refer a path to save the file\n",
        "        VIDEO_DATA_PATH_CURRENT_CYCLE = os.path.join(VIDEO_DATA_PATH, current_cycle_path )\n",
        "\n",
        "        #for persona 7 & 8 & 9 & 10\n",
        "        #if j == \"Izquierda\":\n",
        "         # current_cycle_path= str('Ciclo_') + str(i) + str('_5_')+str('Izq')\n",
        "\n",
        "        for k in dinamyc_alphabets:\n",
        "\n",
        "          #Create the label of the action sign\n",
        "          CURRENT_DYNAMIC_NAMED_ACTION = str(current_cycle_path)+str('_')+str(k) \n",
        "          #print(CURRENT_DYNAMIC_NAMED_ACTION)\n",
        "\n",
        "          #named path to read of the sign\n",
        "          mp4_path = os.path.join(VIDEO_DATA_PATH_CURRENT_CYCLE, CURRENT_DYNAMIC_NAMED_ACTION + str('.mp4'))\n",
        "          #mp4_path = os.path.join(VIDEO_DATA_PATH_CURRENT_CYCLE, CURRENT_DYNAMIC_NAMED_ACTION) #persona 2\n",
        "          if not os.path.exists(mp4_path):\n",
        "            mp4_path = os.path.join(VIDEO_DATA_PATH_CURRENT_CYCLE, CURRENT_DYNAMIC_NAMED_ACTION)\n",
        "\n",
        "          if not os.path.exists(mp4_path):\n",
        "            print(\"False  \", mp4_path)\n",
        "            bad_directories.append(mp4_path)\n",
        "\n",
        "          #use of sv2 to read the video file\n",
        "          cap = cv2.VideoCapture(mp4_path)\n",
        "          ret, frame = cap.read()\n",
        "          \n",
        "            \n",
        "          for frame_num in range(sequence_length):\n",
        "\n",
        "            if os.path.exists(mp4_path):\n",
        "              # Make detections\n",
        "\n",
        "              try:\n",
        "                #print(mp4_path)\n",
        "\n",
        "                image, results = mediapipe_detection(frame, holistic)\n",
        "              except:\n",
        "                pass;\n",
        "\n",
        "              # Draw landmarks\n",
        "              draw_styled_landmarks(image, results)\n",
        "\n",
        "              #extracting the landmark's coordinates\n",
        "              keypoints = extract_keypoints(results)\n",
        "\n",
        "              #create the path to save the lanrmkaks' information sign\n",
        "              npy_path = os.path.join(DATA_PATH_KEYP_Video, k, str(sequence), str(frame_num))\n",
        "\n",
        "              #save the landmarks' coordinates\n",
        "              np.save(npy_path, keypoints)\n",
        "              \n",
        "\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        sequence=sequence+1 # se incrementa el número de muestra\n",
        "\n",
        "#cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print(sequence)\n",
        "#print(bad_directories)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "804fa94b-334f-43bb-d1f4-b4aaaed29109",
        "id": "uIyNEG4sxh3J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False   /content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_rr\n",
            "False   /content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_ñ\n",
            "2\n",
            "['/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_rr', '/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_ñ']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCiclo_1_5_Izquierda/Ciclo_1_5_Izquierda_j\\n\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_rr.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Derecha/Ciclo_1_5_Derecha_ñ.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_10.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_9.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_j.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_k.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_ll.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_q.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_rr.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_x.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_z.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_1_5_Izquierda/Ciclo_1_5_Izquierda_ñ.mp4\\n/content/drive/My Drive/Base de datos/edited_captures/persona_4/Ciclo_3_5_Derecha/Ciclo_3_5_Derecha_ll.mp4\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FyNkCZcngmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7ed3b2-5313-4f6e-e748-e963fdc05242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126\n"
          ]
        }
      ],
      "source": [
        "print(len(keypoints)) #42 landmarks with 3 axis each one (42*3=126)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(keypoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klTXpiN4EUSI",
        "outputId": "9e2ccc20-c7b2-4718-ba8a-3b3978546763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.94070435e-01  4.13339853e-01 -8.38843803e-08  5.94999194e-01\n",
            "  3.76171678e-01  1.53812836e-03  5.92286110e-01  3.42590868e-01\n",
            " -3.73215531e-04  5.91849625e-01  3.16970676e-01 -2.48383079e-03\n",
            "  5.97268701e-01  3.00049245e-01 -4.76585515e-03  5.81786275e-01\n",
            "  3.48388344e-01 -8.50967225e-03  5.65887511e-01  3.39698017e-01\n",
            " -9.91060771e-03  5.69664657e-01  3.48448187e-01 -9.20388103e-03\n",
            "  5.74931026e-01  3.52927357e-01 -9.02639702e-03  5.78238189e-01\n",
            "  3.65941435e-01 -1.07386457e-02  5.62737107e-01  3.59440476e-01\n",
            " -1.09916450e-02  5.66509426e-01  3.65137517e-01 -9.35348030e-03\n",
            "  5.72105467e-01  3.69115233e-01 -9.83733218e-03  5.74967682e-01\n",
            "  3.84008527e-01 -1.22411707e-02  5.61771750e-01  3.77052516e-01\n",
            " -1.19759571e-02  5.65371513e-01  3.81426454e-01 -1.01952134e-02\n",
            "  5.70839405e-01  3.84547204e-01 -1.08036920e-02  5.72680891e-01\n",
            "  4.01732057e-01 -1.34835150e-02  5.60062051e-01  3.99093330e-01\n",
            " -1.43416831e-02  5.52591383e-01  3.99173260e-01 -1.43665429e-02\n",
            "  5.46273768e-01  3.99710208e-01 -1.54060014e-02  4.69263971e-01\n",
            "  7.51380146e-01  1.02376099e-08  4.81959879e-01  7.49737859e-01\n",
            "  1.59874326e-03  4.93639171e-01  7.62367964e-01 -7.83833500e-04\n",
            "  5.02706170e-01  7.81733751e-01 -3.11271707e-03  5.07451057e-01\n",
            "  7.97725499e-01 -4.95254342e-03  4.92887080e-01  7.56350219e-01\n",
            " -1.18749030e-02  5.03859758e-01  7.88187265e-01 -1.44842723e-02\n",
            "  5.02503276e-01  8.00199986e-01 -1.24966558e-02  4.98892814e-01\n",
            "  8.01296115e-01 -1.03508662e-02  4.86546725e-01  7.67194211e-01\n",
            " -1.45025952e-02  4.98189092e-01  8.01540434e-01 -1.67586189e-02\n",
            "  4.95515704e-01  8.06105435e-01 -1.30951237e-02  4.91970330e-01\n",
            "  8.00706089e-01 -1.06374528e-02  4.79650050e-01  7.79358089e-01\n",
            " -1.62350088e-02  4.91322160e-01  8.10301185e-01 -1.68499034e-02\n",
            "  4.88272220e-01  8.10342908e-01 -1.14762951e-02  4.84625429e-01\n",
            "  8.03116083e-01 -8.28025769e-03  4.72944140e-01  7.90740371e-01\n",
            " -1.77798942e-02  4.82874662e-01  8.15493941e-01 -1.69319548e-02\n",
            "  4.81607854e-01  8.13664317e-01 -1.28462650e-02  4.78730381e-01\n",
            "  8.06657791e-01 -1.02836508e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_DATA_PATH = os.path.join(r'/content/drive/My Drive/Base de datos/edited_captures/persona_6/Imagenes') \n",
        "#test of a ceratin folder to verify if exists\n",
        "print(os.path.exists(os.path.join(IMAGE_DATA_PATH )))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOlewIcg6a48",
        "outputId": "da9b1ca2-24d9-4a96-b010-f30aa61b7e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4LBP4qDVCQm"
      },
      "source": [
        "#Data labeling for modeling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigment of the dactylology and the first ten numbers to a certain number label according if it is a static or continous/dynamic sign\n",
        "label_map_dynamic = {label:num for num, label in enumerate(dinamyc_alphabets)}\n",
        "label_map_static = {label:num for num, label in enumerate(static_alphabets)}"
      ],
      "metadata": {
        "id": "NkbppNeMEy_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map_dynamic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2cZ2wBuEzB2",
        "outputId": "262b60d9-64d5-4f6c-e9f2-400eb448c4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'10': 0,\n",
              " '9': 1,\n",
              " 'j': 2,\n",
              " 'k': 3,\n",
              " 'll': 4,\n",
              " 'q': 5,\n",
              " 'rr': 6,\n",
              " 'x': 7,\n",
              " 'z': 8,\n",
              " 'ñ': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map_static"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyK_6Sw-cuP6",
        "outputId": "08b98efd-57cb-4e33-e9f8-ce36068eeabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1': 0,\n",
              " '2': 1,\n",
              " '3': 2,\n",
              " '4': 3,\n",
              " '5': 4,\n",
              " '6': 5,\n",
              " '7': 6,\n",
              " '8': 7,\n",
              " 'a': 8,\n",
              " 'b': 9,\n",
              " 'c': 10,\n",
              " 'd': 11,\n",
              " 'e': 12,\n",
              " 'f': 13,\n",
              " 'g': 14,\n",
              " 'h': 15,\n",
              " 'i': 16,\n",
              " 'l': 17,\n",
              " 'm': 18,\n",
              " 'n': 19,\n",
              " 'o': 20,\n",
              " 'p': 21,\n",
              " 'r': 22,\n",
              " 's': 23,\n",
              " 't': 24,\n",
              " 'u': 25,\n",
              " 'v': 26,\n",
              " 'w': 27,\n",
              " 'y': 28}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Declare the paths to save the keypoints data in Google Drive "
      ],
      "metadata": {
        "id": "pCdoUJC7ij_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DYNAMIC_DATA = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/dynamic_data') \n",
        "STATIC_DATA = os.path.join(r'/content/drive/My Drive/Base de datos/key_points/static_data') \n"
      ],
      "metadata": {
        "id": "yFxR2El_Efwt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Check dynamic mistakes"
      ],
      "metadata": {
        "id": "PMqCUzG7icva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Lankdmark recopliation and Mistake detector dynamic/continous signs"
      ],
      "metadata": {
        "id": "mKR4XLFoUYyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The following code detects which files/sign were not saved accordingly for dynamic/continoous signs and recopilas all the saved landmarks\n",
        "bad_static_detections=[]\n",
        "sequence_length=30\n",
        "sequences, labels = [], []\n",
        "for action in dinamyc_alphabets:\n",
        "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH_KEYP_Video, action))).astype(int):\n",
        "        window = []\n",
        "        if not os.path.exists(os.path.join(DATA_PATH_KEYP_Video, action, str(sequence), \"{}.npy\".format('29'))):\n",
        "            bad_static_detections.append(os.path.join(DATA_PATH_KEYP_Video, action, str(sequence)))\n",
        "            print(\"FALSE   \", os.path.join(DATA_PATH_KEYP_Video, action, str(sequence)))\n",
        "            continue\n",
        "        for frame_num in range(sequence_length):\n",
        "\n",
        "            res = np.load(os.path.join(DATA_PATH_KEYP_Video, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
        "            window.append(res)\n",
        "        sequences.append(window)\n",
        "        labels.append(label_map_dynamic[action]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIJ7udwEzED",
        "outputId": "20f1cb79-a797-4e46-f9c2-51d01bff2298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/11\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/10/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/11\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/9/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/j/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/k/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/4\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/15\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/25\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/56\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/57\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/59\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/71\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/72\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/73\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/74\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/75\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/76\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/77\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/78\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/79\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ll/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/q/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/10\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/56\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/57\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/59\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/71\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/72\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/73\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/74\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/75\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/76\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/77\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/78\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/79\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/rr/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/x/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/z/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/30\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/31\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/32\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/65\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/88\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_videos/ñ/99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Save labels and data"
      ],
      "metadata": {
        "id": "_p_BdvkdUfdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code creates a path to save all the landmarks per sign in only one path\n",
        "npy_path_seq_dyn = os.path.join(DYNAMIC_DATA, 'sequences')\n",
        "np.save(npy_path_seq_dyn, sequences)\n",
        "\n",
        "npy_path_lab_dyn = os.path.join(DYNAMIC_DATA, 'labels')\n",
        "np.save(npy_path_lab_dyn, labels)"
      ],
      "metadata": {
        "id": "qLLHj5BlSaI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "be6107c4-5bd6-44ab-d83e-cc7317548fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-865511b46cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnpy_path_seq_dyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDYNAMIC_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sequences'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_path_seq_dyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnpy_path_lab_dyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDYNAMIC_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpy_path_lab_dyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load labels and data"
      ],
      "metadata": {
        "id": "qtwvf-QiUlBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code load landmarks information\n",
        "labels_dynamic = np.load(os.path.join(DYNAMIC_DATA,str('labels.npy')))\n",
        "sequences_dynamic = np.load(os.path.join(DYNAMIC_DATA,str('sequences.npy')))"
      ],
      "metadata": {
        "id": "F8cBBBmbamU_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test of a certain sign\n",
        "np.array(os.listdir(os.path.join(DATA_PATH_KEYP_Video, 'j'))).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vewZ9cIkfKzW",
        "outputId": "fe985253-2561-4231-cf15-70634bfce538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test if a certain path exist\n",
        "os.path.exists(os.path.join(DATA_PATH_KEYP_Video, 'j', str(\"1\"), \"{}.npy\".format('0')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB35naVTfeRZ",
        "outputId": "9751ac45-d9e7-47dc-c88f-ab52a7a02dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Check static mistakes"
      ],
      "metadata": {
        "id": "PyWj23xMizfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "####Lankdmark recopliation and Mistake detector static signs"
      ],
      "metadata": {
        "id": "sMSmJ0qlUuEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The following code checks which static file were not saved for static signs and recopilation of landmarks per sign \n",
        "sequence_length=1\n",
        "sequences, labels = [], []\n",
        "for action in static_alphabets:\n",
        "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH_KEYP_Image, action))).astype(int):\n",
        "        window = []\n",
        "        if not os.path.exists(os.path.join(DATA_PATH_KEYP_Image, action, str(sequence), \"{}.npy\".format('0'))):\n",
        "            bad_static_detections.append(os.path.join(DATA_PATH_KEYP_Image, action, str(sequence)))\n",
        "            print(\"FALSE   \", os.path.join(DATA_PATH_KEYP_Image, action, str(sequence)))\n",
        "            continue\n",
        "        for frame_num in range(sequence_length):\n",
        "            res = np.load(os.path.join(DATA_PATH_KEYP_Image, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
        "            window.append(res)\n",
        "        sequences.append(window)\n",
        "        labels.append(label_map_static[action])"
      ],
      "metadata": {
        "id": "i7sQdXLNdBnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8732b785-6155-4f57-ad3a-4e334faf1040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/1/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/2/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/3/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/4/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/5/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/6/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/7/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/13\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/17\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/8/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/a/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/b/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/c/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/d/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/e/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/f/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/g/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/h/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/i/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/l/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/m/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/n/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/o/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/p/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/r/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/s/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/t/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/41\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/u/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/v/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/w/99\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/54\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/55\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/80\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/82\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/84\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/86\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/89\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/90\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/91\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/92\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/93\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/94\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/95\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/96\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/97\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/98\n",
            "FALSE    /content/drive/My Drive/Base de datos/key_points/MP_Data_KEYPOINTS_images/y/99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Save labels and data"
      ],
      "metadata": {
        "id": "whOOsNzoqu14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code creates a path to save all the landmarks per sign in only one path\n",
        "\n",
        "npy_path_seq_stat = os.path.join(STATIC_DATA, 'sequences')\n",
        "np.save(npy_path_seq_stat, sequences)\n",
        "\n",
        "npy_path_lab_stat = os.path.join(STATIC_DATA, 'labels')\n",
        "np.save(npy_path_lab_stat, labels)"
      ],
      "metadata": {
        "id": "rOz3K6QdT5S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load labels and data"
      ],
      "metadata": {
        "id": "e00oR084U8R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code load landmarks information\n",
        "\n",
        "labels_static = np.load(os.path.join(STATIC_DATA,str('labels.npy')))\n",
        "sequences_static = np.load(os.path.join(STATIC_DATA,str('sequences.npy')))"
      ],
      "metadata": {
        "id": "YJmv7-a9T5XR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test to see if certain landmark exist\n",
        "os.path.exists(os.path.join(DATA_PATH_KEYP_Video, 'j', str(\"1\"), \"{}.npy\".format('0')))"
      ],
      "metadata": {
        "id": "N3s5Y4yzc7lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if npy files qere saved\n",
        "!ls \"/content/drive/My Drive/Base de datos/key_points/static_data\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXnM2bGfZRzn",
        "outputId": "7b7d62e5-d696-44ce-af9b-46936e1ea9c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels.npy  sequences.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Consult size of the labels and sequences accordingly"
      ],
      "metadata": {
        "id": "amSBuHmwq2BE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check the size of the saved landmarks coordinates for continous signs\n",
        "np.array(sequences_dynamic).shape\n",
        "#(size of the saved files, number of frames saved per file, number of landmarks saved per frame)"
      ],
      "metadata": {
        "id": "zYy8_gfhEzGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7434530d-89c9-42f5-982a-7f998f97b874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(981, 30, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(labels_dynamic).shape\n",
        "#(size of the saved files, )"
      ],
      "metadata": {
        "id": "iVhC9tYREzIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1ffcaf-bd3c-493a-b685-46ade8861689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(981,)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sequences_static).shape\n",
        "#(size of the saved files, number of frames saved per file (1 since it's only an image), number of landmarks saved per frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj6dcsekbjNF",
        "outputId": "4bef5e11-3772-4b72-e133-6d7b26f10863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2696, 1, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(labels_static).shape\n",
        "#(size of the saved files, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeKYPNjobjZS",
        "outputId": "bead0fb7-ab3c-4059-cd4e-80f2548bf3d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2696,)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the following lines checks the structure \n",
        "print(sequences_dynamic[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_JylTU6d46_",
        "outputId": "16bf7f26-a256-4bfa-f5a6-4fbc88f41f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 126)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences_dynamic[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrNzzB402de_",
        "outputId": "a7276fa2-e2c6-48aa-d6dc-e0806617d02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.30367076e-01  2.80238330e-01  6.87930992e-08  5.41301966e-01\n",
            "  2.51855999e-01  2.10945006e-03  5.44586718e-01  2.27309212e-01\n",
            "  1.38219516e-03  5.37563145e-01  2.14655980e-01  2.46940093e-04\n",
            "  5.28551936e-01  2.13348955e-01 -1.89202046e-03  5.37617385e-01\n",
            "  2.15380266e-01 -6.86892448e-03  5.37626028e-01  1.79678023e-01\n",
            " -1.14916218e-02  5.36823392e-01  1.57942683e-01 -1.41193252e-02\n",
            "  5.36041796e-01  1.39843166e-01 -1.57569665e-02  5.26404381e-01\n",
            "  2.15866759e-01 -1.00556947e-02  5.22453964e-01  1.75567195e-01\n",
            " -1.37624275e-02  5.19266427e-01  1.51388362e-01 -1.60670374e-02\n",
            "  5.16664028e-01  1.32525235e-01 -1.79594085e-02  5.16440928e-01\n",
            "  2.20673904e-01 -1.25353849e-02  5.11326969e-01  1.83875412e-01\n",
            " -1.53009864e-02  5.07957578e-01  1.60387427e-01 -1.78950671e-02\n",
            "  5.05515695e-01  1.41914159e-01 -2.00661924e-02  5.08624017e-01\n",
            "  2.28668123e-01 -1.45349344e-02  5.04231215e-01  2.01367155e-01\n",
            " -1.72148086e-02  5.02004564e-01  1.83788031e-01 -1.85837261e-02\n",
            "  5.00313699e-01  1.68434173e-01 -1.96291432e-02  4.36138928e-01\n",
            "  7.04032540e-01  1.10237245e-07  4.48067725e-01  7.05558002e-01\n",
            " -1.08379144e-02  4.57042187e-01  7.15839028e-01 -1.59088690e-02\n",
            "  4.64508116e-01  7.26835012e-01 -1.96059048e-02  4.70964789e-01\n",
            "  7.34878719e-01 -2.27389839e-02  4.49281752e-01  7.64037132e-01\n",
            " -8.16209055e-03  4.52459872e-01  7.89363742e-01 -1.33724902e-02\n",
            "  4.54957455e-01  8.08613777e-01 -1.80206876e-02  4.56761569e-01\n",
            "  8.23366642e-01 -2.08291542e-02  4.45794374e-01  7.71171808e-01\n",
            " -5.17841522e-03  4.50129092e-01  7.97726810e-01 -9.12953261e-03\n",
            "  4.54197139e-01  8.16176891e-01 -1.23402784e-02  4.56623495e-01\n",
            "  8.30023706e-01 -1.45728057e-02  4.44558263e-01  7.73513973e-01\n",
            " -3.40978126e-03  4.49063599e-01  7.96511233e-01 -6.73244614e-03\n",
            "  4.53213185e-01  8.13536644e-01 -8.11598077e-03  4.56283033e-01\n",
            "  8.27380240e-01 -8.59604031e-03  4.45299208e-01  7.72205234e-01\n",
            " -2.82771257e-03  4.49123293e-01  7.93415964e-01 -5.21303015e-03\n",
            "  4.52833652e-01  8.08341444e-01 -5.68305235e-03  4.56006944e-01\n",
            "  8.20714712e-01 -5.59697067e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels_dynamic[400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esUunAL1d5As",
        "outputId": "8c7d905a-79b5-4545-9748-44e29fca2635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checker of how many unique values does every label has accordingly"
      ],
      "metadata": {
        "id": "-CWfU32Cq83M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unique_, counts_ = np.unique(labels_dynamic, return_counts=True)\n",
        "\n",
        "#display unique values and counts of every continous sign\n",
        "print(np.asarray((unique_, counts_)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8cYashvfBtY",
        "outputId": "1f4e56bf-8bb0-4e10-cbba-6f7f601e0fd8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 100]\n",
            " [  1 100]\n",
            " [  2 102]\n",
            " [  3 102]\n",
            " [  4  86]\n",
            " [  5 101]\n",
            " [  6  88]\n",
            " [  7 101]\n",
            " [  8 101]\n",
            " [  9 100]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_s, counts_s = np.unique(labels_static, return_counts=True)\n",
        "\n",
        "#display unique values and counts of every static sign\n",
        "print(np.asarray((unique_s, counts_s)).T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANKqzVm-fV57",
        "outputId": "7f559cb4-0320-446c-cb6d-a661b2e92d38"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 92]\n",
            " [ 1 92]\n",
            " [ 2 92]\n",
            " [ 3 92]\n",
            " [ 4 92]\n",
            " [ 5 92]\n",
            " [ 6 92]\n",
            " [ 7 92]\n",
            " [ 8 94]\n",
            " [ 9 94]\n",
            " [10 94]\n",
            " [11 94]\n",
            " [12 94]\n",
            " [13 94]\n",
            " [14 94]\n",
            " [15 94]\n",
            " [16 93]\n",
            " [17 93]\n",
            " [18 93]\n",
            " [19 93]\n",
            " [20 93]\n",
            " [21 93]\n",
            " [22 93]\n",
            " [23 93]\n",
            " [24 93]\n",
            " [25 92]\n",
            " [26 93]\n",
            " [27 93]\n",
            " [28 93]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling"
      ],
      "metadata": {
        "id": "68GDNEcRjSFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load initial variable preparation for static signs modeling"
      ],
      "metadata": {
        "id": "0PFiw9osVyIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaration of variables and formating for static sign for modeling input\n",
        "X_static = np.array(sequences_static)\n",
        "y_static = labels_static\n",
        "rows, cols = (2696, 126)\n",
        "arr = [[0 for i in range(cols)] for j in range(rows)]\n",
        "for i in range(2696):\n",
        "  for j in range(126):\n",
        "    arr[i][j]=X_static[i][0][j]\n",
        "arr = np.array(arr)\n",
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyqoKuGS66bW",
        "outputId": "57971ef9-c73a-45de-f4c0-3acde692b0c6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2696, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#following lines check the size of each input for independent and dependent variables for static sign modeling\n",
        "y_static.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-p5BuCgVXQt",
        "outputId": "17c8aa90-30a6-4264-86d3-67559bfd2846"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2696,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1LvieG2T5lb",
        "outputId": "ad2daebf-1dc4-4889-88a9-e7a5df32bd39"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2696, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load initial variable preparation for continous signs modeling"
      ],
      "metadata": {
        "id": "hpMElm527gV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaration of variables and formating for dynamic/continous inputs for modeling\n",
        "\n",
        "X = np.array(sequences_dynamic) \n",
        "\n",
        "y = to_categorical(labels_dynamic).astype(int)\n",
        "\n",
        "y.shape"
      ],
      "metadata": {
        "id": "-9E5aZfwE-sB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2653c11-2c70-4f99-8dee-9679670f722b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(981, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data distribution according to the type of sign that is going to be trained"
      ],
      "metadata": {
        "id": "jpZnD_Y9rZmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables declaration of static signs for training , testing and validation staging\n",
        "X_train, X_test, y_train, y_test = train_test_split(arr, y_static, test_size=0.2, random_state=1) ###STATIC\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.5 x 0.2 = 0.1"
      ],
      "metadata": {
        "id": "MSUuQhQTPVP1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables declaration of continous signs for training , testing and validation staging\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) ###DYNAMIC\n",
        "\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1) # 0.5 x 0.2 = 0.1"
      ],
      "metadata": {
        "id": "cBvojBRjjNMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check size of variables assigned per stage\n",
        "y_train.shape"
      ],
      "metadata": {
        "id": "l9ferb1RFE3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17bd5af5-c403-402c-c16a-0e015b2a5794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2156,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mM9HbQs0jSc",
        "outputId": "2dbf120c-1f49-467f-ed42-281a90d8538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2156, 126)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG0zQ-0Cgx77",
        "outputId": "1f7c9b17-6be7-4e46-96c5-f80ed8f030af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensorboard path"
      ],
      "metadata": {
        "id": "1P0rMMgyFIxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/"
      ],
      "metadata": {
        "id": "ibhNbX75xIx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard"
      ],
      "metadata": {
        "id": "uzXYsTrjXAnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create path for logs for tensorboard\n",
        "\n",
        "log_dir = os.path.join(DYNAMIC_DATA,'Logs','fit')\n",
        "#tb_callback = TensorBoard(log_dir=log_dir)\n",
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "8X3KBn6LFLIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static Models settup and training\n"
      ],
      "metadata": {
        "id": "3FbYlOFp4WBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hist Gradient Boosting Classifier "
      ],
      "metadata": {
        "id": "AO1MNV0i3w4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create params' option for the HistGradientBoostingClassifier model in order to put into GridSearch\n",
        "params_grid={'loss':['categorical_crossentropy'], \n",
        "             'learning_rate':[ 0.09, 0.1, 0.11, 0.125, 0.15], \n",
        "             'max_iter':[100, 150, 200, 250, 300, 350],\n",
        "             }\n",
        "\n",
        "'''\n",
        "Other params that can be seen according to the documentation in scikit-learn:\n",
        "            'max_leaf_nodes':31, \n",
        "             'max_depth':None,\n",
        "             'min_samples_leaf':20,\n",
        "             'max_bins':255,\n",
        "             'categorical_features':None,\n",
        "             'monotonic_cst':None,\n",
        "             'interaction_cst':None,\n",
        "             'warm_start':False,\n",
        "             'early_stopping':'auto',\n",
        "             'scoring':'loss',\n",
        "             'validation_fraction':0.1,\n",
        "             'n_iter_no_change':10,\n",
        "             'tol':1e-07,\n",
        "             'verbose':0,\n",
        "             'random_state':None,\n",
        "             'class_weight':None\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "rUx_0A-u3309",
        "outputId": "7e0ffbe5-faed-46bf-ebbf-8d3aea7351d1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nOther params that can be seen according to the documentation in scikit-learn:\\n            'max_leaf_nodes':31, \\n             'max_depth':None,\\n             'min_samples_leaf':20,\\n             'max_bins':255,\\n             'categorical_features':None,\\n             'monotonic_cst':None,\\n             'interaction_cst':None,\\n             'warm_start':False,\\n             'early_stopping':'auto',\\n             'scoring':'loss',\\n             'validation_fraction':0.1,\\n             'n_iter_no_change':10,\\n             'tol':1e-07,\\n             'verbose':0,\\n             'random_state':None,\\n             'class_weight':None\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the model with grid search and train accordingly\n",
        "hist_GDB_model = GridSearchCV(HistGradientBoostingClassifier(), params_grid, refit=True, cv=3, n_jobs=-1)\n",
        "#train\n",
        "hist_GDB_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbrCt51x3vKs",
        "outputId": "ad726b88-8ada-430a-8f1b-65537aed7624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=HistGradientBoostingClassifier(), n_jobs=-1,\n",
              "             param_grid={'learning_rate': [0.09, 0.1, 0.11, 0.125, 0.15],\n",
              "                         'loss': ['categorical_crossentropy'],\n",
              "                         'max_iter': [100, 150, 200, 250, 300, 350]})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save best model\n",
        "final_model = hist_GDB_model.best_estimator_\n",
        "#predict\n",
        "y_pred = final_model.predict(X_test)"
      ],
      "metadata": {
        "id": "YepxFcU_3vX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show best params of the best model\n",
        "hist_GDB_model.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGM-Yc1LvIcH",
        "outputId": "845761fb-77b0-4a41-c0cb-4980e23e2977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.11, 'loss': 'categorical_crossentropy', 'max_iter': 250}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred\n",
        "#matrix of prediction display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73hCtY6huIGc",
        "outputId": "84212fdd-a3a9-4913-f188-08a0afa6af21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5,  9, 12,  6, 16,  5, 17, 13,  8,  7, 23,  2, 13,  0, 13,  0, 15,\n",
              "       17, 18,  0, 20,  8,  7, 22, 18, 25,  9,  1,  4, 10, 28, 21,  0, 20,\n",
              "       20, 27, 28,  5,  9,  6, 11, 25, 16, 19, 12, 20, 25, 19,  2, 15, 19,\n",
              "        8, 20, 22,  3, 13, 28, 13,  8,  2, 10,  5,  2,  2, 21, 14,  0, 18,\n",
              "        6, 12, 27, 21, 26, 16,  3,  4, 14, 24,  1,  8, 25, 20,  8, 14, 12,\n",
              "        6, 28,  2, 10,  2, 20, 20,  5, 24, 25, 11,  5,  2, 12, 21, 12, 28,\n",
              "       18, 21, 28, 19, 13, 18,  4, 19, 12, 28, 19, 20, 21,  1, 10, 24,  6,\n",
              "        0, 20, 23, 26,  1,  4, 14,  6, 24, 14,  8, 15, 12, 21, 28, 23, 10,\n",
              "        7, 12, 25, 27, 17, 16, 22, 22, 15, 15,  9, 13, 19, 25, 16,  2, 17,\n",
              "       11, 12, 18,  1,  3,  0, 23, 21, 28, 25,  6, 22,  4, 22,  7, 22, 21,\n",
              "        9, 24,  7, 13,  5, 22, 13,  3, 19, 11, 22, 18,  6,  8, 26,  8,  0,\n",
              "       11,  9, 27,  3, 22, 12,  5,  2, 18, 21, 16, 20,  6,  4,  6, 23, 27,\n",
              "       11,  5, 26, 18,  7,  9, 21, 28, 19, 25, 12, 27,  1, 13, 21, 19,  2,\n",
              "       12, 26, 20, 24, 15, 25, 25, 17, 12,  3,  1,  8, 18, 25,  2, 17, 24,\n",
              "       27, 13, 18,  2, 18, 17, 19, 27, 12, 10,  0,  5, 18,  7,  6, 12,  3,\n",
              "       25, 25, 17, 22,  4, 27,  5, 12, 13, 24,  7,  4, 17,  1, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM"
      ],
      "metadata": {
        "id": "lvq0dgX28umv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create params' option for the SVM model in order to put into GridSearch\n",
        "params_grid = { 'C':[0.1, 1, 10, 100, 800, 1000, 1200], \n",
        "'kernel':['rbf','linear', 'poly', 'sigmoid'], \n",
        "'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "}"
      ],
      "metadata": {
        "id": "o9sg126fzb2f"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the model with grid search and train accordingly\n",
        "svm_model = GridSearchCV(SVC(), params_grid, refit=True, cv=5, n_jobs=-1)\n",
        "#train the model\n",
        "svm_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vLw41joS_BN",
        "outputId": "0fe29f3b-3d2b-4e87-84ef-51c9042eb6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 800, 1000, 1200],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the the best score\n",
        "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
        "\n",
        "# View the best parameters for the model found using grid search\n",
        "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
        "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
        "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
        "\n",
        "final_model = svm_model.best_estimator_ #save best model into variable\n",
        "y_pred = final_model.predict(X_test)\n",
        "#Y_pred_label = list(encoder.inverse_transform(Y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaRgwxSNS_pQ",
        "outputId": "b6f2b20f-6b53-420c-8cfa-6b9e46653773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best score for training data: 0.9086330239752514 \n",
            "\n",
            "Best C: 1200 \n",
            "\n",
            "Best Kernel: poly \n",
            "\n",
            "Best Gamma: 0.1 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic/Continous Models settup and training"
      ],
      "metadata": {
        "id": "eBj4QIMh3vLk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LSTM"
      ],
      "metadata": {
        "id": "Gm_H-HUqa9Wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, activation='elu', input_shape=(30,126),kernel_initializer='he_normal' ))   #30, 1662\n",
        "model.add(LSTM(128, return_sequences=True, activation='elu',kernel_initializer='he_normal' ))\n",
        "model.add(LSTM(64, return_sequences=False, activation='elu',kernel_initializer='he_normal' ))\n",
        "model.add(Dense(64, activation='elu',kernel_initializer='he_normal' ))\n",
        "model.add(Dense(32, activation='elu',kernel_initializer='he_normal'))\n",
        "model.add(Dense(y_test.shape[1], activation='softmax', kernel_initializer='glorot_uniform', \n",
        "                kernel_regularizer='l2'))"
      ],
      "metadata": {
        "id": "qPlYvDiN_Zsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR LSTM's checkpoints of the model metrics  \n",
        "\n",
        "checkpoint_filepath = MODEL_PATH = os.path.join(DYNAMIC_DATA,'models', 'checkpoints_lstm')\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
        "                       tf.keras.metrics.Precision(name='precision') ,\n",
        "                       tf.keras.metrics.Recall(name='recall')\n",
        "          ]\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
        "              metrics= METRICS\n",
        "              )\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "53vyNARBZMkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779a0978-cdc7-458a-cf0d-9472cddfcdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 30, 64)            48896     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,690\n",
            "Trainable params: 203,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GRU"
      ],
      "metadata": {
        "id": "H6QhbZgnVc4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU Model WITH L2\n",
        "model = Sequential()\n",
        "\n",
        "model.add(GRU(128, return_sequences=True, activation='elu', input_shape=(30,126),kernel_initializer='he_normal' ))   #30, 1662\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='elu',kernel_initializer='he_normal' ))\n",
        "\n",
        "model.add(GRU(64, return_sequences=True, activation='elu',kernel_initializer='he_normal' ))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='elu',kernel_initializer='he_normal'  ))\n",
        "\n",
        "model.add(GRU(32, return_sequences=False, activation='elu',kernel_initializer='he_normal'  ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32, activation='elu',kernel_initializer='he_normal' ))\n",
        "\n",
        "model.add(Dense(10, activation='softmax', kernel_initializer='glorot_uniform', kernel_regularizer='l2'))\n"
      ],
      "metadata": {
        "id": "gHmyaJPXVcZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR GRU's checkpoints of the model metrics  \n",
        "METRICS = [tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
        "                       tf.keras.metrics.Precision(name='precision') ,\n",
        "                       tf.keras.metrics.Recall(name='recall')\n",
        "          ]\n",
        "          \n",
        "checkpoint_filepath = MODEL_PATH = os.path.join(DYNAMIC_DATA,'models', 'checkpoints_gru')\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.0001,  beta_1 = 0.9, beta_2 = 0.999 ), loss='categorical_crossentropy', metrics=METRICS)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kdKh3sdCFLMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbc2ae4-9e38-4f27-d3e4-1de3694e5dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 30, 128)           98304     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 128)           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 30, 64)            8256      \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 30, 64)            24960     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 30, 64)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 30, 64)            4160      \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 32)                9408      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32)               128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 146,602\n",
            "Trainable params: 146,538\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "Xfw6XDh92HtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Total of epochs to train the model\n",
        "EPOCHS = 1200 \n",
        "\n",
        "#Training settup\n",
        "model.fit(X_train, y_train, epochs=EPOCHS, callbacks=[tensorboard_callback, model_checkpoint_callback ] , validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "SXSYjYqiFLWF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba9a4fd9-0668-4de7-ddfa-84e8845f2d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 3.1005 - categorical_accuracy: 0.0804 - precision: 0.0122 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 9s 133ms/step - loss: 3.1005 - categorical_accuracy: 0.0804 - precision: 0.0122 - recall: 0.0013 - val_loss: 2.5329 - val_categorical_accuracy: 0.1224 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.7665 - categorical_accuracy: 0.1135 - precision: 0.1111 - recall: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.7665 - categorical_accuracy: 0.1135 - precision: 0.1111 - recall: 0.0026 - val_loss: 2.5057 - val_categorical_accuracy: 0.1429 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.6827 - categorical_accuracy: 0.1301 - precision: 0.0909 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.6827 - categorical_accuracy: 0.1301 - precision: 0.0909 - recall: 0.0013 - val_loss: 2.5059 - val_categorical_accuracy: 0.1735 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.6662 - categorical_accuracy: 0.0906 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 2.6662 - categorical_accuracy: 0.0906 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.5220 - val_categorical_accuracy: 0.1531 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5682 - categorical_accuracy: 0.1237 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 2.5682 - categorical_accuracy: 0.1237 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4670 - val_categorical_accuracy: 0.1429 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5561 - categorical_accuracy: 0.1301 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 2.5561 - categorical_accuracy: 0.1301 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4748 - val_categorical_accuracy: 0.1224 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5555 - categorical_accuracy: 0.1110 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.5555 - categorical_accuracy: 0.1110 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4773 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5349 - categorical_accuracy: 0.1301 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 2.5349 - categorical_accuracy: 0.1301 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.5058 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5030 - categorical_accuracy: 0.1288 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 2.5030 - categorical_accuracy: 0.1288 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4758 - val_categorical_accuracy: 0.1327 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5008 - categorical_accuracy: 0.1186 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.5008 - categorical_accuracy: 0.1186 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4858 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.5022 - categorical_accuracy: 0.1212 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 2.5022 - categorical_accuracy: 0.1212 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.5196 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4685 - categorical_accuracy: 0.1365 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.4685 - categorical_accuracy: 0.1365 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.5042 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4500 - categorical_accuracy: 0.1429 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.4500 - categorical_accuracy: 0.1429 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4771 - val_categorical_accuracy: 0.1122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4359 - categorical_accuracy: 0.1480 - precision: 1.0000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.4359 - categorical_accuracy: 0.1480 - precision: 1.0000 - recall: 0.0013 - val_loss: 2.4880 - val_categorical_accuracy: 0.1020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4163 - categorical_accuracy: 0.1633 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 2.4163 - categorical_accuracy: 0.1633 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4768 - val_categorical_accuracy: 0.0714 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4087 - categorical_accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.4087 - categorical_accuracy: 0.1696 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.4626 - val_categorical_accuracy: 0.1224 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.4010 - categorical_accuracy: 0.1696 - precision: 1.0000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 2.4010 - categorical_accuracy: 0.1696 - precision: 1.0000 - recall: 0.0013 - val_loss: 2.4694 - val_categorical_accuracy: 0.1224 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3686 - categorical_accuracy: 0.1811 - precision: 1.0000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 2.3686 - categorical_accuracy: 0.1811 - precision: 1.0000 - recall: 0.0013 - val_loss: 2.4737 - val_categorical_accuracy: 0.1020 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3628 - categorical_accuracy: 0.1798 - precision: 1.0000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.3628 - categorical_accuracy: 0.1798 - precision: 1.0000 - recall: 0.0013 - val_loss: 2.4386 - val_categorical_accuracy: 0.1224 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3619 - categorical_accuracy: 0.1811 - precision: 1.0000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 2.3619 - categorical_accuracy: 0.1811 - precision: 1.0000 - recall: 0.0013 - val_loss: 2.4207 - val_categorical_accuracy: 0.0918 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3028 - categorical_accuracy: 0.2194 - precision: 0.5000 - recall: 0.0013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.3028 - categorical_accuracy: 0.2194 - precision: 0.5000 - recall: 0.0013 - val_loss: 2.3642 - val_categorical_accuracy: 0.2143 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3196 - categorical_accuracy: 0.2105 - precision: 1.0000 - recall: 0.0026"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 2.3196 - categorical_accuracy: 0.2105 - precision: 1.0000 - recall: 0.0026 - val_loss: 2.3479 - val_categorical_accuracy: 0.1429 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2792 - categorical_accuracy: 0.2270 - precision: 0.8571 - recall: 0.0077"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 2.2792 - categorical_accuracy: 0.2270 - precision: 0.8571 - recall: 0.0077 - val_loss: 2.3328 - val_categorical_accuracy: 0.1633 - val_precision: 1.0000 - val_recall: 0.0102\n",
            "Epoch 24/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2709 - categorical_accuracy: 0.2500 - precision: 0.7143 - recall: 0.0064"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.2709 - categorical_accuracy: 0.2500 - precision: 0.7143 - recall: 0.0064 - val_loss: 2.2963 - val_categorical_accuracy: 0.2551 - val_precision: 1.0000 - val_recall: 0.0102\n",
            "Epoch 25/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2480 - categorical_accuracy: 0.2436 - precision: 0.8500 - recall: 0.0217"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 2.2480 - categorical_accuracy: 0.2436 - precision: 0.8500 - recall: 0.0217 - val_loss: 2.2594 - val_categorical_accuracy: 0.2551 - val_precision: 1.0000 - val_recall: 0.0102\n",
            "Epoch 26/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.2097 - categorical_accuracy: 0.2577 - precision: 0.7895 - recall: 0.0191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.2097 - categorical_accuracy: 0.2577 - precision: 0.7895 - recall: 0.0191 - val_loss: 2.2370 - val_categorical_accuracy: 0.2347 - val_precision: 1.0000 - val_recall: 0.0204\n",
            "Epoch 27/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1497 - categorical_accuracy: 0.2615 - precision: 0.9032 - recall: 0.0357"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.1497 - categorical_accuracy: 0.2615 - precision: 0.9032 - recall: 0.0357 - val_loss: 2.2489 - val_categorical_accuracy: 0.2347 - val_precision: 1.0000 - val_recall: 0.0102\n",
            "Epoch 28/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.1134 - categorical_accuracy: 0.2806 - precision: 0.8478 - recall: 0.0497"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.1134 - categorical_accuracy: 0.2806 - precision: 0.8478 - recall: 0.0497 - val_loss: 2.1228 - val_categorical_accuracy: 0.2959 - val_precision: 1.0000 - val_recall: 0.0306\n",
            "Epoch 29/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0923 - categorical_accuracy: 0.3048 - precision: 0.7600 - recall: 0.0485"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.0923 - categorical_accuracy: 0.3048 - precision: 0.7600 - recall: 0.0485 - val_loss: 2.0786 - val_categorical_accuracy: 0.3163 - val_precision: 1.0000 - val_recall: 0.0612\n",
            "Epoch 30/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0509 - categorical_accuracy: 0.3112 - precision: 0.8036 - recall: 0.0574"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 2.0509 - categorical_accuracy: 0.3112 - precision: 0.8036 - recall: 0.0574 - val_loss: 2.1461 - val_categorical_accuracy: 0.2449 - val_precision: 0.6364 - val_recall: 0.0714\n",
            "Epoch 31/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.0274 - categorical_accuracy: 0.3240 - precision: 0.8197 - recall: 0.0638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 2.0274 - categorical_accuracy: 0.3240 - precision: 0.8197 - recall: 0.0638 - val_loss: 2.1689 - val_categorical_accuracy: 0.2347 - val_precision: 0.4667 - val_recall: 0.0714\n",
            "Epoch 32/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9892 - categorical_accuracy: 0.3329 - precision: 0.7436 - recall: 0.0740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 1.9892 - categorical_accuracy: 0.3329 - precision: 0.7436 - recall: 0.0740 - val_loss: 2.0266 - val_categorical_accuracy: 0.3265 - val_precision: 0.7778 - val_recall: 0.0714\n",
            "Epoch 33/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9637 - categorical_accuracy: 0.3380 - precision: 0.8313 - recall: 0.0880"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 101ms/step - loss: 1.9637 - categorical_accuracy: 0.3380 - precision: 0.8313 - recall: 0.0880 - val_loss: 1.9865 - val_categorical_accuracy: 0.2653 - val_precision: 0.8750 - val_recall: 0.0714\n",
            "Epoch 34/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.9143 - categorical_accuracy: 0.3482 - precision: 0.8554 - recall: 0.0906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 168ms/step - loss: 1.9143 - categorical_accuracy: 0.3482 - precision: 0.8554 - recall: 0.0906 - val_loss: 2.3441 - val_categorical_accuracy: 0.2143 - val_precision: 0.2353 - val_recall: 0.0816\n",
            "Epoch 35/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8934 - categorical_accuracy: 0.3610 - precision: 0.8265 - recall: 0.1033"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 175ms/step - loss: 1.8934 - categorical_accuracy: 0.3610 - precision: 0.8265 - recall: 0.1033 - val_loss: 2.1534 - val_categorical_accuracy: 0.2347 - val_precision: 0.3636 - val_recall: 0.0816\n",
            "Epoch 36/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.8256 - categorical_accuracy: 0.3941 - precision: 0.8276 - recall: 0.1224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 109ms/step - loss: 1.8256 - categorical_accuracy: 0.3941 - precision: 0.8276 - recall: 0.1224 - val_loss: 1.9357 - val_categorical_accuracy: 0.3265 - val_precision: 0.7692 - val_recall: 0.1020\n",
            "Epoch 37/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7831 - categorical_accuracy: 0.4056 - precision: 0.8462 - recall: 0.1543"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 1.7831 - categorical_accuracy: 0.4056 - precision: 0.8462 - recall: 0.1543 - val_loss: 1.9750 - val_categorical_accuracy: 0.2857 - val_precision: 0.5294 - val_recall: 0.0918\n",
            "Epoch 38/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7799 - categorical_accuracy: 0.4069 - precision: 0.8477 - recall: 0.1633"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 1.7799 - categorical_accuracy: 0.4069 - precision: 0.8477 - recall: 0.1633 - val_loss: 1.7012 - val_categorical_accuracy: 0.4898 - val_precision: 0.9091 - val_recall: 0.1020\n",
            "Epoch 39/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.7286 - categorical_accuracy: 0.4196 - precision: 0.8035 - recall: 0.1773"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 1.7286 - categorical_accuracy: 0.4196 - precision: 0.8035 - recall: 0.1773 - val_loss: 1.7541 - val_categorical_accuracy: 0.4388 - val_precision: 0.9412 - val_recall: 0.1633\n",
            "Epoch 40/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6932 - categorical_accuracy: 0.4388 - precision: 0.8475 - recall: 0.1913"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 1.6932 - categorical_accuracy: 0.4388 - precision: 0.8475 - recall: 0.1913 - val_loss: 1.7426 - val_categorical_accuracy: 0.3878 - val_precision: 0.8182 - val_recall: 0.1837\n",
            "Epoch 41/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6555 - categorical_accuracy: 0.4515 - precision: 0.8316 - recall: 0.2015"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.6555 - categorical_accuracy: 0.4515 - precision: 0.8316 - recall: 0.2015 - val_loss: 1.7078 - val_categorical_accuracy: 0.4592 - val_precision: 0.8696 - val_recall: 0.2041\n",
            "Epoch 42/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.6351 - categorical_accuracy: 0.4758 - precision: 0.8624 - recall: 0.2079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.6351 - categorical_accuracy: 0.4758 - precision: 0.8624 - recall: 0.2079 - val_loss: 1.6616 - val_categorical_accuracy: 0.4184 - val_precision: 0.8696 - val_recall: 0.2041\n",
            "Epoch 43/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5991 - categorical_accuracy: 0.4809 - precision: 0.8439 - recall: 0.2207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 1.5991 - categorical_accuracy: 0.4809 - precision: 0.8439 - recall: 0.2207 - val_loss: 1.5943 - val_categorical_accuracy: 0.5102 - val_precision: 0.9091 - val_recall: 0.2041\n",
            "Epoch 44/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5987 - categorical_accuracy: 0.4707 - precision: 0.8281 - recall: 0.2028"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.5987 - categorical_accuracy: 0.4707 - precision: 0.8281 - recall: 0.2028 - val_loss: 1.6161 - val_categorical_accuracy: 0.4286 - val_precision: 0.7600 - val_recall: 0.1939\n",
            "Epoch 45/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5575 - categorical_accuracy: 0.4936 - precision: 0.8873 - recall: 0.2309"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.5575 - categorical_accuracy: 0.4936 - precision: 0.8873 - recall: 0.2309 - val_loss: 1.5436 - val_categorical_accuracy: 0.5000 - val_precision: 0.9167 - val_recall: 0.2245\n",
            "Epoch 46/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5398 - categorical_accuracy: 0.5000 - precision: 0.8571 - recall: 0.2296"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.5398 - categorical_accuracy: 0.5000 - precision: 0.8571 - recall: 0.2296 - val_loss: 1.6054 - val_categorical_accuracy: 0.4490 - val_precision: 0.7500 - val_recall: 0.2143\n",
            "Epoch 47/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5032 - categorical_accuracy: 0.5140 - precision: 0.8584 - recall: 0.2398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.5032 - categorical_accuracy: 0.5140 - precision: 0.8584 - recall: 0.2398 - val_loss: 1.4553 - val_categorical_accuracy: 0.5408 - val_precision: 0.9091 - val_recall: 0.2041\n",
            "Epoch 48/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.5020 - categorical_accuracy: 0.5102 - precision: 0.8734 - recall: 0.2551"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.5020 - categorical_accuracy: 0.5102 - precision: 0.8734 - recall: 0.2551 - val_loss: 1.7702 - val_categorical_accuracy: 0.4286 - val_precision: 0.5263 - val_recall: 0.2041\n",
            "Epoch 49/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4857 - categorical_accuracy: 0.5026 - precision: 0.8678 - recall: 0.2513"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.4857 - categorical_accuracy: 0.5026 - precision: 0.8678 - recall: 0.2513 - val_loss: 1.5823 - val_categorical_accuracy: 0.4796 - val_precision: 0.8077 - val_recall: 0.2143\n",
            "Epoch 50/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4548 - categorical_accuracy: 0.5332 - precision: 0.8595 - recall: 0.2653"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.4548 - categorical_accuracy: 0.5332 - precision: 0.8595 - recall: 0.2653 - val_loss: 1.4822 - val_categorical_accuracy: 0.5306 - val_precision: 0.9032 - val_recall: 0.2857\n",
            "Epoch 51/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4333 - categorical_accuracy: 0.5293 - precision: 0.8548 - recall: 0.2628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.4333 - categorical_accuracy: 0.5293 - precision: 0.8548 - recall: 0.2628 - val_loss: 1.5755 - val_categorical_accuracy: 0.4592 - val_precision: 0.8611 - val_recall: 0.3163\n",
            "Epoch 52/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4040 - categorical_accuracy: 0.5306 - precision: 0.8964 - recall: 0.2870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.4040 - categorical_accuracy: 0.5306 - precision: 0.8964 - recall: 0.2870 - val_loss: 1.4675 - val_categorical_accuracy: 0.5000 - val_precision: 0.9062 - val_recall: 0.2959\n",
            "Epoch 53/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.4076 - categorical_accuracy: 0.5472 - precision: 0.8571 - recall: 0.2832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.4076 - categorical_accuracy: 0.5472 - precision: 0.8571 - recall: 0.2832 - val_loss: 1.6690 - val_categorical_accuracy: 0.4184 - val_precision: 0.7941 - val_recall: 0.2755\n",
            "Epoch 54/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3793 - categorical_accuracy: 0.5472 - precision: 0.8225 - recall: 0.2895"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.3793 - categorical_accuracy: 0.5472 - precision: 0.8225 - recall: 0.2895 - val_loss: 1.4502 - val_categorical_accuracy: 0.5612 - val_precision: 0.9333 - val_recall: 0.2857\n",
            "Epoch 55/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3891 - categorical_accuracy: 0.5485 - precision: 0.8276 - recall: 0.3061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.3891 - categorical_accuracy: 0.5485 - precision: 0.8276 - recall: 0.3061 - val_loss: 1.3957 - val_categorical_accuracy: 0.5306 - val_precision: 0.8182 - val_recall: 0.2755\n",
            "Epoch 56/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3308 - categorical_accuracy: 0.5944 - precision: 0.8664 - recall: 0.3227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.3308 - categorical_accuracy: 0.5944 - precision: 0.8664 - recall: 0.3227 - val_loss: 1.3314 - val_categorical_accuracy: 0.5918 - val_precision: 0.8857 - val_recall: 0.3163\n",
            "Epoch 57/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3162 - categorical_accuracy: 0.5867 - precision: 0.8552 - recall: 0.3163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.3162 - categorical_accuracy: 0.5867 - precision: 0.8552 - recall: 0.3163 - val_loss: 1.4325 - val_categorical_accuracy: 0.4592 - val_precision: 0.8125 - val_recall: 0.2653\n",
            "Epoch 58/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2961 - categorical_accuracy: 0.5867 - precision: 0.8721 - recall: 0.3393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.2961 - categorical_accuracy: 0.5867 - precision: 0.8721 - recall: 0.3393 - val_loss: 1.4315 - val_categorical_accuracy: 0.5510 - val_precision: 0.7895 - val_recall: 0.3061\n",
            "Epoch 59/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.3056 - categorical_accuracy: 0.5931 - precision: 0.8426 - recall: 0.3278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.3056 - categorical_accuracy: 0.5931 - precision: 0.8426 - recall: 0.3278 - val_loss: 1.3726 - val_categorical_accuracy: 0.5306 - val_precision: 0.8085 - val_recall: 0.3878\n",
            "Epoch 60/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2738 - categorical_accuracy: 0.5727 - precision: 0.8466 - recall: 0.3380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.2738 - categorical_accuracy: 0.5727 - precision: 0.8466 - recall: 0.3380 - val_loss: 1.3620 - val_categorical_accuracy: 0.4796 - val_precision: 0.8571 - val_recall: 0.3673\n",
            "Epoch 61/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2661 - categorical_accuracy: 0.5995 - precision: 0.8242 - recall: 0.3469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.2661 - categorical_accuracy: 0.5995 - precision: 0.8242 - recall: 0.3469 - val_loss: 1.3630 - val_categorical_accuracy: 0.5612 - val_precision: 0.7500 - val_recall: 0.3061\n",
            "Epoch 62/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2807 - categorical_accuracy: 0.5778 - precision: 0.8182 - recall: 0.3559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.2807 - categorical_accuracy: 0.5778 - precision: 0.8182 - recall: 0.3559 - val_loss: 1.5268 - val_categorical_accuracy: 0.4592 - val_precision: 0.6522 - val_recall: 0.3061\n",
            "Epoch 63/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2663 - categorical_accuracy: 0.5969 - precision: 0.8338 - recall: 0.3648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.2663 - categorical_accuracy: 0.5969 - precision: 0.8338 - recall: 0.3648 - val_loss: 1.5158 - val_categorical_accuracy: 0.5306 - val_precision: 0.6905 - val_recall: 0.2959\n",
            "Epoch 64/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2464 - categorical_accuracy: 0.6148 - precision: 0.8473 - recall: 0.3610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.2464 - categorical_accuracy: 0.6148 - precision: 0.8473 - recall: 0.3610 - val_loss: 1.3100 - val_categorical_accuracy: 0.6224 - val_precision: 0.8718 - val_recall: 0.3469\n",
            "Epoch 65/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2008 - categorical_accuracy: 0.6161 - precision: 0.8453 - recall: 0.3903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 1.2008 - categorical_accuracy: 0.6161 - precision: 0.8453 - recall: 0.3903 - val_loss: 1.3374 - val_categorical_accuracy: 0.5816 - val_precision: 0.8000 - val_recall: 0.3673\n",
            "Epoch 66/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.2109 - categorical_accuracy: 0.6122 - precision: 0.8144 - recall: 0.3750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.2109 - categorical_accuracy: 0.6122 - precision: 0.8144 - recall: 0.3750 - val_loss: 1.2502 - val_categorical_accuracy: 0.5306 - val_precision: 0.8039 - val_recall: 0.4184\n",
            "Epoch 67/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1886 - categorical_accuracy: 0.6212 - precision: 0.8503 - recall: 0.3839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.1886 - categorical_accuracy: 0.6212 - precision: 0.8503 - recall: 0.3839 - val_loss: 1.3603 - val_categorical_accuracy: 0.4898 - val_precision: 0.8000 - val_recall: 0.4082\n",
            "Epoch 68/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1955 - categorical_accuracy: 0.6097 - precision: 0.7967 - recall: 0.3699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.1955 - categorical_accuracy: 0.6097 - precision: 0.7967 - recall: 0.3699 - val_loss: 1.2657 - val_categorical_accuracy: 0.5510 - val_precision: 0.8085 - val_recall: 0.3878\n",
            "Epoch 69/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1695 - categorical_accuracy: 0.6352 - precision: 0.8372 - recall: 0.4196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.1695 - categorical_accuracy: 0.6352 - precision: 0.8372 - recall: 0.4196 - val_loss: 1.2543 - val_categorical_accuracy: 0.5918 - val_precision: 0.8125 - val_recall: 0.3980\n",
            "Epoch 70/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1710 - categorical_accuracy: 0.6416 - precision: 0.8511 - recall: 0.4082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 1.1710 - categorical_accuracy: 0.6416 - precision: 0.8511 - recall: 0.4082 - val_loss: 1.1910 - val_categorical_accuracy: 0.5816 - val_precision: 0.8667 - val_recall: 0.3980\n",
            "Epoch 71/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1372 - categorical_accuracy: 0.6365 - precision: 0.8452 - recall: 0.4247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.1372 - categorical_accuracy: 0.6365 - precision: 0.8452 - recall: 0.4247 - val_loss: 1.1381 - val_categorical_accuracy: 0.6429 - val_precision: 0.9020 - val_recall: 0.4694\n",
            "Epoch 72/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1314 - categorical_accuracy: 0.6709 - precision: 0.8535 - recall: 0.4235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.1314 - categorical_accuracy: 0.6709 - precision: 0.8535 - recall: 0.4235 - val_loss: 1.1272 - val_categorical_accuracy: 0.6531 - val_precision: 0.8600 - val_recall: 0.4388\n",
            "Epoch 73/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1166 - categorical_accuracy: 0.6518 - precision: 0.8337 - recall: 0.4349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.1166 - categorical_accuracy: 0.6518 - precision: 0.8337 - recall: 0.4349 - val_loss: 1.1464 - val_categorical_accuracy: 0.6327 - val_precision: 0.8269 - val_recall: 0.4388\n",
            "Epoch 74/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1324 - categorical_accuracy: 0.6352 - precision: 0.8235 - recall: 0.4286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 1.1324 - categorical_accuracy: 0.6352 - precision: 0.8235 - recall: 0.4286 - val_loss: 1.3226 - val_categorical_accuracy: 0.5204 - val_precision: 0.6481 - val_recall: 0.3571\n",
            "Epoch 75/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.1057 - categorical_accuracy: 0.6658 - precision: 0.8432 - recall: 0.4528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 1.1057 - categorical_accuracy: 0.6658 - precision: 0.8432 - recall: 0.4528 - val_loss: 1.1391 - val_categorical_accuracy: 0.6224 - val_precision: 0.8333 - val_recall: 0.4592\n",
            "Epoch 76/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0906 - categorical_accuracy: 0.6594 - precision: 0.8167 - recall: 0.4490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 1.0906 - categorical_accuracy: 0.6594 - precision: 0.8167 - recall: 0.4490 - val_loss: 1.2724 - val_categorical_accuracy: 0.5510 - val_precision: 0.8333 - val_recall: 0.4082\n",
            "Epoch 77/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0917 - categorical_accuracy: 0.6607 - precision: 0.8585 - recall: 0.4566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.0917 - categorical_accuracy: 0.6607 - precision: 0.8585 - recall: 0.4566 - val_loss: 1.5787 - val_categorical_accuracy: 0.4388 - val_precision: 0.4918 - val_recall: 0.3061\n",
            "Epoch 78/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0905 - categorical_accuracy: 0.6543 - precision: 0.8537 - recall: 0.4541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.0905 - categorical_accuracy: 0.6543 - precision: 0.8537 - recall: 0.4541 - val_loss: 1.2182 - val_categorical_accuracy: 0.6224 - val_precision: 0.8667 - val_recall: 0.3980\n",
            "Epoch 79/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0727 - categorical_accuracy: 0.6620 - precision: 0.8581 - recall: 0.4783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.0727 - categorical_accuracy: 0.6620 - precision: 0.8581 - recall: 0.4783 - val_loss: 1.3437 - val_categorical_accuracy: 0.5612 - val_precision: 0.7826 - val_recall: 0.3673\n",
            "Epoch 80/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0756 - categorical_accuracy: 0.6556 - precision: 0.8456 - recall: 0.4681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.0756 - categorical_accuracy: 0.6556 - precision: 0.8456 - recall: 0.4681 - val_loss: 1.3138 - val_categorical_accuracy: 0.5816 - val_precision: 0.7872 - val_recall: 0.3776\n",
            "Epoch 81/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0771 - categorical_accuracy: 0.6645 - precision: 0.8239 - recall: 0.4656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.0771 - categorical_accuracy: 0.6645 - precision: 0.8239 - recall: 0.4656 - val_loss: 1.1650 - val_categorical_accuracy: 0.6429 - val_precision: 0.8800 - val_recall: 0.4490\n",
            "Epoch 82/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0333 - categorical_accuracy: 0.6901 - precision: 0.8462 - recall: 0.4911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.0333 - categorical_accuracy: 0.6901 - precision: 0.8462 - recall: 0.4911 - val_loss: 1.2900 - val_categorical_accuracy: 0.5306 - val_precision: 0.8261 - val_recall: 0.3878\n",
            "Epoch 83/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0648 - categorical_accuracy: 0.6556 - precision: 0.8256 - recall: 0.4770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 1.0648 - categorical_accuracy: 0.6556 - precision: 0.8256 - recall: 0.4770 - val_loss: 1.3659 - val_categorical_accuracy: 0.5102 - val_precision: 0.6964 - val_recall: 0.3980\n",
            "Epoch 84/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0484 - categorical_accuracy: 0.6811 - precision: 0.8322 - recall: 0.4872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 1.0484 - categorical_accuracy: 0.6811 - precision: 0.8322 - recall: 0.4872 - val_loss: 1.0314 - val_categorical_accuracy: 0.6633 - val_precision: 0.8333 - val_recall: 0.4592\n",
            "Epoch 85/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0389 - categorical_accuracy: 0.6582 - precision: 0.8330 - recall: 0.4962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.0389 - categorical_accuracy: 0.6582 - precision: 0.8330 - recall: 0.4962 - val_loss: 1.1094 - val_categorical_accuracy: 0.6020 - val_precision: 0.7931 - val_recall: 0.4694\n",
            "Epoch 86/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0321 - categorical_accuracy: 0.6862 - precision: 0.8431 - recall: 0.5140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 1.0321 - categorical_accuracy: 0.6862 - precision: 0.8431 - recall: 0.5140 - val_loss: 1.0392 - val_categorical_accuracy: 0.6633 - val_precision: 0.8846 - val_recall: 0.4694\n",
            "Epoch 87/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9857 - categorical_accuracy: 0.6977 - precision: 0.8528 - recall: 0.5319"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.9857 - categorical_accuracy: 0.6977 - precision: 0.8528 - recall: 0.5319 - val_loss: 1.0442 - val_categorical_accuracy: 0.6837 - val_precision: 0.8654 - val_recall: 0.4592\n",
            "Epoch 88/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9690 - categorical_accuracy: 0.7092 - precision: 0.8619 - recall: 0.5255"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.9690 - categorical_accuracy: 0.7092 - precision: 0.8619 - recall: 0.5255 - val_loss: 1.1048 - val_categorical_accuracy: 0.6633 - val_precision: 0.8868 - val_recall: 0.4796\n",
            "Epoch 89/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9937 - categorical_accuracy: 0.6977 - precision: 0.8392 - recall: 0.5128"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.9937 - categorical_accuracy: 0.6977 - precision: 0.8392 - recall: 0.5128 - val_loss: 1.4748 - val_categorical_accuracy: 0.5000 - val_precision: 0.6441 - val_recall: 0.3878\n",
            "Epoch 90/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 1.0713 - categorical_accuracy: 0.6518 - precision: 0.8091 - recall: 0.4758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 1.0713 - categorical_accuracy: 0.6518 - precision: 0.8091 - recall: 0.4758 - val_loss: 1.1813 - val_categorical_accuracy: 0.6020 - val_precision: 0.7164 - val_recall: 0.4898\n",
            "Epoch 91/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9996 - categorical_accuracy: 0.6888 - precision: 0.8379 - recall: 0.5077"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.9996 - categorical_accuracy: 0.6888 - precision: 0.8379 - recall: 0.5077 - val_loss: 1.0978 - val_categorical_accuracy: 0.6327 - val_precision: 0.8361 - val_recall: 0.5204\n",
            "Epoch 92/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9509 - categorical_accuracy: 0.7117 - precision: 0.8626 - recall: 0.5446"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.9509 - categorical_accuracy: 0.7117 - precision: 0.8626 - recall: 0.5446 - val_loss: 1.0919 - val_categorical_accuracy: 0.6735 - val_precision: 0.7869 - val_recall: 0.4898\n",
            "Epoch 93/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9622 - categorical_accuracy: 0.6913 - precision: 0.8340 - recall: 0.5191"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.9622 - categorical_accuracy: 0.6913 - precision: 0.8340 - recall: 0.5191 - val_loss: 0.9956 - val_categorical_accuracy: 0.7143 - val_precision: 0.8852 - val_recall: 0.5510\n",
            "Epoch 94/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9370 - categorical_accuracy: 0.7143 - precision: 0.8645 - recall: 0.5370"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.9370 - categorical_accuracy: 0.7143 - precision: 0.8645 - recall: 0.5370 - val_loss: 0.9994 - val_categorical_accuracy: 0.6735 - val_precision: 0.8548 - val_recall: 0.5408\n",
            "Epoch 95/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9322 - categorical_accuracy: 0.7156 - precision: 0.8492 - recall: 0.5676"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.9322 - categorical_accuracy: 0.7156 - precision: 0.8492 - recall: 0.5676 - val_loss: 1.0425 - val_categorical_accuracy: 0.6429 - val_precision: 0.8033 - val_recall: 0.5000\n",
            "Epoch 96/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9370 - categorical_accuracy: 0.7066 - precision: 0.8563 - recall: 0.5395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.9370 - categorical_accuracy: 0.7066 - precision: 0.8563 - recall: 0.5395 - val_loss: 1.0671 - val_categorical_accuracy: 0.6327 - val_precision: 0.7703 - val_recall: 0.5816\n",
            "Epoch 97/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9231 - categorical_accuracy: 0.7411 - precision: 0.8362 - recall: 0.5536"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.9231 - categorical_accuracy: 0.7411 - precision: 0.8362 - recall: 0.5536 - val_loss: 0.9604 - val_categorical_accuracy: 0.7245 - val_precision: 0.8769 - val_recall: 0.5816\n",
            "Epoch 98/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8909 - categorical_accuracy: 0.7526 - precision: 0.8740 - recall: 0.5753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8909 - categorical_accuracy: 0.7526 - precision: 0.8740 - recall: 0.5753 - val_loss: 1.4458 - val_categorical_accuracy: 0.4490 - val_precision: 0.6552 - val_recall: 0.3878\n",
            "Epoch 99/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9253 - categorical_accuracy: 0.7283 - precision: 0.8436 - recall: 0.5778"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.9253 - categorical_accuracy: 0.7283 - precision: 0.8436 - recall: 0.5778 - val_loss: 1.1872 - val_categorical_accuracy: 0.5816 - val_precision: 0.6769 - val_recall: 0.4490\n",
            "Epoch 100/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9322 - categorical_accuracy: 0.7041 - precision: 0.8216 - recall: 0.5344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.9322 - categorical_accuracy: 0.7041 - precision: 0.8216 - recall: 0.5344 - val_loss: 1.2765 - val_categorical_accuracy: 0.5714 - val_precision: 0.7241 - val_recall: 0.4286\n",
            "Epoch 101/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9071 - categorical_accuracy: 0.7219 - precision: 0.8607 - recall: 0.5753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.9071 - categorical_accuracy: 0.7219 - precision: 0.8607 - recall: 0.5753 - val_loss: 1.0445 - val_categorical_accuracy: 0.6633 - val_precision: 0.8475 - val_recall: 0.5102\n",
            "Epoch 102/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9501 - categorical_accuracy: 0.6952 - precision: 0.8536 - recall: 0.5651"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.9501 - categorical_accuracy: 0.6952 - precision: 0.8536 - recall: 0.5651 - val_loss: 1.0406 - val_categorical_accuracy: 0.6327 - val_precision: 0.7714 - val_recall: 0.5510\n",
            "Epoch 103/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9366 - categorical_accuracy: 0.7130 - precision: 0.8473 - recall: 0.5663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.9366 - categorical_accuracy: 0.7130 - precision: 0.8473 - recall: 0.5663 - val_loss: 1.8486 - val_categorical_accuracy: 0.4184 - val_precision: 0.5070 - val_recall: 0.3673\n",
            "Epoch 104/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8914 - categorical_accuracy: 0.7436 - precision: 0.8725 - recall: 0.6020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.8914 - categorical_accuracy: 0.7436 - precision: 0.8725 - recall: 0.6020 - val_loss: 0.9224 - val_categorical_accuracy: 0.7347 - val_precision: 0.8806 - val_recall: 0.6020\n",
            "Epoch 105/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8630 - categorical_accuracy: 0.7462 - precision: 0.8579 - recall: 0.6084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8630 - categorical_accuracy: 0.7462 - precision: 0.8579 - recall: 0.6084 - val_loss: 1.1040 - val_categorical_accuracy: 0.6531 - val_precision: 0.8030 - val_recall: 0.5408\n",
            "Epoch 106/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8560 - categorical_accuracy: 0.7449 - precision: 0.8708 - recall: 0.6020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8560 - categorical_accuracy: 0.7449 - precision: 0.8708 - recall: 0.6020 - val_loss: 0.9470 - val_categorical_accuracy: 0.7041 - val_precision: 0.8209 - val_recall: 0.5612\n",
            "Epoch 107/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8757 - categorical_accuracy: 0.7398 - precision: 0.8638 - recall: 0.5906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8757 - categorical_accuracy: 0.7398 - precision: 0.8638 - recall: 0.5906 - val_loss: 1.0781 - val_categorical_accuracy: 0.6429 - val_precision: 0.7460 - val_recall: 0.4796\n",
            "Epoch 108/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.9059 - categorical_accuracy: 0.7117 - precision: 0.8287 - recall: 0.5676"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.9059 - categorical_accuracy: 0.7117 - precision: 0.8287 - recall: 0.5676 - val_loss: 0.9640 - val_categorical_accuracy: 0.7041 - val_precision: 0.8689 - val_recall: 0.5408\n",
            "Epoch 109/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8737 - categorical_accuracy: 0.7436 - precision: 0.8532 - recall: 0.5855"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.8737 - categorical_accuracy: 0.7436 - precision: 0.8532 - recall: 0.5855 - val_loss: 0.9277 - val_categorical_accuracy: 0.7041 - val_precision: 0.8286 - val_recall: 0.5918\n",
            "Epoch 110/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8377 - categorical_accuracy: 0.7602 - precision: 0.8703 - recall: 0.6161"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8377 - categorical_accuracy: 0.7602 - precision: 0.8703 - recall: 0.6161 - val_loss: 0.9220 - val_categorical_accuracy: 0.7143 - val_precision: 0.8571 - val_recall: 0.6122\n",
            "Epoch 111/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8575 - categorical_accuracy: 0.7449 - precision: 0.8512 - recall: 0.5982"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.8575 - categorical_accuracy: 0.7449 - precision: 0.8512 - recall: 0.5982 - val_loss: 1.0427 - val_categorical_accuracy: 0.6531 - val_precision: 0.7727 - val_recall: 0.5204\n",
            "Epoch 112/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8675 - categorical_accuracy: 0.7551 - precision: 0.8449 - recall: 0.6046"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8675 - categorical_accuracy: 0.7551 - precision: 0.8449 - recall: 0.6046 - val_loss: 1.0157 - val_categorical_accuracy: 0.6939 - val_precision: 0.7879 - val_recall: 0.5306\n",
            "Epoch 113/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8518 - categorical_accuracy: 0.7577 - precision: 0.8499 - recall: 0.5995"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.8518 - categorical_accuracy: 0.7577 - precision: 0.8499 - recall: 0.5995 - val_loss: 0.8687 - val_categorical_accuracy: 0.7551 - val_precision: 0.8571 - val_recall: 0.6122\n",
            "Epoch 114/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8376 - categorical_accuracy: 0.7474 - precision: 0.8584 - recall: 0.6263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.8376 - categorical_accuracy: 0.7474 - precision: 0.8584 - recall: 0.6263 - val_loss: 0.8577 - val_categorical_accuracy: 0.7449 - val_precision: 0.8676 - val_recall: 0.6020\n",
            "Epoch 115/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8377 - categorical_accuracy: 0.7296 - precision: 0.8363 - recall: 0.6059"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.8377 - categorical_accuracy: 0.7296 - precision: 0.8363 - recall: 0.6059 - val_loss: 0.9736 - val_categorical_accuracy: 0.6837 - val_precision: 0.7808 - val_recall: 0.5816\n",
            "Epoch 116/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8325 - categorical_accuracy: 0.7602 - precision: 0.8472 - recall: 0.6365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.8325 - categorical_accuracy: 0.7602 - precision: 0.8472 - recall: 0.6365 - val_loss: 1.0928 - val_categorical_accuracy: 0.6224 - val_precision: 0.7429 - val_recall: 0.5306\n",
            "Epoch 117/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8641 - categorical_accuracy: 0.7436 - precision: 0.8459 - recall: 0.6020"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8641 - categorical_accuracy: 0.7436 - precision: 0.8459 - recall: 0.6020 - val_loss: 0.8947 - val_categorical_accuracy: 0.7347 - val_precision: 0.8636 - val_recall: 0.5816\n",
            "Epoch 118/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8577 - categorical_accuracy: 0.7500 - precision: 0.8539 - recall: 0.6263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8577 - categorical_accuracy: 0.7500 - precision: 0.8539 - recall: 0.6263 - val_loss: 1.1215 - val_categorical_accuracy: 0.6224 - val_precision: 0.7619 - val_recall: 0.4898\n",
            "Epoch 119/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8488 - categorical_accuracy: 0.7577 - precision: 0.8474 - recall: 0.6161"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8488 - categorical_accuracy: 0.7577 - precision: 0.8474 - recall: 0.6161 - val_loss: 0.9220 - val_categorical_accuracy: 0.6939 - val_precision: 0.7922 - val_recall: 0.6224\n",
            "Epoch 120/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8245 - categorical_accuracy: 0.7589 - precision: 0.8586 - recall: 0.6429"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.8245 - categorical_accuracy: 0.7589 - precision: 0.8586 - recall: 0.6429 - val_loss: 1.1246 - val_categorical_accuracy: 0.6020 - val_precision: 0.7083 - val_recall: 0.5204\n",
            "Epoch 121/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8076 - categorical_accuracy: 0.7577 - precision: 0.8611 - recall: 0.6327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.8076 - categorical_accuracy: 0.7577 - precision: 0.8611 - recall: 0.6327 - val_loss: 1.1400 - val_categorical_accuracy: 0.6020 - val_precision: 0.7077 - val_recall: 0.4694\n",
            "Epoch 122/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8251 - categorical_accuracy: 0.7500 - precision: 0.8555 - recall: 0.6492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8251 - categorical_accuracy: 0.7500 - precision: 0.8555 - recall: 0.6492 - val_loss: 1.1114 - val_categorical_accuracy: 0.6327 - val_precision: 0.7692 - val_recall: 0.5102\n",
            "Epoch 123/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8147 - categorical_accuracy: 0.7602 - precision: 0.8681 - recall: 0.6378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.8147 - categorical_accuracy: 0.7602 - precision: 0.8681 - recall: 0.6378 - val_loss: 0.8517 - val_categorical_accuracy: 0.7449 - val_precision: 0.8382 - val_recall: 0.5816\n",
            "Epoch 124/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8211 - categorical_accuracy: 0.7717 - precision: 0.8576 - recall: 0.6378"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.8211 - categorical_accuracy: 0.7717 - precision: 0.8576 - recall: 0.6378 - val_loss: 1.1294 - val_categorical_accuracy: 0.6327 - val_precision: 0.6795 - val_recall: 0.5408\n",
            "Epoch 125/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8172 - categorical_accuracy: 0.7640 - precision: 0.8729 - recall: 0.6480"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.8172 - categorical_accuracy: 0.7640 - precision: 0.8729 - recall: 0.6480 - val_loss: 0.9433 - val_categorical_accuracy: 0.6837 - val_precision: 0.8028 - val_recall: 0.5816\n",
            "Epoch 126/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8205 - categorical_accuracy: 0.7513 - precision: 0.8655 - recall: 0.6403"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8205 - categorical_accuracy: 0.7513 - precision: 0.8655 - recall: 0.6403 - val_loss: 0.9148 - val_categorical_accuracy: 0.6939 - val_precision: 0.7973 - val_recall: 0.6020\n",
            "Epoch 127/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.8160 - categorical_accuracy: 0.7602 - precision: 0.8479 - recall: 0.6327"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.8160 - categorical_accuracy: 0.7602 - precision: 0.8479 - recall: 0.6327 - val_loss: 0.8674 - val_categorical_accuracy: 0.7347 - val_precision: 0.8630 - val_recall: 0.6429\n",
            "Epoch 128/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7848 - categorical_accuracy: 0.7691 - precision: 0.8679 - recall: 0.6620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7848 - categorical_accuracy: 0.7691 - precision: 0.8679 - recall: 0.6620 - val_loss: 0.8655 - val_categorical_accuracy: 0.7041 - val_precision: 0.8462 - val_recall: 0.5612\n",
            "Epoch 129/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7764 - categorical_accuracy: 0.7730 - precision: 0.8667 - recall: 0.6633"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.7764 - categorical_accuracy: 0.7730 - precision: 0.8667 - recall: 0.6633 - val_loss: 0.8913 - val_categorical_accuracy: 0.7245 - val_precision: 0.8056 - val_recall: 0.5918\n",
            "Epoch 130/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7703 - categorical_accuracy: 0.7857 - precision: 0.8731 - recall: 0.6671"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7703 - categorical_accuracy: 0.7857 - precision: 0.8731 - recall: 0.6671 - val_loss: 0.7921 - val_categorical_accuracy: 0.7449 - val_precision: 0.9155 - val_recall: 0.6633\n",
            "Epoch 131/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7703 - categorical_accuracy: 0.7602 - precision: 0.8754 - recall: 0.6633"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7703 - categorical_accuracy: 0.7602 - precision: 0.8754 - recall: 0.6633 - val_loss: 0.8972 - val_categorical_accuracy: 0.7245 - val_precision: 0.8267 - val_recall: 0.6327\n",
            "Epoch 132/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7896 - categorical_accuracy: 0.7640 - precision: 0.8627 - recall: 0.6735"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.7896 - categorical_accuracy: 0.7640 - precision: 0.8627 - recall: 0.6735 - val_loss: 0.8766 - val_categorical_accuracy: 0.7041 - val_precision: 0.8158 - val_recall: 0.6327\n",
            "Epoch 133/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7657 - categorical_accuracy: 0.7806 - precision: 0.8608 - recall: 0.6786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 154ms/step - loss: 0.7657 - categorical_accuracy: 0.7806 - precision: 0.8608 - recall: 0.6786 - val_loss: 0.8917 - val_categorical_accuracy: 0.7143 - val_precision: 0.8026 - val_recall: 0.6224\n",
            "Epoch 134/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7370 - categorical_accuracy: 0.8074 - precision: 0.8812 - recall: 0.7003"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 180ms/step - loss: 0.7370 - categorical_accuracy: 0.8074 - precision: 0.8812 - recall: 0.7003 - val_loss: 0.9723 - val_categorical_accuracy: 0.6735 - val_precision: 0.7561 - val_recall: 0.6327\n",
            "Epoch 135/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7505 - categorical_accuracy: 0.7857 - precision: 0.8667 - recall: 0.6798"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 124ms/step - loss: 0.7505 - categorical_accuracy: 0.7857 - precision: 0.8667 - recall: 0.6798 - val_loss: 0.8911 - val_categorical_accuracy: 0.7245 - val_precision: 0.8000 - val_recall: 0.6531\n",
            "Epoch 136/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7766 - categorical_accuracy: 0.7755 - precision: 0.8576 - recall: 0.6684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.7766 - categorical_accuracy: 0.7755 - precision: 0.8576 - recall: 0.6684 - val_loss: 1.0700 - val_categorical_accuracy: 0.6633 - val_precision: 0.7284 - val_recall: 0.6020\n",
            "Epoch 137/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7878 - categorical_accuracy: 0.7640 - precision: 0.8381 - recall: 0.6735"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7878 - categorical_accuracy: 0.7640 - precision: 0.8381 - recall: 0.6735 - val_loss: 0.9171 - val_categorical_accuracy: 0.6837 - val_precision: 0.7821 - val_recall: 0.6224\n",
            "Epoch 138/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7433 - categorical_accuracy: 0.7768 - precision: 0.8636 - recall: 0.6862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.7433 - categorical_accuracy: 0.7768 - precision: 0.8636 - recall: 0.6862 - val_loss: 0.7890 - val_categorical_accuracy: 0.7449 - val_precision: 0.8750 - val_recall: 0.6429\n",
            "Epoch 139/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7422 - categorical_accuracy: 0.7908 - precision: 0.8774 - recall: 0.6939"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7422 - categorical_accuracy: 0.7908 - precision: 0.8774 - recall: 0.6939 - val_loss: 0.8210 - val_categorical_accuracy: 0.7347 - val_precision: 0.8101 - val_recall: 0.6531\n",
            "Epoch 140/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7421 - categorical_accuracy: 0.7819 - precision: 0.8652 - recall: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7421 - categorical_accuracy: 0.7819 - precision: 0.8652 - recall: 0.6875 - val_loss: 0.7930 - val_categorical_accuracy: 0.7653 - val_precision: 0.8400 - val_recall: 0.6429\n",
            "Epoch 141/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7521 - categorical_accuracy: 0.7857 - precision: 0.8654 - recall: 0.6722"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.7521 - categorical_accuracy: 0.7857 - precision: 0.8654 - recall: 0.6722 - val_loss: 0.8607 - val_categorical_accuracy: 0.6837 - val_precision: 0.7733 - val_recall: 0.5918\n",
            "Epoch 142/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7681 - categorical_accuracy: 0.7602 - precision: 0.8576 - recall: 0.6837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.7681 - categorical_accuracy: 0.7602 - precision: 0.8576 - recall: 0.6837 - val_loss: 0.8423 - val_categorical_accuracy: 0.7245 - val_precision: 0.8333 - val_recall: 0.6633\n",
            "Epoch 143/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7532 - categorical_accuracy: 0.7806 - precision: 0.8464 - recall: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7532 - categorical_accuracy: 0.7806 - precision: 0.8464 - recall: 0.6888 - val_loss: 0.8465 - val_categorical_accuracy: 0.6837 - val_precision: 0.8289 - val_recall: 0.6429\n",
            "Epoch 144/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7557 - categorical_accuracy: 0.7793 - precision: 0.8677 - recall: 0.6862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.7557 - categorical_accuracy: 0.7793 - precision: 0.8677 - recall: 0.6862 - val_loss: 0.8998 - val_categorical_accuracy: 0.7347 - val_precision: 0.8077 - val_recall: 0.6429\n",
            "Epoch 145/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7716 - categorical_accuracy: 0.7589 - precision: 0.8505 - recall: 0.6747"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7716 - categorical_accuracy: 0.7589 - precision: 0.8505 - recall: 0.6747 - val_loss: 0.8076 - val_categorical_accuracy: 0.7347 - val_precision: 0.8608 - val_recall: 0.6939\n",
            "Epoch 146/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7338 - categorical_accuracy: 0.7806 - precision: 0.8694 - recall: 0.6964"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7338 - categorical_accuracy: 0.7806 - precision: 0.8694 - recall: 0.6964 - val_loss: 1.0653 - val_categorical_accuracy: 0.6327 - val_precision: 0.7125 - val_recall: 0.5816\n",
            "Epoch 147/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7607 - categorical_accuracy: 0.7666 - precision: 0.8594 - recall: 0.6862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.7607 - categorical_accuracy: 0.7666 - precision: 0.8594 - recall: 0.6862 - val_loss: 1.0813 - val_categorical_accuracy: 0.5918 - val_precision: 0.6420 - val_recall: 0.5306\n",
            "Epoch 148/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7203 - categorical_accuracy: 0.7959 - precision: 0.8766 - recall: 0.7066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7203 - categorical_accuracy: 0.7959 - precision: 0.8766 - recall: 0.7066 - val_loss: 1.9301 - val_categorical_accuracy: 0.4286 - val_precision: 0.4578 - val_recall: 0.3878\n",
            "Epoch 149/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7388 - categorical_accuracy: 0.7895 - precision: 0.8618 - recall: 0.7079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7388 - categorical_accuracy: 0.7895 - precision: 0.8618 - recall: 0.7079 - val_loss: 1.0509 - val_categorical_accuracy: 0.6020 - val_precision: 0.6790 - val_recall: 0.5612\n",
            "Epoch 150/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6885 - categorical_accuracy: 0.8099 - precision: 0.8915 - recall: 0.7334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6885 - categorical_accuracy: 0.8099 - precision: 0.8915 - recall: 0.7334 - val_loss: 0.7384 - val_categorical_accuracy: 0.7653 - val_precision: 0.8608 - val_recall: 0.6939\n",
            "Epoch 151/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7303 - categorical_accuracy: 0.7870 - precision: 0.8521 - recall: 0.7054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7303 - categorical_accuracy: 0.7870 - precision: 0.8521 - recall: 0.7054 - val_loss: 1.0096 - val_categorical_accuracy: 0.6531 - val_precision: 0.7808 - val_recall: 0.5816\n",
            "Epoch 152/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7331 - categorical_accuracy: 0.7883 - precision: 0.8748 - recall: 0.6862"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7331 - categorical_accuracy: 0.7883 - precision: 0.8748 - recall: 0.6862 - val_loss: 1.1138 - val_categorical_accuracy: 0.6224 - val_precision: 0.7237 - val_recall: 0.5612\n",
            "Epoch 153/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7079 - categorical_accuracy: 0.8099 - precision: 0.8785 - recall: 0.7283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7079 - categorical_accuracy: 0.8099 - precision: 0.8785 - recall: 0.7283 - val_loss: 0.7538 - val_categorical_accuracy: 0.7551 - val_precision: 0.8395 - val_recall: 0.6939\n",
            "Epoch 154/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6875 - categorical_accuracy: 0.7985 - precision: 0.8699 - recall: 0.7334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6875 - categorical_accuracy: 0.7985 - precision: 0.8699 - recall: 0.7334 - val_loss: 0.9656 - val_categorical_accuracy: 0.6633 - val_precision: 0.8030 - val_recall: 0.5408\n",
            "Epoch 155/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7425 - categorical_accuracy: 0.7755 - precision: 0.8627 - recall: 0.7054"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7425 - categorical_accuracy: 0.7755 - precision: 0.8627 - recall: 0.7054 - val_loss: 0.8748 - val_categorical_accuracy: 0.6735 - val_precision: 0.7564 - val_recall: 0.6020\n",
            "Epoch 156/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7283 - categorical_accuracy: 0.7832 - precision: 0.8589 - recall: 0.7066"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7283 - categorical_accuracy: 0.7832 - precision: 0.8589 - recall: 0.7066 - val_loss: 1.1050 - val_categorical_accuracy: 0.6327 - val_precision: 0.6706 - val_recall: 0.5816\n",
            "Epoch 157/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7592 - categorical_accuracy: 0.7691 - precision: 0.8612 - recall: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7592 - categorical_accuracy: 0.7691 - precision: 0.8612 - recall: 0.6888 - val_loss: 0.9041 - val_categorical_accuracy: 0.7245 - val_precision: 0.8382 - val_recall: 0.5816\n",
            "Epoch 158/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7432 - categorical_accuracy: 0.7921 - precision: 0.8605 - recall: 0.7079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7432 - categorical_accuracy: 0.7921 - precision: 0.8605 - recall: 0.7079 - val_loss: 0.8822 - val_categorical_accuracy: 0.7551 - val_precision: 0.8049 - val_recall: 0.6735\n",
            "Epoch 159/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6963 - categorical_accuracy: 0.8010 - precision: 0.8818 - recall: 0.7232"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6963 - categorical_accuracy: 0.8010 - precision: 0.8818 - recall: 0.7232 - val_loss: 0.7640 - val_categorical_accuracy: 0.7959 - val_precision: 0.8919 - val_recall: 0.6735\n",
            "Epoch 160/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6931 - categorical_accuracy: 0.8010 - precision: 0.8746 - recall: 0.7296"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6931 - categorical_accuracy: 0.8010 - precision: 0.8746 - recall: 0.7296 - val_loss: 0.7771 - val_categorical_accuracy: 0.7959 - val_precision: 0.8553 - val_recall: 0.6633\n",
            "Epoch 161/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6435 - categorical_accuracy: 0.8253 - precision: 0.8839 - recall: 0.7474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6435 - categorical_accuracy: 0.8253 - precision: 0.8839 - recall: 0.7474 - val_loss: 0.7571 - val_categorical_accuracy: 0.7755 - val_precision: 0.8025 - val_recall: 0.6633\n",
            "Epoch 162/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7043 - categorical_accuracy: 0.7832 - precision: 0.8641 - recall: 0.7219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.7043 - categorical_accuracy: 0.7832 - precision: 0.8641 - recall: 0.7219 - val_loss: 0.8342 - val_categorical_accuracy: 0.7245 - val_precision: 0.8026 - val_recall: 0.6224\n",
            "Epoch 163/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6627 - categorical_accuracy: 0.8163 - precision: 0.8903 - recall: 0.7347"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6627 - categorical_accuracy: 0.8163 - precision: 0.8903 - recall: 0.7347 - val_loss: 0.8003 - val_categorical_accuracy: 0.7449 - val_precision: 0.7976 - val_recall: 0.6837\n",
            "Epoch 164/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7036 - categorical_accuracy: 0.7857 - precision: 0.8563 - recall: 0.7219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.7036 - categorical_accuracy: 0.7857 - precision: 0.8563 - recall: 0.7219 - val_loss: 0.8788 - val_categorical_accuracy: 0.6837 - val_precision: 0.7821 - val_recall: 0.6224\n",
            "Epoch 165/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6870 - categorical_accuracy: 0.8036 - precision: 0.8802 - recall: 0.7219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6870 - categorical_accuracy: 0.8036 - precision: 0.8802 - recall: 0.7219 - val_loss: 0.7523 - val_categorical_accuracy: 0.7449 - val_precision: 0.8228 - val_recall: 0.6633\n",
            "Epoch 166/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6708 - categorical_accuracy: 0.8099 - precision: 0.8849 - recall: 0.7551"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6708 - categorical_accuracy: 0.8099 - precision: 0.8849 - recall: 0.7551 - val_loss: 0.7594 - val_categorical_accuracy: 0.7449 - val_precision: 0.8434 - val_recall: 0.7143\n",
            "Epoch 167/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7094 - categorical_accuracy: 0.7895 - precision: 0.8674 - recall: 0.7258"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.7094 - categorical_accuracy: 0.7895 - precision: 0.8674 - recall: 0.7258 - val_loss: 0.7470 - val_categorical_accuracy: 0.7755 - val_precision: 0.8395 - val_recall: 0.6939\n",
            "Epoch 168/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6724 - categorical_accuracy: 0.8036 - precision: 0.8651 - recall: 0.7360"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6724 - categorical_accuracy: 0.8036 - precision: 0.8651 - recall: 0.7360 - val_loss: 0.8314 - val_categorical_accuracy: 0.7143 - val_precision: 0.8171 - val_recall: 0.6837\n",
            "Epoch 169/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6336 - categorical_accuracy: 0.8202 - precision: 0.8943 - recall: 0.7551"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6336 - categorical_accuracy: 0.8202 - precision: 0.8943 - recall: 0.7551 - val_loss: 0.9857 - val_categorical_accuracy: 0.6122 - val_precision: 0.6706 - val_recall: 0.5816\n",
            "Epoch 170/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7020 - categorical_accuracy: 0.8061 - precision: 0.8589 - recall: 0.7219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.7020 - categorical_accuracy: 0.8061 - precision: 0.8589 - recall: 0.7219 - val_loss: 1.1468 - val_categorical_accuracy: 0.6020 - val_precision: 0.6883 - val_recall: 0.5408\n",
            "Epoch 171/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6933 - categorical_accuracy: 0.7997 - precision: 0.8841 - recall: 0.7398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6933 - categorical_accuracy: 0.7997 - precision: 0.8841 - recall: 0.7398 - val_loss: 0.8896 - val_categorical_accuracy: 0.6633 - val_precision: 0.7407 - val_recall: 0.6122\n",
            "Epoch 172/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6722 - categorical_accuracy: 0.8023 - precision: 0.8660 - recall: 0.7334"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6722 - categorical_accuracy: 0.8023 - precision: 0.8660 - recall: 0.7334 - val_loss: 0.9859 - val_categorical_accuracy: 0.6327 - val_precision: 0.7037 - val_recall: 0.5816\n",
            "Epoch 173/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6708 - categorical_accuracy: 0.8112 - precision: 0.8696 - recall: 0.7398"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 86ms/step - loss: 0.6708 - categorical_accuracy: 0.8112 - precision: 0.8696 - recall: 0.7398 - val_loss: 0.7814 - val_categorical_accuracy: 0.7551 - val_precision: 0.8375 - val_recall: 0.6837\n",
            "Epoch 174/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6792 - categorical_accuracy: 0.8048 - precision: 0.8698 - recall: 0.7411"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6792 - categorical_accuracy: 0.8048 - precision: 0.8698 - recall: 0.7411 - val_loss: 0.7065 - val_categorical_accuracy: 0.7959 - val_precision: 0.8810 - val_recall: 0.7551\n",
            "Epoch 175/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6140 - categorical_accuracy: 0.8304 - precision: 0.8963 - recall: 0.7717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.6140 - categorical_accuracy: 0.8304 - precision: 0.8963 - recall: 0.7717 - val_loss: 0.8244 - val_categorical_accuracy: 0.6939 - val_precision: 0.8333 - val_recall: 0.6633\n",
            "Epoch 176/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6389 - categorical_accuracy: 0.8240 - precision: 0.8884 - recall: 0.7513"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6389 - categorical_accuracy: 0.8240 - precision: 0.8884 - recall: 0.7513 - val_loss: 0.8037 - val_categorical_accuracy: 0.7347 - val_precision: 0.7901 - val_recall: 0.6531\n",
            "Epoch 177/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6834 - categorical_accuracy: 0.8061 - precision: 0.8697 - recall: 0.7321"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6834 - categorical_accuracy: 0.8061 - precision: 0.8697 - recall: 0.7321 - val_loss: 1.0581 - val_categorical_accuracy: 0.6327 - val_precision: 0.6585 - val_recall: 0.5510\n",
            "Epoch 178/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6599 - categorical_accuracy: 0.8176 - precision: 0.8896 - recall: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.6599 - categorical_accuracy: 0.8176 - precision: 0.8896 - recall: 0.7500 - val_loss: 0.7035 - val_categorical_accuracy: 0.7755 - val_precision: 0.8795 - val_recall: 0.7449\n",
            "Epoch 179/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6545 - categorical_accuracy: 0.8125 - precision: 0.8910 - recall: 0.7615"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.6545 - categorical_accuracy: 0.8125 - precision: 0.8910 - recall: 0.7615 - val_loss: 0.8009 - val_categorical_accuracy: 0.7449 - val_precision: 0.8023 - val_recall: 0.7041\n",
            "Epoch 180/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6587 - categorical_accuracy: 0.7934 - precision: 0.8614 - recall: 0.7296"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6587 - categorical_accuracy: 0.7934 - precision: 0.8614 - recall: 0.7296 - val_loss: 0.9079 - val_categorical_accuracy: 0.6939 - val_precision: 0.7558 - val_recall: 0.6633\n",
            "Epoch 181/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6517 - categorical_accuracy: 0.8099 - precision: 0.8769 - recall: 0.7449"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6517 - categorical_accuracy: 0.8099 - precision: 0.8769 - recall: 0.7449 - val_loss: 0.8028 - val_categorical_accuracy: 0.7755 - val_precision: 0.8312 - val_recall: 0.6531\n",
            "Epoch 182/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6528 - categorical_accuracy: 0.8099 - precision: 0.8714 - recall: 0.7436"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.6528 - categorical_accuracy: 0.8099 - precision: 0.8714 - recall: 0.7436 - val_loss: 0.6647 - val_categorical_accuracy: 0.8061 - val_precision: 0.8902 - val_recall: 0.7449\n",
            "Epoch 183/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6097 - categorical_accuracy: 0.8227 - precision: 0.8994 - recall: 0.7640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6097 - categorical_accuracy: 0.8227 - precision: 0.8994 - recall: 0.7640 - val_loss: 0.7365 - val_categorical_accuracy: 0.7755 - val_precision: 0.8434 - val_recall: 0.7143\n",
            "Epoch 184/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6114 - categorical_accuracy: 0.8304 - precision: 0.8830 - recall: 0.7704"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.6114 - categorical_accuracy: 0.8304 - precision: 0.8830 - recall: 0.7704 - val_loss: 0.8914 - val_categorical_accuracy: 0.7041 - val_precision: 0.7442 - val_recall: 0.6531\n",
            "Epoch 185/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6952 - categorical_accuracy: 0.7819 - precision: 0.8385 - recall: 0.7219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6952 - categorical_accuracy: 0.7819 - precision: 0.8385 - recall: 0.7219 - val_loss: 0.9903 - val_categorical_accuracy: 0.6939 - val_precision: 0.7975 - val_recall: 0.6429\n",
            "Epoch 186/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6429 - categorical_accuracy: 0.8163 - precision: 0.8807 - recall: 0.7436"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6429 - categorical_accuracy: 0.8163 - precision: 0.8807 - recall: 0.7436 - val_loss: 0.7720 - val_categorical_accuracy: 0.7755 - val_precision: 0.8590 - val_recall: 0.6837\n",
            "Epoch 187/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6072 - categorical_accuracy: 0.8265 - precision: 0.8960 - recall: 0.7691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6072 - categorical_accuracy: 0.8265 - precision: 0.8960 - recall: 0.7691 - val_loss: 0.8098 - val_categorical_accuracy: 0.7245 - val_precision: 0.8025 - val_recall: 0.6633\n",
            "Epoch 188/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.7042 - categorical_accuracy: 0.7870 - precision: 0.8606 - recall: 0.7321"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.7042 - categorical_accuracy: 0.7870 - precision: 0.8606 - recall: 0.7321 - val_loss: 0.9072 - val_categorical_accuracy: 0.7245 - val_precision: 0.8205 - val_recall: 0.6531\n",
            "Epoch 189/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6552 - categorical_accuracy: 0.8048 - precision: 0.8721 - recall: 0.7564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6552 - categorical_accuracy: 0.8048 - precision: 0.8721 - recall: 0.7564 - val_loss: 0.7317 - val_categorical_accuracy: 0.7653 - val_precision: 0.8571 - val_recall: 0.7347\n",
            "Epoch 190/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6689 - categorical_accuracy: 0.7997 - precision: 0.8786 - recall: 0.7385"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6689 - categorical_accuracy: 0.7997 - precision: 0.8786 - recall: 0.7385 - val_loss: 0.9150 - val_categorical_accuracy: 0.6939 - val_precision: 0.7468 - val_recall: 0.6020\n",
            "Epoch 191/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6004 - categorical_accuracy: 0.8304 - precision: 0.8896 - recall: 0.7602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6004 - categorical_accuracy: 0.8304 - precision: 0.8896 - recall: 0.7602 - val_loss: 0.8589 - val_categorical_accuracy: 0.6939 - val_precision: 0.7531 - val_recall: 0.6224\n",
            "Epoch 192/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6299 - categorical_accuracy: 0.8151 - precision: 0.8804 - recall: 0.7602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6299 - categorical_accuracy: 0.8151 - precision: 0.8804 - recall: 0.7602 - val_loss: 0.8368 - val_categorical_accuracy: 0.7653 - val_precision: 0.8375 - val_recall: 0.6837\n",
            "Epoch 193/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6299 - categorical_accuracy: 0.8214 - precision: 0.8737 - recall: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.6299 - categorical_accuracy: 0.8214 - precision: 0.8737 - recall: 0.7500 - val_loss: 0.8423 - val_categorical_accuracy: 0.6939 - val_precision: 0.7683 - val_recall: 0.6429\n",
            "Epoch 194/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6323 - categorical_accuracy: 0.8138 - precision: 0.8759 - recall: 0.7564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6323 - categorical_accuracy: 0.8138 - precision: 0.8759 - recall: 0.7564 - val_loss: 0.7166 - val_categorical_accuracy: 0.8061 - val_precision: 0.8706 - val_recall: 0.7551\n",
            "Epoch 195/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6169 - categorical_accuracy: 0.8202 - precision: 0.8874 - recall: 0.7640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6169 - categorical_accuracy: 0.8202 - precision: 0.8874 - recall: 0.7640 - val_loss: 0.8293 - val_categorical_accuracy: 0.7245 - val_precision: 0.8049 - val_recall: 0.6735\n",
            "Epoch 196/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6596 - categorical_accuracy: 0.8048 - precision: 0.8543 - recall: 0.7551"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6596 - categorical_accuracy: 0.8048 - precision: 0.8543 - recall: 0.7551 - val_loss: 0.6842 - val_categorical_accuracy: 0.7551 - val_precision: 0.8642 - val_recall: 0.7143\n",
            "Epoch 197/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6193 - categorical_accuracy: 0.8099 - precision: 0.8732 - recall: 0.7640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.6193 - categorical_accuracy: 0.8099 - precision: 0.8732 - recall: 0.7640 - val_loss: 0.8558 - val_categorical_accuracy: 0.6939 - val_precision: 0.7750 - val_recall: 0.6327\n",
            "Epoch 198/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6221 - categorical_accuracy: 0.8163 - precision: 0.8803 - recall: 0.7691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.6221 - categorical_accuracy: 0.8163 - precision: 0.8803 - recall: 0.7691 - val_loss: 0.6826 - val_categorical_accuracy: 0.8061 - val_precision: 0.8506 - val_recall: 0.7551\n",
            "Epoch 199/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5912 - categorical_accuracy: 0.8265 - precision: 0.8785 - recall: 0.7653"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5912 - categorical_accuracy: 0.8265 - precision: 0.8785 - recall: 0.7653 - val_loss: 0.6927 - val_categorical_accuracy: 0.7755 - val_precision: 0.8372 - val_recall: 0.7347\n",
            "Epoch 200/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5707 - categorical_accuracy: 0.8457 - precision: 0.9055 - recall: 0.7946"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.5707 - categorical_accuracy: 0.8457 - precision: 0.9055 - recall: 0.7946 - val_loss: 0.6959 - val_categorical_accuracy: 0.7857 - val_precision: 0.8452 - val_recall: 0.7245\n",
            "Epoch 201/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6046 - categorical_accuracy: 0.8265 - precision: 0.8835 - recall: 0.7640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6046 - categorical_accuracy: 0.8265 - precision: 0.8835 - recall: 0.7640 - val_loss: 0.7726 - val_categorical_accuracy: 0.7857 - val_precision: 0.8276 - val_recall: 0.7347\n",
            "Epoch 202/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6129 - categorical_accuracy: 0.8240 - precision: 0.8932 - recall: 0.7679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6129 - categorical_accuracy: 0.8240 - precision: 0.8932 - recall: 0.7679 - val_loss: 0.6635 - val_categorical_accuracy: 0.7857 - val_precision: 0.8675 - val_recall: 0.7347\n",
            "Epoch 203/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6467 - categorical_accuracy: 0.8151 - precision: 0.8759 - recall: 0.7474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6467 - categorical_accuracy: 0.8151 - precision: 0.8759 - recall: 0.7474 - val_loss: 0.7611 - val_categorical_accuracy: 0.7755 - val_precision: 0.8140 - val_recall: 0.7143\n",
            "Epoch 204/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6077 - categorical_accuracy: 0.8367 - precision: 0.8853 - recall: 0.7679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6077 - categorical_accuracy: 0.8367 - precision: 0.8853 - recall: 0.7679 - val_loss: 1.0055 - val_categorical_accuracy: 0.6327 - val_precision: 0.7179 - val_recall: 0.5714\n",
            "Epoch 205/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6303 - categorical_accuracy: 0.8074 - precision: 0.8603 - recall: 0.7462"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6303 - categorical_accuracy: 0.8074 - precision: 0.8603 - recall: 0.7462 - val_loss: 0.7514 - val_categorical_accuracy: 0.7653 - val_precision: 0.8235 - val_recall: 0.7143\n",
            "Epoch 206/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6031 - categorical_accuracy: 0.8406 - precision: 0.8846 - recall: 0.7819"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.6031 - categorical_accuracy: 0.8406 - precision: 0.8846 - recall: 0.7819 - val_loss: 0.7488 - val_categorical_accuracy: 0.7449 - val_precision: 0.8395 - val_recall: 0.6939\n",
            "Epoch 207/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6189 - categorical_accuracy: 0.8151 - precision: 0.8788 - recall: 0.7679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6189 - categorical_accuracy: 0.8151 - precision: 0.8788 - recall: 0.7679 - val_loss: 0.8001 - val_categorical_accuracy: 0.7551 - val_precision: 0.7978 - val_recall: 0.7245\n",
            "Epoch 208/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6133 - categorical_accuracy: 0.8202 - precision: 0.8774 - recall: 0.7666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.6133 - categorical_accuracy: 0.8202 - precision: 0.8774 - recall: 0.7666 - val_loss: 0.6323 - val_categorical_accuracy: 0.8163 - val_precision: 0.8837 - val_recall: 0.7755\n",
            "Epoch 209/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6144 - categorical_accuracy: 0.8176 - precision: 0.8654 - recall: 0.7628"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.6144 - categorical_accuracy: 0.8176 - precision: 0.8654 - recall: 0.7628 - val_loss: 0.9506 - val_categorical_accuracy: 0.6735 - val_precision: 0.7468 - val_recall: 0.6020\n",
            "Epoch 210/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6593 - categorical_accuracy: 0.8151 - precision: 0.8789 - recall: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6593 - categorical_accuracy: 0.8151 - precision: 0.8789 - recall: 0.7500 - val_loss: 0.9481 - val_categorical_accuracy: 0.6837 - val_precision: 0.7229 - val_recall: 0.6122\n",
            "Epoch 211/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6660 - categorical_accuracy: 0.7997 - precision: 0.8439 - recall: 0.7309"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6660 - categorical_accuracy: 0.7997 - precision: 0.8439 - recall: 0.7309 - val_loss: 0.7762 - val_categorical_accuracy: 0.7245 - val_precision: 0.7907 - val_recall: 0.6939\n",
            "Epoch 212/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6243 - categorical_accuracy: 0.8227 - precision: 0.8803 - recall: 0.7691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.6243 - categorical_accuracy: 0.8227 - precision: 0.8803 - recall: 0.7691 - val_loss: 0.8176 - val_categorical_accuracy: 0.7245 - val_precision: 0.7674 - val_recall: 0.6735\n",
            "Epoch 213/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5893 - categorical_accuracy: 0.8342 - precision: 0.8902 - recall: 0.7755"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5893 - categorical_accuracy: 0.8342 - precision: 0.8902 - recall: 0.7755 - val_loss: 0.7512 - val_categorical_accuracy: 0.7449 - val_precision: 0.8072 - val_recall: 0.6837\n",
            "Epoch 214/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5704 - categorical_accuracy: 0.8380 - precision: 0.8957 - recall: 0.7883"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.5704 - categorical_accuracy: 0.8380 - precision: 0.8957 - recall: 0.7883 - val_loss: 0.7995 - val_categorical_accuracy: 0.7755 - val_precision: 0.8312 - val_recall: 0.6531\n",
            "Epoch 215/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5567 - categorical_accuracy: 0.8431 - precision: 0.9069 - recall: 0.8074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.5567 - categorical_accuracy: 0.8431 - precision: 0.9069 - recall: 0.8074 - val_loss: 0.7181 - val_categorical_accuracy: 0.7755 - val_precision: 0.8554 - val_recall: 0.7245\n",
            "Epoch 216/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5643 - categorical_accuracy: 0.8380 - precision: 0.9001 - recall: 0.7819"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5643 - categorical_accuracy: 0.8380 - precision: 0.9001 - recall: 0.7819 - val_loss: 0.6826 - val_categorical_accuracy: 0.7959 - val_precision: 0.8721 - val_recall: 0.7653\n",
            "Epoch 217/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5697 - categorical_accuracy: 0.8508 - precision: 0.8984 - recall: 0.7781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5697 - categorical_accuracy: 0.8508 - precision: 0.8984 - recall: 0.7781 - val_loss: 0.7801 - val_categorical_accuracy: 0.7347 - val_precision: 0.8095 - val_recall: 0.6939\n",
            "Epoch 218/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5606 - categorical_accuracy: 0.8520 - precision: 0.8980 - recall: 0.7972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5606 - categorical_accuracy: 0.8520 - precision: 0.8980 - recall: 0.7972 - val_loss: 0.7491 - val_categorical_accuracy: 0.7449 - val_precision: 0.8046 - val_recall: 0.7143\n",
            "Epoch 219/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5497 - categorical_accuracy: 0.8431 - precision: 0.9120 - recall: 0.8061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5497 - categorical_accuracy: 0.8431 - precision: 0.9120 - recall: 0.8061 - val_loss: 0.7230 - val_categorical_accuracy: 0.7653 - val_precision: 0.8471 - val_recall: 0.7347\n",
            "Epoch 220/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5820 - categorical_accuracy: 0.8406 - precision: 0.8771 - recall: 0.7832"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5820 - categorical_accuracy: 0.8406 - precision: 0.8771 - recall: 0.7832 - val_loss: 0.9679 - val_categorical_accuracy: 0.7143 - val_precision: 0.7857 - val_recall: 0.6735\n",
            "Epoch 221/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5477 - categorical_accuracy: 0.8418 - precision: 0.9010 - recall: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5477 - categorical_accuracy: 0.8418 - precision: 0.9010 - recall: 0.8010 - val_loss: 0.7150 - val_categorical_accuracy: 0.7959 - val_precision: 0.8471 - val_recall: 0.7347\n",
            "Epoch 222/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5508 - categorical_accuracy: 0.8482 - precision: 0.8981 - recall: 0.7985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5508 - categorical_accuracy: 0.8482 - precision: 0.8981 - recall: 0.7985 - val_loss: 0.6972 - val_categorical_accuracy: 0.7857 - val_precision: 0.8929 - val_recall: 0.7653\n",
            "Epoch 223/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5555 - categorical_accuracy: 0.8533 - precision: 0.8990 - recall: 0.8061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5555 - categorical_accuracy: 0.8533 - precision: 0.8990 - recall: 0.8061 - val_loss: 0.8516 - val_categorical_accuracy: 0.7449 - val_precision: 0.7955 - val_recall: 0.7143\n",
            "Epoch 224/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5665 - categorical_accuracy: 0.8508 - precision: 0.9090 - recall: 0.8023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.5665 - categorical_accuracy: 0.8508 - precision: 0.9090 - recall: 0.8023 - val_loss: 1.2043 - val_categorical_accuracy: 0.6224 - val_precision: 0.6951 - val_recall: 0.5816\n",
            "Epoch 225/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5826 - categorical_accuracy: 0.8355 - precision: 0.8940 - recall: 0.7857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5826 - categorical_accuracy: 0.8355 - precision: 0.8940 - recall: 0.7857 - val_loss: 0.6554 - val_categorical_accuracy: 0.8265 - val_precision: 0.8941 - val_recall: 0.7755\n",
            "Epoch 226/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5588 - categorical_accuracy: 0.8482 - precision: 0.8895 - recall: 0.7908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5588 - categorical_accuracy: 0.8482 - precision: 0.8895 - recall: 0.7908 - val_loss: 0.7566 - val_categorical_accuracy: 0.7449 - val_precision: 0.7955 - val_recall: 0.7143\n",
            "Epoch 227/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5442 - categorical_accuracy: 0.8584 - precision: 0.9052 - recall: 0.8036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5442 - categorical_accuracy: 0.8584 - precision: 0.9052 - recall: 0.8036 - val_loss: 0.6926 - val_categorical_accuracy: 0.7653 - val_precision: 0.7889 - val_recall: 0.7245\n",
            "Epoch 228/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5273 - categorical_accuracy: 0.8610 - precision: 0.9034 - recall: 0.8112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5273 - categorical_accuracy: 0.8610 - precision: 0.9034 - recall: 0.8112 - val_loss: 0.7474 - val_categorical_accuracy: 0.7347 - val_precision: 0.8333 - val_recall: 0.7143\n",
            "Epoch 229/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5265 - categorical_accuracy: 0.8571 - precision: 0.9046 - recall: 0.7985"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.5265 - categorical_accuracy: 0.8571 - precision: 0.9046 - recall: 0.7985 - val_loss: 0.7296 - val_categorical_accuracy: 0.7857 - val_precision: 0.8353 - val_recall: 0.7245\n",
            "Epoch 230/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5429 - categorical_accuracy: 0.8457 - precision: 0.8999 - recall: 0.8023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5429 - categorical_accuracy: 0.8457 - precision: 0.8999 - recall: 0.8023 - val_loss: 0.6766 - val_categorical_accuracy: 0.7857 - val_precision: 0.8488 - val_recall: 0.7449\n",
            "Epoch 231/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5469 - categorical_accuracy: 0.8457 - precision: 0.8944 - recall: 0.7997"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5469 - categorical_accuracy: 0.8457 - precision: 0.8944 - recall: 0.7997 - val_loss: 0.6364 - val_categorical_accuracy: 0.8061 - val_precision: 0.9036 - val_recall: 0.7653\n",
            "Epoch 232/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5322 - categorical_accuracy: 0.8661 - precision: 0.9018 - recall: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5322 - categorical_accuracy: 0.8661 - precision: 0.9018 - recall: 0.8087 - val_loss: 0.6251 - val_categorical_accuracy: 0.8469 - val_precision: 0.8977 - val_recall: 0.8061\n",
            "Epoch 233/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5365 - categorical_accuracy: 0.8457 - precision: 0.9004 - recall: 0.8074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5365 - categorical_accuracy: 0.8457 - precision: 0.9004 - recall: 0.8074 - val_loss: 0.6786 - val_categorical_accuracy: 0.7959 - val_precision: 0.8372 - val_recall: 0.7347\n",
            "Epoch 234/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5189 - categorical_accuracy: 0.8495 - precision: 0.9023 - recall: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5189 - categorical_accuracy: 0.8495 - precision: 0.9023 - recall: 0.8010 - val_loss: 0.6437 - val_categorical_accuracy: 0.8265 - val_precision: 0.8916 - val_recall: 0.7551\n",
            "Epoch 235/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5448 - categorical_accuracy: 0.8495 - precision: 0.9022 - recall: 0.7883"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5448 - categorical_accuracy: 0.8495 - precision: 0.9022 - recall: 0.7883 - val_loss: 0.7250 - val_categorical_accuracy: 0.7653 - val_precision: 0.8182 - val_recall: 0.7347\n",
            "Epoch 236/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5776 - categorical_accuracy: 0.8316 - precision: 0.8732 - recall: 0.7819"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5776 - categorical_accuracy: 0.8316 - precision: 0.8732 - recall: 0.7819 - val_loss: 0.6969 - val_categorical_accuracy: 0.7857 - val_precision: 0.8675 - val_recall: 0.7347\n",
            "Epoch 237/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5727 - categorical_accuracy: 0.8329 - precision: 0.8777 - recall: 0.7870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.5727 - categorical_accuracy: 0.8329 - precision: 0.8777 - recall: 0.7870 - val_loss: 0.7744 - val_categorical_accuracy: 0.7347 - val_precision: 0.8256 - val_recall: 0.7245\n",
            "Epoch 238/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5722 - categorical_accuracy: 0.8304 - precision: 0.8757 - recall: 0.7908"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 166ms/step - loss: 0.5722 - categorical_accuracy: 0.8304 - precision: 0.8757 - recall: 0.7908 - val_loss: 0.7646 - val_categorical_accuracy: 0.7551 - val_precision: 0.7955 - val_recall: 0.7143\n",
            "Epoch 239/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5588 - categorical_accuracy: 0.8342 - precision: 0.8876 - recall: 0.7857"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 160ms/step - loss: 0.5588 - categorical_accuracy: 0.8342 - precision: 0.8876 - recall: 0.7857 - val_loss: 0.8880 - val_categorical_accuracy: 0.6735 - val_precision: 0.7561 - val_recall: 0.6327\n",
            "Epoch 240/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5310 - categorical_accuracy: 0.8610 - precision: 0.9015 - recall: 0.8176"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 113ms/step - loss: 0.5310 - categorical_accuracy: 0.8610 - precision: 0.9015 - recall: 0.8176 - val_loss: 0.8023 - val_categorical_accuracy: 0.7857 - val_precision: 0.7955 - val_recall: 0.7143\n",
            "Epoch 241/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5303 - categorical_accuracy: 0.8571 - precision: 0.9018 - recall: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5303 - categorical_accuracy: 0.8571 - precision: 0.9018 - recall: 0.8087 - val_loss: 0.7284 - val_categorical_accuracy: 0.7653 - val_precision: 0.8488 - val_recall: 0.7449\n",
            "Epoch 242/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5220 - categorical_accuracy: 0.8520 - precision: 0.9021 - recall: 0.8112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5220 - categorical_accuracy: 0.8520 - precision: 0.9021 - recall: 0.8112 - val_loss: 0.6815 - val_categorical_accuracy: 0.7959 - val_precision: 0.8659 - val_recall: 0.7245\n",
            "Epoch 243/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5373 - categorical_accuracy: 0.8508 - precision: 0.8983 - recall: 0.8112"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5373 - categorical_accuracy: 0.8508 - precision: 0.8983 - recall: 0.8112 - val_loss: 1.0280 - val_categorical_accuracy: 0.6633 - val_precision: 0.7011 - val_recall: 0.6224\n",
            "Epoch 244/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.6072 - categorical_accuracy: 0.8214 - precision: 0.8712 - recall: 0.7679"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.6072 - categorical_accuracy: 0.8214 - precision: 0.8712 - recall: 0.7679 - val_loss: 0.7278 - val_categorical_accuracy: 0.7653 - val_precision: 0.8090 - val_recall: 0.7347\n",
            "Epoch 245/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5354 - categorical_accuracy: 0.8342 - precision: 0.8897 - recall: 0.8023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5354 - categorical_accuracy: 0.8342 - precision: 0.8897 - recall: 0.8023 - val_loss: 0.6787 - val_categorical_accuracy: 0.7857 - val_precision: 0.8372 - val_recall: 0.7347\n",
            "Epoch 246/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5108 - categorical_accuracy: 0.8571 - precision: 0.9058 - recall: 0.8099"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5108 - categorical_accuracy: 0.8571 - precision: 0.9058 - recall: 0.8099 - val_loss: 0.7056 - val_categorical_accuracy: 0.8163 - val_precision: 0.8588 - val_recall: 0.7449\n",
            "Epoch 247/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5230 - categorical_accuracy: 0.8444 - precision: 0.8898 - recall: 0.7934"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5230 - categorical_accuracy: 0.8444 - precision: 0.8898 - recall: 0.7934 - val_loss: 0.6189 - val_categorical_accuracy: 0.8367 - val_precision: 0.8824 - val_recall: 0.7653\n",
            "Epoch 248/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4859 - categorical_accuracy: 0.8635 - precision: 0.9229 - recall: 0.8240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4859 - categorical_accuracy: 0.8635 - precision: 0.9229 - recall: 0.8240 - val_loss: 0.9444 - val_categorical_accuracy: 0.7143 - val_precision: 0.7529 - val_recall: 0.6531\n",
            "Epoch 249/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5159 - categorical_accuracy: 0.8597 - precision: 0.9135 - recall: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.5159 - categorical_accuracy: 0.8597 - precision: 0.9135 - recall: 0.8087 - val_loss: 0.6670 - val_categorical_accuracy: 0.7755 - val_precision: 0.8256 - val_recall: 0.7245\n",
            "Epoch 250/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.8763 - precision: 0.9098 - recall: 0.8367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4735 - categorical_accuracy: 0.8763 - precision: 0.9098 - recall: 0.8367 - val_loss: 0.7205 - val_categorical_accuracy: 0.7755 - val_precision: 0.8256 - val_recall: 0.7245\n",
            "Epoch 251/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5007 - categorical_accuracy: 0.8712 - precision: 0.9020 - recall: 0.8214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5007 - categorical_accuracy: 0.8712 - precision: 0.9020 - recall: 0.8214 - val_loss: 0.9530 - val_categorical_accuracy: 0.7041 - val_precision: 0.7470 - val_recall: 0.6327\n",
            "Epoch 252/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5418 - categorical_accuracy: 0.8406 - precision: 0.8895 - recall: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5418 - categorical_accuracy: 0.8406 - precision: 0.8895 - recall: 0.8010 - val_loss: 0.8493 - val_categorical_accuracy: 0.7041 - val_precision: 0.7674 - val_recall: 0.6735\n",
            "Epoch 253/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5201 - categorical_accuracy: 0.8508 - precision: 0.9040 - recall: 0.8163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5201 - categorical_accuracy: 0.8508 - precision: 0.9040 - recall: 0.8163 - val_loss: 0.6689 - val_categorical_accuracy: 0.7857 - val_precision: 0.8605 - val_recall: 0.7551\n",
            "Epoch 254/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5173 - categorical_accuracy: 0.8469 - precision: 0.8942 - recall: 0.8189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5173 - categorical_accuracy: 0.8469 - precision: 0.8942 - recall: 0.8189 - val_loss: 0.8139 - val_categorical_accuracy: 0.7653 - val_precision: 0.8202 - val_recall: 0.7449\n",
            "Epoch 255/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5583 - categorical_accuracy: 0.8291 - precision: 0.8840 - recall: 0.7972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5583 - categorical_accuracy: 0.8291 - precision: 0.8840 - recall: 0.7972 - val_loss: 0.6850 - val_categorical_accuracy: 0.8061 - val_precision: 0.8588 - val_recall: 0.7449\n",
            "Epoch 256/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5157 - categorical_accuracy: 0.8533 - precision: 0.8980 - recall: 0.7972"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5157 - categorical_accuracy: 0.8533 - precision: 0.8980 - recall: 0.7972 - val_loss: 0.6969 - val_categorical_accuracy: 0.8163 - val_precision: 0.8736 - val_recall: 0.7755\n",
            "Epoch 257/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4960 - categorical_accuracy: 0.8610 - precision: 0.8968 - recall: 0.8316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4960 - categorical_accuracy: 0.8610 - precision: 0.8968 - recall: 0.8316 - val_loss: 0.6601 - val_categorical_accuracy: 0.8061 - val_precision: 0.8810 - val_recall: 0.7551\n",
            "Epoch 258/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5066 - categorical_accuracy: 0.8661 - precision: 0.9056 - recall: 0.8202"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5066 - categorical_accuracy: 0.8661 - precision: 0.9056 - recall: 0.8202 - val_loss: 0.9172 - val_categorical_accuracy: 0.6735 - val_precision: 0.7033 - val_recall: 0.6531\n",
            "Epoch 259/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5470 - categorical_accuracy: 0.8355 - precision: 0.8796 - recall: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5470 - categorical_accuracy: 0.8355 - precision: 0.8796 - recall: 0.8010 - val_loss: 0.8479 - val_categorical_accuracy: 0.7449 - val_precision: 0.8095 - val_recall: 0.6939\n",
            "Epoch 260/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4880 - categorical_accuracy: 0.8661 - precision: 0.9066 - recall: 0.8176"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4880 - categorical_accuracy: 0.8661 - precision: 0.9066 - recall: 0.8176 - val_loss: 0.7504 - val_categorical_accuracy: 0.7347 - val_precision: 0.7882 - val_recall: 0.6837\n",
            "Epoch 261/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5443 - categorical_accuracy: 0.8380 - precision: 0.8837 - recall: 0.7946"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.5443 - categorical_accuracy: 0.8380 - precision: 0.8837 - recall: 0.7946 - val_loss: 0.8674 - val_categorical_accuracy: 0.7143 - val_precision: 0.7765 - val_recall: 0.6735\n",
            "Epoch 262/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5301 - categorical_accuracy: 0.8533 - precision: 0.9011 - recall: 0.8023"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.5301 - categorical_accuracy: 0.8533 - precision: 0.9011 - recall: 0.8023 - val_loss: 1.0400 - val_categorical_accuracy: 0.6327 - val_precision: 0.6782 - val_recall: 0.6020\n",
            "Epoch 263/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4996 - categorical_accuracy: 0.8712 - precision: 0.9030 - recall: 0.8316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4996 - categorical_accuracy: 0.8712 - precision: 0.9030 - recall: 0.8316 - val_loss: 0.7213 - val_categorical_accuracy: 0.8163 - val_precision: 0.8471 - val_recall: 0.7347\n",
            "Epoch 264/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4789 - categorical_accuracy: 0.8750 - precision: 0.9107 - recall: 0.8329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4789 - categorical_accuracy: 0.8750 - precision: 0.9107 - recall: 0.8329 - val_loss: 0.7591 - val_categorical_accuracy: 0.7653 - val_precision: 0.8046 - val_recall: 0.7143\n",
            "Epoch 265/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4926 - categorical_accuracy: 0.8673 - precision: 0.9044 - recall: 0.8329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4926 - categorical_accuracy: 0.8673 - precision: 0.9044 - recall: 0.8329 - val_loss: 0.7033 - val_categorical_accuracy: 0.8061 - val_precision: 0.8427 - val_recall: 0.7653\n",
            "Epoch 266/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5011 - categorical_accuracy: 0.8622 - precision: 0.9000 - recall: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5011 - categorical_accuracy: 0.8622 - precision: 0.9000 - recall: 0.8265 - val_loss: 0.7307 - val_categorical_accuracy: 0.7551 - val_precision: 0.8537 - val_recall: 0.7143\n",
            "Epoch 267/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5073 - categorical_accuracy: 0.8508 - precision: 0.9011 - recall: 0.8138"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.5073 - categorical_accuracy: 0.8508 - precision: 0.9011 - recall: 0.8138 - val_loss: 0.7229 - val_categorical_accuracy: 0.7551 - val_precision: 0.8276 - val_recall: 0.7347\n",
            "Epoch 268/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4919 - categorical_accuracy: 0.8673 - precision: 0.9127 - recall: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4919 - categorical_accuracy: 0.8673 - precision: 0.9127 - recall: 0.8265 - val_loss: 0.6641 - val_categorical_accuracy: 0.8163 - val_precision: 0.8132 - val_recall: 0.7551\n",
            "Epoch 269/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4853 - categorical_accuracy: 0.8686 - precision: 0.9088 - recall: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4853 - categorical_accuracy: 0.8686 - precision: 0.9088 - recall: 0.8265 - val_loss: 0.6597 - val_categorical_accuracy: 0.8061 - val_precision: 0.8539 - val_recall: 0.7755\n",
            "Epoch 270/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4893 - categorical_accuracy: 0.8648 - precision: 0.9069 - recall: 0.8329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4893 - categorical_accuracy: 0.8648 - precision: 0.9069 - recall: 0.8329 - val_loss: 0.6662 - val_categorical_accuracy: 0.7959 - val_precision: 0.8605 - val_recall: 0.7551\n",
            "Epoch 271/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4831 - categorical_accuracy: 0.8610 - precision: 0.9017 - recall: 0.8304"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.4831 - categorical_accuracy: 0.8610 - precision: 0.9017 - recall: 0.8304 - val_loss: 0.7512 - val_categorical_accuracy: 0.7551 - val_precision: 0.7907 - val_recall: 0.6939\n",
            "Epoch 272/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4887 - categorical_accuracy: 0.8661 - precision: 0.9038 - recall: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4887 - categorical_accuracy: 0.8661 - precision: 0.9038 - recall: 0.8265 - val_loss: 0.9212 - val_categorical_accuracy: 0.6531 - val_precision: 0.7000 - val_recall: 0.6429\n",
            "Epoch 273/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5030 - categorical_accuracy: 0.8584 - precision: 0.9008 - recall: 0.8227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5030 - categorical_accuracy: 0.8584 - precision: 0.9008 - recall: 0.8227 - val_loss: 0.6756 - val_categorical_accuracy: 0.8061 - val_precision: 0.8556 - val_recall: 0.7857\n",
            "Epoch 274/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5007 - categorical_accuracy: 0.8495 - precision: 0.8911 - recall: 0.8036"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.5007 - categorical_accuracy: 0.8495 - precision: 0.8911 - recall: 0.8036 - val_loss: 0.9415 - val_categorical_accuracy: 0.6531 - val_precision: 0.6966 - val_recall: 0.6327\n",
            "Epoch 275/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5216 - categorical_accuracy: 0.8533 - precision: 0.9025 - recall: 0.8151"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.5216 - categorical_accuracy: 0.8533 - precision: 0.9025 - recall: 0.8151 - val_loss: 0.7843 - val_categorical_accuracy: 0.7551 - val_precision: 0.7978 - val_recall: 0.7245\n",
            "Epoch 276/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.8737 - precision: 0.9093 - recall: 0.8316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4758 - categorical_accuracy: 0.8737 - precision: 0.9093 - recall: 0.8316 - val_loss: 0.6692 - val_categorical_accuracy: 0.7857 - val_precision: 0.8488 - val_recall: 0.7449\n",
            "Epoch 277/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4504 - categorical_accuracy: 0.8776 - precision: 0.9229 - recall: 0.8393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4504 - categorical_accuracy: 0.8776 - precision: 0.9229 - recall: 0.8393 - val_loss: 0.6674 - val_categorical_accuracy: 0.7653 - val_precision: 0.8276 - val_recall: 0.7347\n",
            "Epoch 278/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4644 - categorical_accuracy: 0.8737 - precision: 0.9114 - recall: 0.8393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4644 - categorical_accuracy: 0.8737 - precision: 0.9114 - recall: 0.8393 - val_loss: 0.6739 - val_categorical_accuracy: 0.7857 - val_precision: 0.8276 - val_recall: 0.7347\n",
            "Epoch 279/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5236 - categorical_accuracy: 0.8584 - precision: 0.8994 - recall: 0.8214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.5236 - categorical_accuracy: 0.8584 - precision: 0.8994 - recall: 0.8214 - val_loss: 0.7026 - val_categorical_accuracy: 0.7755 - val_precision: 0.8353 - val_recall: 0.7245\n",
            "Epoch 280/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4597 - categorical_accuracy: 0.8724 - precision: 0.9116 - recall: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4597 - categorical_accuracy: 0.8724 - precision: 0.9116 - recall: 0.8418 - val_loss: 0.5903 - val_categorical_accuracy: 0.8367 - val_precision: 0.8864 - val_recall: 0.7959\n",
            "Epoch 281/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4539 - categorical_accuracy: 0.8827 - precision: 0.9141 - recall: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4539 - categorical_accuracy: 0.8827 - precision: 0.9141 - recall: 0.8418 - val_loss: 0.6239 - val_categorical_accuracy: 0.8265 - val_precision: 0.8864 - val_recall: 0.7959\n",
            "Epoch 282/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4705 - categorical_accuracy: 0.8776 - precision: 0.9241 - recall: 0.8380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4705 - categorical_accuracy: 0.8776 - precision: 0.9241 - recall: 0.8380 - val_loss: 0.7098 - val_categorical_accuracy: 0.8061 - val_precision: 0.8391 - val_recall: 0.7449\n",
            "Epoch 283/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4647 - categorical_accuracy: 0.8724 - precision: 0.9004 - recall: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4647 - categorical_accuracy: 0.8724 - precision: 0.9004 - recall: 0.8418 - val_loss: 0.6893 - val_categorical_accuracy: 0.7449 - val_precision: 0.8161 - val_recall: 0.7245\n",
            "Epoch 284/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4471 - categorical_accuracy: 0.8814 - precision: 0.9211 - recall: 0.8482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4471 - categorical_accuracy: 0.8814 - precision: 0.9211 - recall: 0.8482 - val_loss: 0.7454 - val_categorical_accuracy: 0.7449 - val_precision: 0.8256 - val_recall: 0.7245\n",
            "Epoch 285/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4661 - categorical_accuracy: 0.8763 - precision: 0.9181 - recall: 0.8431"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4661 - categorical_accuracy: 0.8763 - precision: 0.9181 - recall: 0.8431 - val_loss: 0.7169 - val_categorical_accuracy: 0.7857 - val_precision: 0.8506 - val_recall: 0.7551\n",
            "Epoch 286/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4524 - categorical_accuracy: 0.8827 - precision: 0.9190 - recall: 0.8393"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4524 - categorical_accuracy: 0.8827 - precision: 0.9190 - recall: 0.8393 - val_loss: 0.7394 - val_categorical_accuracy: 0.7755 - val_precision: 0.8161 - val_recall: 0.7245\n",
            "Epoch 287/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4735 - categorical_accuracy: 0.8686 - precision: 0.9091 - recall: 0.8291"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4735 - categorical_accuracy: 0.8686 - precision: 0.9091 - recall: 0.8291 - val_loss: 0.6584 - val_categorical_accuracy: 0.8265 - val_precision: 0.8750 - val_recall: 0.7857\n",
            "Epoch 288/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4911 - categorical_accuracy: 0.8584 - precision: 0.9025 - recall: 0.8151"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4911 - categorical_accuracy: 0.8584 - precision: 0.9025 - recall: 0.8151 - val_loss: 0.8052 - val_categorical_accuracy: 0.7245 - val_precision: 0.7727 - val_recall: 0.6939\n",
            "Epoch 289/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4908 - categorical_accuracy: 0.8661 - precision: 0.9046 - recall: 0.8227"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4908 - categorical_accuracy: 0.8661 - precision: 0.9046 - recall: 0.8227 - val_loss: 0.7032 - val_categorical_accuracy: 0.7857 - val_precision: 0.8152 - val_recall: 0.7653\n",
            "Epoch 290/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4836 - categorical_accuracy: 0.8673 - precision: 0.9144 - recall: 0.8316"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4836 - categorical_accuracy: 0.8673 - precision: 0.9144 - recall: 0.8316 - val_loss: 0.6600 - val_categorical_accuracy: 0.7959 - val_precision: 0.8261 - val_recall: 0.7755\n",
            "Epoch 291/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4556 - categorical_accuracy: 0.8941 - precision: 0.9193 - recall: 0.8571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4556 - categorical_accuracy: 0.8941 - precision: 0.9193 - recall: 0.8571 - val_loss: 0.7664 - val_categorical_accuracy: 0.7857 - val_precision: 0.8022 - val_recall: 0.7449\n",
            "Epoch 292/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4730 - categorical_accuracy: 0.8673 - precision: 0.9079 - recall: 0.8304"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.4730 - categorical_accuracy: 0.8673 - precision: 0.9079 - recall: 0.8304 - val_loss: 0.9889 - val_categorical_accuracy: 0.6122 - val_precision: 0.6705 - val_recall: 0.6020\n",
            "Epoch 293/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4411 - categorical_accuracy: 0.8839 - precision: 0.9147 - recall: 0.8482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4411 - categorical_accuracy: 0.8839 - precision: 0.9147 - recall: 0.8482 - val_loss: 0.6649 - val_categorical_accuracy: 0.8061 - val_precision: 0.8636 - val_recall: 0.7755\n",
            "Epoch 294/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4198 - categorical_accuracy: 0.8890 - precision: 0.9227 - recall: 0.8520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4198 - categorical_accuracy: 0.8890 - precision: 0.9227 - recall: 0.8520 - val_loss: 0.6018 - val_categorical_accuracy: 0.8163 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 295/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4665 - categorical_accuracy: 0.8737 - precision: 0.9081 - recall: 0.8444"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4665 - categorical_accuracy: 0.8737 - precision: 0.9081 - recall: 0.8444 - val_loss: 0.7484 - val_categorical_accuracy: 0.7755 - val_precision: 0.8000 - val_recall: 0.7347\n",
            "Epoch 296/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4599 - categorical_accuracy: 0.8724 - precision: 0.9160 - recall: 0.8482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4599 - categorical_accuracy: 0.8724 - precision: 0.9160 - recall: 0.8482 - val_loss: 0.6682 - val_categorical_accuracy: 0.7857 - val_precision: 0.8172 - val_recall: 0.7755\n",
            "Epoch 297/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4758 - categorical_accuracy: 0.8546 - precision: 0.8957 - recall: 0.8214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4758 - categorical_accuracy: 0.8546 - precision: 0.8957 - recall: 0.8214 - val_loss: 0.6357 - val_categorical_accuracy: 0.8367 - val_precision: 0.8778 - val_recall: 0.8061\n",
            "Epoch 298/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4719 - categorical_accuracy: 0.8699 - precision: 0.9036 - recall: 0.8367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4719 - categorical_accuracy: 0.8699 - precision: 0.9036 - recall: 0.8367 - val_loss: 1.1324 - val_categorical_accuracy: 0.6327 - val_precision: 0.6452 - val_recall: 0.6122\n",
            "Epoch 299/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4529 - categorical_accuracy: 0.8750 - precision: 0.9175 - recall: 0.8367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4529 - categorical_accuracy: 0.8750 - precision: 0.9175 - recall: 0.8367 - val_loss: 0.7556 - val_categorical_accuracy: 0.7653 - val_precision: 0.8095 - val_recall: 0.6939\n",
            "Epoch 300/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4585 - categorical_accuracy: 0.8686 - precision: 0.9121 - recall: 0.8342"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4585 - categorical_accuracy: 0.8686 - precision: 0.9121 - recall: 0.8342 - val_loss: 0.8092 - val_categorical_accuracy: 0.7041 - val_precision: 0.7640 - val_recall: 0.6939\n",
            "Epoch 301/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4548 - categorical_accuracy: 0.8839 - precision: 0.9199 - recall: 0.8495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4548 - categorical_accuracy: 0.8839 - precision: 0.9199 - recall: 0.8495 - val_loss: 0.6092 - val_categorical_accuracy: 0.8571 - val_precision: 0.8889 - val_recall: 0.8163\n",
            "Epoch 302/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4468 - categorical_accuracy: 0.8878 - precision: 0.9159 - recall: 0.8469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4468 - categorical_accuracy: 0.8878 - precision: 0.9159 - recall: 0.8469 - val_loss: 0.6412 - val_categorical_accuracy: 0.8163 - val_precision: 0.8556 - val_recall: 0.7857\n",
            "Epoch 303/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4680 - categorical_accuracy: 0.8661 - precision: 0.9025 - recall: 0.8380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.4680 - categorical_accuracy: 0.8661 - precision: 0.9025 - recall: 0.8380 - val_loss: 0.8736 - val_categorical_accuracy: 0.7551 - val_precision: 0.7907 - val_recall: 0.6939\n",
            "Epoch 304/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4564 - categorical_accuracy: 0.8724 - precision: 0.9077 - recall: 0.8406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 0.4564 - categorical_accuracy: 0.8724 - precision: 0.9077 - recall: 0.8406 - val_loss: 0.9708 - val_categorical_accuracy: 0.6837 - val_precision: 0.7444 - val_recall: 0.6837\n",
            "Epoch 305/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4261 - categorical_accuracy: 0.8941 - precision: 0.9278 - recall: 0.8520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4261 - categorical_accuracy: 0.8941 - precision: 0.9278 - recall: 0.8520 - val_loss: 0.6798 - val_categorical_accuracy: 0.7857 - val_precision: 0.8427 - val_recall: 0.7653\n",
            "Epoch 306/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4098 - categorical_accuracy: 0.8992 - precision: 0.9275 - recall: 0.8648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4098 - categorical_accuracy: 0.8992 - precision: 0.9275 - recall: 0.8648 - val_loss: 0.6054 - val_categorical_accuracy: 0.8469 - val_precision: 0.8889 - val_recall: 0.8163\n",
            "Epoch 307/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4077 - categorical_accuracy: 0.9031 - precision: 0.9365 - recall: 0.8648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4077 - categorical_accuracy: 0.9031 - precision: 0.9365 - recall: 0.8648 - val_loss: 0.6012 - val_categorical_accuracy: 0.8265 - val_precision: 0.8889 - val_recall: 0.8163\n",
            "Epoch 308/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4238 - categorical_accuracy: 0.8929 - precision: 0.9184 - recall: 0.8610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4238 - categorical_accuracy: 0.8929 - precision: 0.9184 - recall: 0.8610 - val_loss: 0.6391 - val_categorical_accuracy: 0.8061 - val_precision: 0.8539 - val_recall: 0.7755\n",
            "Epoch 309/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4573 - categorical_accuracy: 0.8788 - precision: 0.9091 - recall: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4573 - categorical_accuracy: 0.8788 - precision: 0.9091 - recall: 0.8418 - val_loss: 0.6220 - val_categorical_accuracy: 0.8367 - val_precision: 0.8851 - val_recall: 0.7857\n",
            "Epoch 310/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4317 - categorical_accuracy: 0.8827 - precision: 0.9132 - recall: 0.8457"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.4317 - categorical_accuracy: 0.8827 - precision: 0.9132 - recall: 0.8457 - val_loss: 0.8129 - val_categorical_accuracy: 0.7449 - val_precision: 0.7931 - val_recall: 0.7041\n",
            "Epoch 311/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4274 - categorical_accuracy: 0.8941 - precision: 0.9191 - recall: 0.8546"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4274 - categorical_accuracy: 0.8941 - precision: 0.9191 - recall: 0.8546 - val_loss: 1.0289 - val_categorical_accuracy: 0.6939 - val_precision: 0.7303 - val_recall: 0.6633\n",
            "Epoch 312/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5053 - categorical_accuracy: 0.8444 - precision: 0.8877 - recall: 0.8163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.5053 - categorical_accuracy: 0.8444 - precision: 0.8877 - recall: 0.8163 - val_loss: 0.7725 - val_categorical_accuracy: 0.7551 - val_precision: 0.8068 - val_recall: 0.7245\n",
            "Epoch 313/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4525 - categorical_accuracy: 0.8763 - precision: 0.9066 - recall: 0.8418"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4525 - categorical_accuracy: 0.8763 - precision: 0.9066 - recall: 0.8418 - val_loss: 0.6862 - val_categorical_accuracy: 0.7857 - val_precision: 0.8315 - val_recall: 0.7551\n",
            "Epoch 314/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4992 - categorical_accuracy: 0.8546 - precision: 0.8932 - recall: 0.8214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.4992 - categorical_accuracy: 0.8546 - precision: 0.8932 - recall: 0.8214 - val_loss: 0.6833 - val_categorical_accuracy: 0.8469 - val_precision: 0.8556 - val_recall: 0.7857\n",
            "Epoch 315/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4280 - categorical_accuracy: 0.8890 - precision: 0.9200 - recall: 0.8508"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.4280 - categorical_accuracy: 0.8890 - precision: 0.9200 - recall: 0.8508 - val_loss: 0.6265 - val_categorical_accuracy: 0.8265 - val_precision: 0.8681 - val_recall: 0.8061\n",
            "Epoch 316/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4759 - categorical_accuracy: 0.8648 - precision: 0.9000 - recall: 0.8380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4759 - categorical_accuracy: 0.8648 - precision: 0.9000 - recall: 0.8380 - val_loss: 0.8382 - val_categorical_accuracy: 0.7245 - val_precision: 0.7778 - val_recall: 0.7143\n",
            "Epoch 317/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4583 - categorical_accuracy: 0.8814 - precision: 0.9135 - recall: 0.8482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4583 - categorical_accuracy: 0.8814 - precision: 0.9135 - recall: 0.8482 - val_loss: 0.6124 - val_categorical_accuracy: 0.7959 - val_precision: 0.8352 - val_recall: 0.7755\n",
            "Epoch 318/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4775 - categorical_accuracy: 0.8546 - precision: 0.8938 - recall: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4775 - categorical_accuracy: 0.8546 - precision: 0.8938 - recall: 0.8265 - val_loss: 0.5725 - val_categorical_accuracy: 0.8571 - val_precision: 0.8901 - val_recall: 0.8265\n",
            "Epoch 319/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4217 - categorical_accuracy: 0.8967 - precision: 0.9324 - recall: 0.8622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4217 - categorical_accuracy: 0.8967 - precision: 0.9324 - recall: 0.8622 - val_loss: 0.6769 - val_categorical_accuracy: 0.8265 - val_precision: 0.8636 - val_recall: 0.7755\n",
            "Epoch 320/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.5833 - categorical_accuracy: 0.8112 - precision: 0.8542 - recall: 0.7844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.5833 - categorical_accuracy: 0.8112 - precision: 0.8542 - recall: 0.7844 - val_loss: 1.0700 - val_categorical_accuracy: 0.6531 - val_precision: 0.6941 - val_recall: 0.6020\n",
            "Epoch 321/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4673 - categorical_accuracy: 0.8673 - precision: 0.9069 - recall: 0.8329"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.4673 - categorical_accuracy: 0.8673 - precision: 0.9069 - recall: 0.8329 - val_loss: 0.6030 - val_categorical_accuracy: 0.8265 - val_precision: 0.8750 - val_recall: 0.7857\n",
            "Epoch 322/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4130 - categorical_accuracy: 0.8916 - precision: 0.9263 - recall: 0.8495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4130 - categorical_accuracy: 0.8916 - precision: 0.9263 - recall: 0.8495 - val_loss: 0.5899 - val_categorical_accuracy: 0.8571 - val_precision: 0.9070 - val_recall: 0.7959\n",
            "Epoch 323/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4025 - categorical_accuracy: 0.8954 - precision: 0.9403 - recall: 0.8635"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.4025 - categorical_accuracy: 0.8954 - precision: 0.9403 - recall: 0.8635 - val_loss: 0.5994 - val_categorical_accuracy: 0.8367 - val_precision: 0.8681 - val_recall: 0.8061\n",
            "Epoch 324/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4162 - categorical_accuracy: 0.8903 - precision: 0.9183 - recall: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.4162 - categorical_accuracy: 0.8903 - precision: 0.9183 - recall: 0.8597 - val_loss: 0.6100 - val_categorical_accuracy: 0.8265 - val_precision: 0.8791 - val_recall: 0.8163\n",
            "Epoch 325/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4174 - categorical_accuracy: 0.8967 - precision: 0.9238 - recall: 0.8661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4174 - categorical_accuracy: 0.8967 - precision: 0.9238 - recall: 0.8661 - val_loss: 0.7246 - val_categorical_accuracy: 0.7755 - val_precision: 0.8202 - val_recall: 0.7449\n",
            "Epoch 326/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4203 - categorical_accuracy: 0.8890 - precision: 0.9185 - recall: 0.8622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4203 - categorical_accuracy: 0.8890 - precision: 0.9185 - recall: 0.8622 - val_loss: 0.5836 - val_categorical_accuracy: 0.8469 - val_precision: 0.8977 - val_recall: 0.8061\n",
            "Epoch 327/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4516 - categorical_accuracy: 0.8686 - precision: 0.9010 - recall: 0.8355"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4516 - categorical_accuracy: 0.8686 - precision: 0.9010 - recall: 0.8355 - val_loss: 0.5624 - val_categorical_accuracy: 0.8571 - val_precision: 0.9080 - val_recall: 0.8061\n",
            "Epoch 328/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3915 - categorical_accuracy: 0.8954 - precision: 0.9298 - recall: 0.8622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3915 - categorical_accuracy: 0.8954 - precision: 0.9298 - recall: 0.8622 - val_loss: 0.5767 - val_categorical_accuracy: 0.8469 - val_precision: 0.9111 - val_recall: 0.8367\n",
            "Epoch 329/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4082 - categorical_accuracy: 0.8980 - precision: 0.9167 - recall: 0.8559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.4082 - categorical_accuracy: 0.8980 - precision: 0.9167 - recall: 0.8559 - val_loss: 0.7004 - val_categorical_accuracy: 0.8163 - val_precision: 0.8539 - val_recall: 0.7755\n",
            "Epoch 330/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4171 - categorical_accuracy: 0.8878 - precision: 0.9256 - recall: 0.8571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4171 - categorical_accuracy: 0.8878 - precision: 0.9256 - recall: 0.8571 - val_loss: 0.7299 - val_categorical_accuracy: 0.7959 - val_precision: 0.8333 - val_recall: 0.7653\n",
            "Epoch 331/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4175 - categorical_accuracy: 0.8941 - precision: 0.9195 - recall: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4175 - categorical_accuracy: 0.8941 - precision: 0.9195 - recall: 0.8597 - val_loss: 0.5682 - val_categorical_accuracy: 0.8673 - val_precision: 0.9000 - val_recall: 0.8265\n",
            "Epoch 332/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4012 - categorical_accuracy: 0.8878 - precision: 0.9239 - recall: 0.8673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4012 - categorical_accuracy: 0.8878 - precision: 0.9239 - recall: 0.8673 - val_loss: 0.5265 - val_categorical_accuracy: 0.8776 - val_precision: 0.8913 - val_recall: 0.8367\n",
            "Epoch 333/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3903 - categorical_accuracy: 0.8992 - precision: 0.9401 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3903 - categorical_accuracy: 0.8992 - precision: 0.9401 - recall: 0.8801 - val_loss: 0.5622 - val_categorical_accuracy: 0.8469 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 334/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3719 - categorical_accuracy: 0.9043 - precision: 0.9376 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.3719 - categorical_accuracy: 0.9043 - precision: 0.9376 - recall: 0.8814 - val_loss: 0.6936 - val_categorical_accuracy: 0.7959 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 335/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4422 - categorical_accuracy: 0.8776 - precision: 0.9138 - recall: 0.8520"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4422 - categorical_accuracy: 0.8776 - precision: 0.9138 - recall: 0.8520 - val_loss: 0.5636 - val_categorical_accuracy: 0.8776 - val_precision: 0.9111 - val_recall: 0.8367\n",
            "Epoch 336/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4091 - categorical_accuracy: 0.9005 - precision: 0.9260 - recall: 0.8622"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4091 - categorical_accuracy: 0.9005 - precision: 0.9260 - recall: 0.8622 - val_loss: 0.8559 - val_categorical_accuracy: 0.7551 - val_precision: 0.8235 - val_recall: 0.7143\n",
            "Epoch 337/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4170 - categorical_accuracy: 0.8878 - precision: 0.9145 - recall: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.4170 - categorical_accuracy: 0.8878 - precision: 0.9145 - recall: 0.8597 - val_loss: 0.6025 - val_categorical_accuracy: 0.8469 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 338/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3868 - categorical_accuracy: 0.9043 - precision: 0.9299 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3868 - categorical_accuracy: 0.9043 - precision: 0.9299 - recall: 0.8801 - val_loss: 0.6359 - val_categorical_accuracy: 0.8061 - val_precision: 0.8571 - val_recall: 0.7959\n",
            "Epoch 339/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3853 - categorical_accuracy: 0.8954 - precision: 0.9188 - recall: 0.8661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 126ms/step - loss: 0.3853 - categorical_accuracy: 0.8954 - precision: 0.9188 - recall: 0.8661 - val_loss: 0.5820 - val_categorical_accuracy: 0.8367 - val_precision: 0.8764 - val_recall: 0.7959\n",
            "Epoch 340/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3791 - categorical_accuracy: 0.9120 - precision: 0.9324 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 169ms/step - loss: 0.3791 - categorical_accuracy: 0.9120 - precision: 0.9324 - recall: 0.8801 - val_loss: 0.6302 - val_categorical_accuracy: 0.8265 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 341/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3964 - categorical_accuracy: 0.9031 - precision: 0.9197 - recall: 0.8763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 159ms/step - loss: 0.3964 - categorical_accuracy: 0.9031 - precision: 0.9197 - recall: 0.8763 - val_loss: 0.5396 - val_categorical_accuracy: 0.8776 - val_precision: 0.9130 - val_recall: 0.8571\n",
            "Epoch 342/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4068 - categorical_accuracy: 0.8852 - precision: 0.9122 - recall: 0.8610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.4068 - categorical_accuracy: 0.8852 - precision: 0.9122 - recall: 0.8610 - val_loss: 0.6724 - val_categorical_accuracy: 0.7959 - val_precision: 0.8444 - val_recall: 0.7755\n",
            "Epoch 343/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4299 - categorical_accuracy: 0.8776 - precision: 0.9096 - recall: 0.8469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4299 - categorical_accuracy: 0.8776 - precision: 0.9096 - recall: 0.8469 - val_loss: 0.6859 - val_categorical_accuracy: 0.7959 - val_precision: 0.8427 - val_recall: 0.7653\n",
            "Epoch 344/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3845 - categorical_accuracy: 0.9082 - precision: 0.9372 - recall: 0.8763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3845 - categorical_accuracy: 0.9082 - precision: 0.9372 - recall: 0.8763 - val_loss: 0.5786 - val_categorical_accuracy: 0.8469 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 345/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3926 - categorical_accuracy: 0.8992 - precision: 0.9307 - recall: 0.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.3926 - categorical_accuracy: 0.8992 - precision: 0.9307 - recall: 0.8737 - val_loss: 0.5687 - val_categorical_accuracy: 0.8571 - val_precision: 0.8989 - val_recall: 0.8163\n",
            "Epoch 346/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3789 - categorical_accuracy: 0.9043 - precision: 0.9389 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3789 - categorical_accuracy: 0.9043 - precision: 0.9389 - recall: 0.8814 - val_loss: 0.5792 - val_categorical_accuracy: 0.8571 - val_precision: 0.8876 - val_recall: 0.8061\n",
            "Epoch 347/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3908 - categorical_accuracy: 0.9005 - precision: 0.9252 - recall: 0.8673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3908 - categorical_accuracy: 0.9005 - precision: 0.9252 - recall: 0.8673 - val_loss: 0.8701 - val_categorical_accuracy: 0.7653 - val_precision: 0.8256 - val_recall: 0.7245\n",
            "Epoch 348/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3705 - categorical_accuracy: 0.9133 - precision: 0.9388 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3705 - categorical_accuracy: 0.9133 - precision: 0.9388 - recall: 0.8801 - val_loss: 0.5991 - val_categorical_accuracy: 0.8469 - val_precision: 0.9000 - val_recall: 0.8265\n",
            "Epoch 349/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3909 - categorical_accuracy: 0.8967 - precision: 0.9204 - recall: 0.8699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3909 - categorical_accuracy: 0.8967 - precision: 0.9204 - recall: 0.8699 - val_loss: 0.5730 - val_categorical_accuracy: 0.8571 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 350/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4138 - categorical_accuracy: 0.8878 - precision: 0.9215 - recall: 0.8686"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4138 - categorical_accuracy: 0.8878 - precision: 0.9215 - recall: 0.8686 - val_loss: 0.6932 - val_categorical_accuracy: 0.7755 - val_precision: 0.8132 - val_recall: 0.7551\n",
            "Epoch 351/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3839 - categorical_accuracy: 0.9069 - precision: 0.9318 - recall: 0.8712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3839 - categorical_accuracy: 0.9069 - precision: 0.9318 - recall: 0.8712 - val_loss: 0.6891 - val_categorical_accuracy: 0.7857 - val_precision: 0.8202 - val_recall: 0.7449\n",
            "Epoch 352/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3700 - categorical_accuracy: 0.9018 - precision: 0.9324 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3700 - categorical_accuracy: 0.9018 - precision: 0.9324 - recall: 0.8801 - val_loss: 0.6542 - val_categorical_accuracy: 0.8265 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 353/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4163 - categorical_accuracy: 0.8903 - precision: 0.9212 - recall: 0.8648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4163 - categorical_accuracy: 0.8903 - precision: 0.9212 - recall: 0.8648 - val_loss: 0.6813 - val_categorical_accuracy: 0.7959 - val_precision: 0.8105 - val_recall: 0.7857\n",
            "Epoch 354/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3751 - categorical_accuracy: 0.9056 - precision: 0.9361 - recall: 0.8776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 89ms/step - loss: 0.3751 - categorical_accuracy: 0.9056 - precision: 0.9361 - recall: 0.8776 - val_loss: 0.5819 - val_categorical_accuracy: 0.8776 - val_precision: 0.9130 - val_recall: 0.8571\n",
            "Epoch 355/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3879 - categorical_accuracy: 0.9005 - precision: 0.9225 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3879 - categorical_accuracy: 0.9005 - precision: 0.9225 - recall: 0.8801 - val_loss: 0.6292 - val_categorical_accuracy: 0.8163 - val_precision: 0.8370 - val_recall: 0.7857\n",
            "Epoch 356/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4030 - categorical_accuracy: 0.8941 - precision: 0.9169 - recall: 0.8584"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4030 - categorical_accuracy: 0.8941 - precision: 0.9169 - recall: 0.8584 - val_loss: 0.7233 - val_categorical_accuracy: 0.8469 - val_precision: 0.8539 - val_recall: 0.7755\n",
            "Epoch 357/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4020 - categorical_accuracy: 0.8814 - precision: 0.9158 - recall: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4020 - categorical_accuracy: 0.8814 - precision: 0.9158 - recall: 0.8597 - val_loss: 0.6154 - val_categorical_accuracy: 0.8163 - val_precision: 0.8791 - val_recall: 0.8163\n",
            "Epoch 358/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4992 - categorical_accuracy: 0.8482 - precision: 0.8889 - recall: 0.8163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4992 - categorical_accuracy: 0.8482 - precision: 0.8889 - recall: 0.8163 - val_loss: 0.8885 - val_categorical_accuracy: 0.7041 - val_precision: 0.7416 - val_recall: 0.6735\n",
            "Epoch 359/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4574 - categorical_accuracy: 0.8724 - precision: 0.8939 - recall: 0.8380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4574 - categorical_accuracy: 0.8724 - precision: 0.8939 - recall: 0.8380 - val_loss: 0.7965 - val_categorical_accuracy: 0.7551 - val_precision: 0.7849 - val_recall: 0.7449\n",
            "Epoch 360/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4426 - categorical_accuracy: 0.8814 - precision: 0.9153 - recall: 0.8546"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4426 - categorical_accuracy: 0.8814 - precision: 0.9153 - recall: 0.8546 - val_loss: 0.8718 - val_categorical_accuracy: 0.6939 - val_precision: 0.7391 - val_recall: 0.6939\n",
            "Epoch 361/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3719 - categorical_accuracy: 0.9005 - precision: 0.9155 - recall: 0.8839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3719 - categorical_accuracy: 0.9005 - precision: 0.9155 - recall: 0.8839 - val_loss: 0.6268 - val_categorical_accuracy: 0.8265 - val_precision: 0.8681 - val_recall: 0.8061\n",
            "Epoch 362/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3773 - categorical_accuracy: 0.9069 - precision: 0.9322 - recall: 0.8763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3773 - categorical_accuracy: 0.9069 - precision: 0.9322 - recall: 0.8763 - val_loss: 0.6661 - val_categorical_accuracy: 0.7653 - val_precision: 0.8242 - val_recall: 0.7653\n",
            "Epoch 363/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3752 - categorical_accuracy: 0.9069 - precision: 0.9237 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3752 - categorical_accuracy: 0.9069 - precision: 0.9237 - recall: 0.8801 - val_loss: 0.6532 - val_categorical_accuracy: 0.8265 - val_precision: 0.8556 - val_recall: 0.7857\n",
            "Epoch 364/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3836 - categorical_accuracy: 0.9069 - precision: 0.9484 - recall: 0.8903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3836 - categorical_accuracy: 0.9069 - precision: 0.9484 - recall: 0.8903 - val_loss: 0.5719 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 365/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4011 - categorical_accuracy: 0.8929 - precision: 0.9198 - recall: 0.8635"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.4011 - categorical_accuracy: 0.8929 - precision: 0.9198 - recall: 0.8635 - val_loss: 0.8209 - val_categorical_accuracy: 0.7857 - val_precision: 0.7766 - val_recall: 0.7449\n",
            "Epoch 366/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3912 - categorical_accuracy: 0.8967 - precision: 0.9243 - recall: 0.8724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3912 - categorical_accuracy: 0.8967 - precision: 0.9243 - recall: 0.8724 - val_loss: 0.5655 - val_categorical_accuracy: 0.8367 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 367/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3596 - categorical_accuracy: 0.9005 - precision: 0.9363 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3596 - categorical_accuracy: 0.9005 - precision: 0.9363 - recall: 0.8814 - val_loss: 0.6904 - val_categorical_accuracy: 0.8367 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 368/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3913 - categorical_accuracy: 0.9005 - precision: 0.9155 - recall: 0.8712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3913 - categorical_accuracy: 0.9005 - precision: 0.9155 - recall: 0.8712 - val_loss: 0.6917 - val_categorical_accuracy: 0.8061 - val_precision: 0.8085 - val_recall: 0.7755\n",
            "Epoch 369/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3687 - categorical_accuracy: 0.9043 - precision: 0.9350 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3687 - categorical_accuracy: 0.9043 - precision: 0.9350 - recall: 0.8801 - val_loss: 0.6407 - val_categorical_accuracy: 0.8265 - val_precision: 0.8750 - val_recall: 0.7857\n",
            "Epoch 370/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3792 - categorical_accuracy: 0.8903 - precision: 0.9255 - recall: 0.8712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3792 - categorical_accuracy: 0.8903 - precision: 0.9255 - recall: 0.8712 - val_loss: 0.6117 - val_categorical_accuracy: 0.8367 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 371/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3826 - categorical_accuracy: 0.8992 - precision: 0.9295 - recall: 0.8750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3826 - categorical_accuracy: 0.8992 - precision: 0.9295 - recall: 0.8750 - val_loss: 0.5458 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 372/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3743 - categorical_accuracy: 0.9094 - precision: 0.9416 - recall: 0.8839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3743 - categorical_accuracy: 0.9094 - precision: 0.9416 - recall: 0.8839 - val_loss: 0.6329 - val_categorical_accuracy: 0.8163 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 373/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4167 - categorical_accuracy: 0.8839 - precision: 0.9127 - recall: 0.8533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.4167 - categorical_accuracy: 0.8839 - precision: 0.9127 - recall: 0.8533 - val_loss: 0.8685 - val_categorical_accuracy: 0.7449 - val_precision: 0.7931 - val_recall: 0.7041\n",
            "Epoch 374/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4721 - categorical_accuracy: 0.8699 - precision: 0.8908 - recall: 0.8431"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.4721 - categorical_accuracy: 0.8699 - precision: 0.8908 - recall: 0.8431 - val_loss: 0.8618 - val_categorical_accuracy: 0.7143 - val_precision: 0.7333 - val_recall: 0.6735\n",
            "Epoch 375/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3842 - categorical_accuracy: 0.9056 - precision: 0.9213 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3842 - categorical_accuracy: 0.9056 - precision: 0.9213 - recall: 0.8814 - val_loss: 0.5645 - val_categorical_accuracy: 0.8571 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 376/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3685 - categorical_accuracy: 0.8980 - precision: 0.9356 - recall: 0.8712"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3685 - categorical_accuracy: 0.8980 - precision: 0.9356 - recall: 0.8712 - val_loss: 0.6179 - val_categorical_accuracy: 0.8469 - val_precision: 0.8791 - val_recall: 0.8163\n",
            "Epoch 377/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4148 - categorical_accuracy: 0.8724 - precision: 0.8987 - recall: 0.8597"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4148 - categorical_accuracy: 0.8724 - precision: 0.8987 - recall: 0.8597 - val_loss: 0.9057 - val_categorical_accuracy: 0.7755 - val_precision: 0.8132 - val_recall: 0.7551\n",
            "Epoch 378/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4038 - categorical_accuracy: 0.8903 - precision: 0.9151 - recall: 0.8661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.4038 - categorical_accuracy: 0.8903 - precision: 0.9151 - recall: 0.8661 - val_loss: 0.5991 - val_categorical_accuracy: 0.8673 - val_precision: 0.8913 - val_recall: 0.8367\n",
            "Epoch 379/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3574 - categorical_accuracy: 0.9158 - precision: 0.9430 - recall: 0.8865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.3574 - categorical_accuracy: 0.9158 - precision: 0.9430 - recall: 0.8865 - val_loss: 0.6371 - val_categorical_accuracy: 0.8265 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 380/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3456 - categorical_accuracy: 0.9133 - precision: 0.9432 - recall: 0.8903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3456 - categorical_accuracy: 0.9133 - precision: 0.9432 - recall: 0.8903 - val_loss: 0.6141 - val_categorical_accuracy: 0.8367 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 381/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3371 - categorical_accuracy: 0.9260 - precision: 0.9526 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3371 - categorical_accuracy: 0.9260 - precision: 0.9526 - recall: 0.8967 - val_loss: 0.5389 - val_categorical_accuracy: 0.8878 - val_precision: 0.9121 - val_recall: 0.8469\n",
            "Epoch 382/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3360 - categorical_accuracy: 0.9184 - precision: 0.9500 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3360 - categorical_accuracy: 0.9184 - precision: 0.9500 - recall: 0.8967 - val_loss: 0.6713 - val_categorical_accuracy: 0.7857 - val_precision: 0.8352 - val_recall: 0.7755\n",
            "Epoch 383/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3465 - categorical_accuracy: 0.9107 - precision: 0.9324 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3465 - categorical_accuracy: 0.9107 - precision: 0.9324 - recall: 0.8967 - val_loss: 0.6860 - val_categorical_accuracy: 0.8265 - val_precision: 0.8370 - val_recall: 0.7857\n",
            "Epoch 384/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3964 - categorical_accuracy: 0.8954 - precision: 0.9170 - recall: 0.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3964 - categorical_accuracy: 0.8954 - precision: 0.9170 - recall: 0.8737 - val_loss: 0.6647 - val_categorical_accuracy: 0.8367 - val_precision: 0.8571 - val_recall: 0.7959\n",
            "Epoch 385/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3903 - categorical_accuracy: 0.9056 - precision: 0.9293 - recall: 0.8890"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3903 - categorical_accuracy: 0.9056 - precision: 0.9293 - recall: 0.8890 - val_loss: 0.6695 - val_categorical_accuracy: 0.7755 - val_precision: 0.8261 - val_recall: 0.7755\n",
            "Epoch 386/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3666 - categorical_accuracy: 0.9031 - precision: 0.9378 - recall: 0.8852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3666 - categorical_accuracy: 0.9031 - precision: 0.9378 - recall: 0.8852 - val_loss: 0.5846 - val_categorical_accuracy: 0.8367 - val_precision: 0.8791 - val_recall: 0.8163\n",
            "Epoch 387/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3685 - categorical_accuracy: 0.9005 - precision: 0.9231 - recall: 0.8724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3685 - categorical_accuracy: 0.9005 - precision: 0.9231 - recall: 0.8724 - val_loss: 0.5681 - val_categorical_accuracy: 0.8469 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 388/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3367 - categorical_accuracy: 0.9273 - precision: 0.9453 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.3367 - categorical_accuracy: 0.9273 - precision: 0.9453 - recall: 0.9043 - val_loss: 0.6325 - val_categorical_accuracy: 0.8163 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 389/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3446 - categorical_accuracy: 0.9222 - precision: 0.9409 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3446 - categorical_accuracy: 0.9222 - precision: 0.9409 - recall: 0.8941 - val_loss: 0.6791 - val_categorical_accuracy: 0.7857 - val_precision: 0.8172 - val_recall: 0.7755\n",
            "Epoch 390/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3266 - categorical_accuracy: 0.9171 - precision: 0.9337 - recall: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3266 - categorical_accuracy: 0.9171 - precision: 0.9337 - recall: 0.8980 - val_loss: 0.6194 - val_categorical_accuracy: 0.8571 - val_precision: 0.9000 - val_recall: 0.8265\n",
            "Epoch 391/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4005 - categorical_accuracy: 0.8839 - precision: 0.9099 - recall: 0.8635"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.4005 - categorical_accuracy: 0.8839 - precision: 0.9099 - recall: 0.8635 - val_loss: 0.5778 - val_categorical_accuracy: 0.8469 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 392/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3525 - categorical_accuracy: 0.9082 - precision: 0.9344 - recall: 0.8903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3525 - categorical_accuracy: 0.9082 - precision: 0.9344 - recall: 0.8903 - val_loss: 0.5449 - val_categorical_accuracy: 0.8776 - val_precision: 0.9011 - val_recall: 0.8367\n",
            "Epoch 393/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3677 - categorical_accuracy: 0.9069 - precision: 0.9262 - recall: 0.8801"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3677 - categorical_accuracy: 0.9069 - precision: 0.9262 - recall: 0.8801 - val_loss: 0.5435 - val_categorical_accuracy: 0.8571 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 394/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3726 - categorical_accuracy: 0.8929 - precision: 0.9182 - recall: 0.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3726 - categorical_accuracy: 0.8929 - precision: 0.9182 - recall: 0.8737 - val_loss: 0.6287 - val_categorical_accuracy: 0.8367 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 395/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3583 - categorical_accuracy: 0.9158 - precision: 0.9361 - recall: 0.8788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3583 - categorical_accuracy: 0.9158 - precision: 0.9361 - recall: 0.8788 - val_loss: 0.6086 - val_categorical_accuracy: 0.8163 - val_precision: 0.8571 - val_recall: 0.7959\n",
            "Epoch 396/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3448 - categorical_accuracy: 0.9094 - precision: 0.9339 - recall: 0.8827"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3448 - categorical_accuracy: 0.9094 - precision: 0.9339 - recall: 0.8827 - val_loss: 0.6223 - val_categorical_accuracy: 0.8265 - val_precision: 0.8652 - val_recall: 0.7857\n",
            "Epoch 397/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3324 - categorical_accuracy: 0.9120 - precision: 0.9270 - recall: 0.8903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3324 - categorical_accuracy: 0.9120 - precision: 0.9270 - recall: 0.8903 - val_loss: 0.5065 - val_categorical_accuracy: 0.8673 - val_precision: 0.9000 - val_recall: 0.8265\n",
            "Epoch 398/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3200 - categorical_accuracy: 0.9235 - precision: 0.9479 - recall: 0.9056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3200 - categorical_accuracy: 0.9235 - precision: 0.9479 - recall: 0.9056 - val_loss: 0.6375 - val_categorical_accuracy: 0.8163 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 399/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3318 - categorical_accuracy: 0.9260 - precision: 0.9441 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3318 - categorical_accuracy: 0.9260 - precision: 0.9441 - recall: 0.9043 - val_loss: 0.5744 - val_categorical_accuracy: 0.8367 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 400/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3296 - categorical_accuracy: 0.9209 - precision: 0.9388 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3296 - categorical_accuracy: 0.9209 - precision: 0.9388 - recall: 0.9005 - val_loss: 0.5546 - val_categorical_accuracy: 0.8469 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 401/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3058 - categorical_accuracy: 0.9362 - precision: 0.9548 - recall: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3058 - categorical_accuracy: 0.9362 - precision: 0.9548 - recall: 0.9158 - val_loss: 0.6552 - val_categorical_accuracy: 0.8265 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 402/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3352 - categorical_accuracy: 0.9209 - precision: 0.9359 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3352 - categorical_accuracy: 0.9209 - precision: 0.9359 - recall: 0.8941 - val_loss: 0.6936 - val_categorical_accuracy: 0.8061 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 403/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3320 - categorical_accuracy: 0.9247 - precision: 0.9401 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3320 - categorical_accuracy: 0.9247 - precision: 0.9401 - recall: 0.9005 - val_loss: 0.5519 - val_categorical_accuracy: 0.8776 - val_precision: 0.9140 - val_recall: 0.8673\n",
            "Epoch 404/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3245 - categorical_accuracy: 0.9209 - precision: 0.9364 - recall: 0.9018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3245 - categorical_accuracy: 0.9209 - precision: 0.9364 - recall: 0.9018 - val_loss: 0.7486 - val_categorical_accuracy: 0.7755 - val_precision: 0.8276 - val_recall: 0.7347\n",
            "Epoch 405/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3333 - categorical_accuracy: 0.9209 - precision: 0.9412 - recall: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3333 - categorical_accuracy: 0.9209 - precision: 0.9412 - recall: 0.8980 - val_loss: 0.5600 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 406/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3295 - categorical_accuracy: 0.9298 - precision: 0.9408 - recall: 0.9120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3295 - categorical_accuracy: 0.9298 - precision: 0.9408 - recall: 0.9120 - val_loss: 0.5842 - val_categorical_accuracy: 0.8571 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 407/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3342 - categorical_accuracy: 0.9145 - precision: 0.9357 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3342 - categorical_accuracy: 0.9145 - precision: 0.9357 - recall: 0.8916 - val_loss: 0.5390 - val_categorical_accuracy: 0.8571 - val_precision: 0.9022 - val_recall: 0.8469\n",
            "Epoch 408/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3483 - categorical_accuracy: 0.9094 - precision: 0.9338 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3483 - categorical_accuracy: 0.9094 - precision: 0.9338 - recall: 0.8814 - val_loss: 0.5680 - val_categorical_accuracy: 0.8469 - val_precision: 0.8696 - val_recall: 0.8163\n",
            "Epoch 409/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3194 - categorical_accuracy: 0.9362 - precision: 0.9513 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3194 - categorical_accuracy: 0.9362 - precision: 0.9513 - recall: 0.9222 - val_loss: 0.5695 - val_categorical_accuracy: 0.8469 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 410/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3998 - categorical_accuracy: 0.8788 - precision: 0.8936 - recall: 0.8571"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3998 - categorical_accuracy: 0.8788 - precision: 0.8936 - recall: 0.8571 - val_loss: 0.4875 - val_categorical_accuracy: 0.8878 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 411/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3961 - categorical_accuracy: 0.8801 - precision: 0.9090 - recall: 0.8533"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3961 - categorical_accuracy: 0.8801 - precision: 0.9090 - recall: 0.8533 - val_loss: 0.8055 - val_categorical_accuracy: 0.7959 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 412/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3806 - categorical_accuracy: 0.8992 - precision: 0.9235 - recall: 0.8776"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3806 - categorical_accuracy: 0.8992 - precision: 0.9235 - recall: 0.8776 - val_loss: 1.1120 - val_categorical_accuracy: 0.7041 - val_precision: 0.7191 - val_recall: 0.6531\n",
            "Epoch 413/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3635 - categorical_accuracy: 0.9069 - precision: 0.9229 - recall: 0.8852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3635 - categorical_accuracy: 0.9069 - precision: 0.9229 - recall: 0.8852 - val_loss: 0.5923 - val_categorical_accuracy: 0.8265 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 414/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3946 - categorical_accuracy: 0.8929 - precision: 0.9144 - recall: 0.8724"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.3946 - categorical_accuracy: 0.8929 - precision: 0.9144 - recall: 0.8724 - val_loss: 0.6706 - val_categorical_accuracy: 0.7959 - val_precision: 0.8242 - val_recall: 0.7653\n",
            "Epoch 415/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3238 - categorical_accuracy: 0.9196 - precision: 0.9414 - recall: 0.9018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3238 - categorical_accuracy: 0.9196 - precision: 0.9414 - recall: 0.9018 - val_loss: 0.5765 - val_categorical_accuracy: 0.8265 - val_precision: 0.8571 - val_recall: 0.7959\n",
            "Epoch 416/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3301 - categorical_accuracy: 0.9145 - precision: 0.9345 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3301 - categorical_accuracy: 0.9145 - precision: 0.9345 - recall: 0.8916 - val_loss: 0.6012 - val_categorical_accuracy: 0.8571 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 417/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3428 - categorical_accuracy: 0.9031 - precision: 0.9282 - recall: 0.8903"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3428 - categorical_accuracy: 0.9031 - precision: 0.9282 - recall: 0.8903 - val_loss: 0.6562 - val_categorical_accuracy: 0.8367 - val_precision: 0.8387 - val_recall: 0.7959\n",
            "Epoch 418/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3344 - categorical_accuracy: 0.9222 - precision: 0.9362 - recall: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3344 - categorical_accuracy: 0.9222 - precision: 0.9362 - recall: 0.8980 - val_loss: 0.5469 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 419/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3310 - categorical_accuracy: 0.9171 - precision: 0.9365 - recall: 0.9031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.3310 - categorical_accuracy: 0.9171 - precision: 0.9365 - recall: 0.9031 - val_loss: 0.5266 - val_categorical_accuracy: 0.8571 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 420/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3366 - categorical_accuracy: 0.9069 - precision: 0.9209 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3366 - categorical_accuracy: 0.9069 - precision: 0.9209 - recall: 0.8916 - val_loss: 0.6754 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 421/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3279 - categorical_accuracy: 0.9171 - precision: 0.9373 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3279 - categorical_accuracy: 0.9171 - precision: 0.9373 - recall: 0.8967 - val_loss: 0.4969 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 422/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3126 - categorical_accuracy: 0.9235 - precision: 0.9372 - recall: 0.8954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3126 - categorical_accuracy: 0.9235 - precision: 0.9372 - recall: 0.8954 - val_loss: 0.7179 - val_categorical_accuracy: 0.8265 - val_precision: 0.8370 - val_recall: 0.7857\n",
            "Epoch 423/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3333 - categorical_accuracy: 0.9120 - precision: 0.9297 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3333 - categorical_accuracy: 0.9120 - precision: 0.9297 - recall: 0.8941 - val_loss: 0.7776 - val_categorical_accuracy: 0.7959 - val_precision: 0.7935 - val_recall: 0.7449\n",
            "Epoch 424/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3399 - categorical_accuracy: 0.9158 - precision: 0.9383 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3399 - categorical_accuracy: 0.9158 - precision: 0.9383 - recall: 0.8916 - val_loss: 0.5655 - val_categorical_accuracy: 0.8571 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 425/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3076 - categorical_accuracy: 0.9298 - precision: 0.9448 - recall: 0.9171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3076 - categorical_accuracy: 0.9298 - precision: 0.9448 - recall: 0.9171 - val_loss: 0.5709 - val_categorical_accuracy: 0.8469 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 426/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3078 - categorical_accuracy: 0.9247 - precision: 0.9419 - recall: 0.9094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3078 - categorical_accuracy: 0.9247 - precision: 0.9419 - recall: 0.9094 - val_loss: 0.7341 - val_categorical_accuracy: 0.8061 - val_precision: 0.8370 - val_recall: 0.7857\n",
            "Epoch 427/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3424 - categorical_accuracy: 0.9107 - precision: 0.9312 - recall: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3424 - categorical_accuracy: 0.9107 - precision: 0.9312 - recall: 0.8980 - val_loss: 0.4879 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 428/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3587 - categorical_accuracy: 0.9056 - precision: 0.9271 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3587 - categorical_accuracy: 0.9056 - precision: 0.9271 - recall: 0.8916 - val_loss: 0.7449 - val_categorical_accuracy: 0.7857 - val_precision: 0.8280 - val_recall: 0.7857\n",
            "Epoch 429/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.4608 - categorical_accuracy: 0.8686 - precision: 0.8904 - recall: 0.8495"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.4608 - categorical_accuracy: 0.8686 - precision: 0.8904 - recall: 0.8495 - val_loss: 0.6519 - val_categorical_accuracy: 0.8061 - val_precision: 0.8681 - val_recall: 0.8061\n",
            "Epoch 430/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3909 - categorical_accuracy: 0.8852 - precision: 0.9073 - recall: 0.8610"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3909 - categorical_accuracy: 0.8852 - precision: 0.9073 - recall: 0.8610 - val_loss: 0.6341 - val_categorical_accuracy: 0.8265 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 431/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3107 - categorical_accuracy: 0.9184 - precision: 0.9343 - recall: 0.9069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3107 - categorical_accuracy: 0.9184 - precision: 0.9343 - recall: 0.9069 - val_loss: 0.6194 - val_categorical_accuracy: 0.8469 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 432/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3061 - categorical_accuracy: 0.9209 - precision: 0.9401 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3061 - categorical_accuracy: 0.9209 - precision: 0.9401 - recall: 0.9005 - val_loss: 0.6694 - val_categorical_accuracy: 0.8265 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 433/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.9184 - precision: 0.9455 - recall: 0.9069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3046 - categorical_accuracy: 0.9184 - precision: 0.9455 - recall: 0.9069 - val_loss: 0.7685 - val_categorical_accuracy: 0.7857 - val_precision: 0.8000 - val_recall: 0.7755\n",
            "Epoch 434/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3256 - categorical_accuracy: 0.9235 - precision: 0.9348 - recall: 0.8954"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3256 - categorical_accuracy: 0.9235 - precision: 0.9348 - recall: 0.8954 - val_loss: 0.8982 - val_categorical_accuracy: 0.7449 - val_precision: 0.7579 - val_recall: 0.7347\n",
            "Epoch 435/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3339 - categorical_accuracy: 0.9209 - precision: 0.9373 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3339 - categorical_accuracy: 0.9209 - precision: 0.9373 - recall: 0.8967 - val_loss: 0.5952 - val_categorical_accuracy: 0.8163 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 436/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3282 - categorical_accuracy: 0.9158 - precision: 0.9339 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 147ms/step - loss: 0.3282 - categorical_accuracy: 0.9158 - precision: 0.9339 - recall: 0.9005 - val_loss: 0.6513 - val_categorical_accuracy: 0.8265 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 437/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3215 - categorical_accuracy: 0.9196 - precision: 0.9469 - recall: 0.9094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 170ms/step - loss: 0.3215 - categorical_accuracy: 0.9196 - precision: 0.9469 - recall: 0.9094 - val_loss: 0.6654 - val_categorical_accuracy: 0.8265 - val_precision: 0.8404 - val_recall: 0.8061\n",
            "Epoch 438/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3512 - categorical_accuracy: 0.8992 - precision: 0.9238 - recall: 0.8814"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 148ms/step - loss: 0.3512 - categorical_accuracy: 0.8992 - precision: 0.9238 - recall: 0.8814 - val_loss: 0.5970 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 439/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3192 - categorical_accuracy: 0.9209 - precision: 0.9340 - recall: 0.9031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3192 - categorical_accuracy: 0.9209 - precision: 0.9340 - recall: 0.9031 - val_loss: 0.5491 - val_categorical_accuracy: 0.8469 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 440/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3292 - categorical_accuracy: 0.9120 - precision: 0.9351 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3292 - categorical_accuracy: 0.9120 - precision: 0.9351 - recall: 0.9005 - val_loss: 0.6098 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 441/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3017 - categorical_accuracy: 0.9298 - precision: 0.9521 - recall: 0.9133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3017 - categorical_accuracy: 0.9298 - precision: 0.9521 - recall: 0.9133 - val_loss: 0.5404 - val_categorical_accuracy: 0.8265 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 442/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2864 - categorical_accuracy: 0.9375 - precision: 0.9586 - recall: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2864 - categorical_accuracy: 0.9375 - precision: 0.9586 - recall: 0.9145 - val_loss: 0.5256 - val_categorical_accuracy: 0.8571 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 443/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3195 - categorical_accuracy: 0.9209 - precision: 0.9353 - recall: 0.9031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3195 - categorical_accuracy: 0.9209 - precision: 0.9353 - recall: 0.9031 - val_loss: 0.6804 - val_categorical_accuracy: 0.8163 - val_precision: 0.8444 - val_recall: 0.7755\n",
            "Epoch 444/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3430 - categorical_accuracy: 0.9145 - precision: 0.9285 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3430 - categorical_accuracy: 0.9145 - precision: 0.9285 - recall: 0.8941 - val_loss: 0.6743 - val_categorical_accuracy: 0.7857 - val_precision: 0.8132 - val_recall: 0.7551\n",
            "Epoch 445/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3302 - categorical_accuracy: 0.9133 - precision: 0.9287 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3302 - categorical_accuracy: 0.9133 - precision: 0.9287 - recall: 0.8967 - val_loss: 0.6414 - val_categorical_accuracy: 0.8163 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 446/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3078 - categorical_accuracy: 0.9311 - precision: 0.9473 - recall: 0.9171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3078 - categorical_accuracy: 0.9311 - precision: 0.9473 - recall: 0.9171 - val_loss: 0.5026 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 447/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3170 - categorical_accuracy: 0.9209 - precision: 0.9305 - recall: 0.9056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3170 - categorical_accuracy: 0.9209 - precision: 0.9305 - recall: 0.9056 - val_loss: 0.7239 - val_categorical_accuracy: 0.8061 - val_precision: 0.8041 - val_recall: 0.7959\n",
            "Epoch 448/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3333 - categorical_accuracy: 0.9171 - precision: 0.9321 - recall: 0.8929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3333 - categorical_accuracy: 0.9171 - precision: 0.9321 - recall: 0.8929 - val_loss: 0.5901 - val_categorical_accuracy: 0.8367 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 449/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3914 - categorical_accuracy: 0.8890 - precision: 0.9079 - recall: 0.8673"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3914 - categorical_accuracy: 0.8890 - precision: 0.9079 - recall: 0.8673 - val_loss: 0.5318 - val_categorical_accuracy: 0.8571 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 450/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3005 - categorical_accuracy: 0.9260 - precision: 0.9441 - recall: 0.9056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.3005 - categorical_accuracy: 0.9260 - precision: 0.9441 - recall: 0.9056 - val_loss: 0.5939 - val_categorical_accuracy: 0.8163 - val_precision: 0.8571 - val_recall: 0.7959\n",
            "Epoch 451/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3150 - categorical_accuracy: 0.9222 - precision: 0.9355 - recall: 0.9069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3150 - categorical_accuracy: 0.9222 - precision: 0.9355 - recall: 0.9069 - val_loss: 0.6900 - val_categorical_accuracy: 0.7755 - val_precision: 0.8152 - val_recall: 0.7653\n",
            "Epoch 452/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2948 - categorical_accuracy: 0.9222 - precision: 0.9389 - recall: 0.9018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2948 - categorical_accuracy: 0.9222 - precision: 0.9389 - recall: 0.9018 - val_loss: 0.6888 - val_categorical_accuracy: 0.7857 - val_precision: 0.8172 - val_recall: 0.7755\n",
            "Epoch 453/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2876 - categorical_accuracy: 0.9298 - precision: 0.9481 - recall: 0.9094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2876 - categorical_accuracy: 0.9298 - precision: 0.9481 - recall: 0.9094 - val_loss: 0.5578 - val_categorical_accuracy: 0.8367 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 454/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3098 - categorical_accuracy: 0.9120 - precision: 0.9320 - recall: 0.8916"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3098 - categorical_accuracy: 0.9120 - precision: 0.9320 - recall: 0.8916 - val_loss: 0.7081 - val_categorical_accuracy: 0.8061 - val_precision: 0.8280 - val_recall: 0.7857\n",
            "Epoch 455/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3212 - categorical_accuracy: 0.9184 - precision: 0.9466 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3212 - categorical_accuracy: 0.9184 - precision: 0.9466 - recall: 0.9043 - val_loss: 0.7609 - val_categorical_accuracy: 0.7959 - val_precision: 0.7872 - val_recall: 0.7551\n",
            "Epoch 456/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3090 - categorical_accuracy: 0.9286 - precision: 0.9439 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3090 - categorical_accuracy: 0.9286 - precision: 0.9439 - recall: 0.9005 - val_loss: 0.5784 - val_categorical_accuracy: 0.8571 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 457/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2883 - categorical_accuracy: 0.9349 - precision: 0.9461 - recall: 0.9184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2883 - categorical_accuracy: 0.9349 - precision: 0.9461 - recall: 0.9184 - val_loss: 0.5739 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 458/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2705 - categorical_accuracy: 0.9388 - precision: 0.9589 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2705 - categorical_accuracy: 0.9388 - precision: 0.9589 - recall: 0.9222 - val_loss: 0.6583 - val_categorical_accuracy: 0.8265 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 459/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3021 - categorical_accuracy: 0.9337 - precision: 0.9439 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3021 - categorical_accuracy: 0.9337 - precision: 0.9439 - recall: 0.9222 - val_loss: 0.7490 - val_categorical_accuracy: 0.8061 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 460/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3037 - categorical_accuracy: 0.9235 - precision: 0.9382 - recall: 0.9107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3037 - categorical_accuracy: 0.9235 - precision: 0.9382 - recall: 0.9107 - val_loss: 0.6519 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 461/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2762 - categorical_accuracy: 0.9337 - precision: 0.9463 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2762 - categorical_accuracy: 0.9337 - precision: 0.9463 - recall: 0.9209 - val_loss: 0.5756 - val_categorical_accuracy: 0.8571 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 462/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2689 - categorical_accuracy: 0.9337 - precision: 0.9441 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2689 - categorical_accuracy: 0.9337 - precision: 0.9441 - recall: 0.9260 - val_loss: 0.6010 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 463/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2558 - categorical_accuracy: 0.9490 - precision: 0.9620 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2558 - categorical_accuracy: 0.9490 - precision: 0.9620 - recall: 0.9362 - val_loss: 0.5828 - val_categorical_accuracy: 0.8367 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 464/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2710 - categorical_accuracy: 0.9401 - precision: 0.9515 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2710 - categorical_accuracy: 0.9401 - precision: 0.9515 - recall: 0.9260 - val_loss: 0.5739 - val_categorical_accuracy: 0.8367 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 465/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2955 - categorical_accuracy: 0.9311 - precision: 0.9472 - recall: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2955 - categorical_accuracy: 0.9311 - precision: 0.9472 - recall: 0.9145 - val_loss: 0.6217 - val_categorical_accuracy: 0.7959 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 466/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3049 - categorical_accuracy: 0.9222 - precision: 0.9391 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3049 - categorical_accuracy: 0.9222 - precision: 0.9391 - recall: 0.9043 - val_loss: 0.5192 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 467/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2790 - categorical_accuracy: 0.9401 - precision: 0.9524 - recall: 0.9196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2790 - categorical_accuracy: 0.9401 - precision: 0.9524 - recall: 0.9196 - val_loss: 0.6186 - val_categorical_accuracy: 0.7959 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 468/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3130 - categorical_accuracy: 0.9209 - precision: 0.9465 - recall: 0.9031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3130 - categorical_accuracy: 0.9209 - precision: 0.9465 - recall: 0.9031 - val_loss: 0.5545 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 469/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3280 - categorical_accuracy: 0.9184 - precision: 0.9413 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3280 - categorical_accuracy: 0.9184 - precision: 0.9413 - recall: 0.9005 - val_loss: 0.6549 - val_categorical_accuracy: 0.8163 - val_precision: 0.8387 - val_recall: 0.7959\n",
            "Epoch 470/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2914 - categorical_accuracy: 0.9286 - precision: 0.9469 - recall: 0.9094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2914 - categorical_accuracy: 0.9286 - precision: 0.9469 - recall: 0.9094 - val_loss: 0.5459 - val_categorical_accuracy: 0.8673 - val_precision: 0.9022 - val_recall: 0.8469\n",
            "Epoch 471/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2792 - categorical_accuracy: 0.9349 - precision: 0.9500 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2792 - categorical_accuracy: 0.9349 - precision: 0.9500 - recall: 0.9209 - val_loss: 0.4766 - val_categorical_accuracy: 0.8878 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 472/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3133 - categorical_accuracy: 0.9120 - precision: 0.9336 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3133 - categorical_accuracy: 0.9120 - precision: 0.9336 - recall: 0.8967 - val_loss: 0.7021 - val_categorical_accuracy: 0.7857 - val_precision: 0.7872 - val_recall: 0.7551\n",
            "Epoch 473/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2907 - categorical_accuracy: 0.9209 - precision: 0.9402 - recall: 0.9031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2907 - categorical_accuracy: 0.9209 - precision: 0.9402 - recall: 0.9031 - val_loss: 0.6081 - val_categorical_accuracy: 0.8265 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 474/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2772 - categorical_accuracy: 0.9349 - precision: 0.9490 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2772 - categorical_accuracy: 0.9349 - precision: 0.9490 - recall: 0.9260 - val_loss: 0.6555 - val_categorical_accuracy: 0.8367 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 475/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.9235 - precision: 0.9343 - recall: 0.9069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3046 - categorical_accuracy: 0.9235 - precision: 0.9343 - recall: 0.9069 - val_loss: 0.6308 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 476/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3319 - categorical_accuracy: 0.9056 - precision: 0.9224 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3319 - categorical_accuracy: 0.9056 - precision: 0.9224 - recall: 0.8941 - val_loss: 1.2414 - val_categorical_accuracy: 0.7347 - val_precision: 0.7419 - val_recall: 0.7041\n",
            "Epoch 477/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3994 - categorical_accuracy: 0.8878 - precision: 0.9085 - recall: 0.8737"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3994 - categorical_accuracy: 0.8878 - precision: 0.9085 - recall: 0.8737 - val_loss: 0.8519 - val_categorical_accuracy: 0.7653 - val_precision: 0.7979 - val_recall: 0.7653\n",
            "Epoch 478/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3048 - categorical_accuracy: 0.9260 - precision: 0.9432 - recall: 0.9107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3048 - categorical_accuracy: 0.9260 - precision: 0.9432 - recall: 0.9107 - val_loss: 0.5093 - val_categorical_accuracy: 0.8776 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 479/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2921 - categorical_accuracy: 0.9235 - precision: 0.9373 - recall: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2921 - categorical_accuracy: 0.9235 - precision: 0.9373 - recall: 0.9158 - val_loss: 0.6888 - val_categorical_accuracy: 0.8061 - val_precision: 0.8404 - val_recall: 0.8061\n",
            "Epoch 480/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3271 - categorical_accuracy: 0.9120 - precision: 0.9238 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3271 - categorical_accuracy: 0.9120 - precision: 0.9238 - recall: 0.8967 - val_loss: 0.6140 - val_categorical_accuracy: 0.8367 - val_precision: 0.8804 - val_recall: 0.8265\n",
            "Epoch 481/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2931 - categorical_accuracy: 0.9324 - precision: 0.9495 - recall: 0.9107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2931 - categorical_accuracy: 0.9324 - precision: 0.9495 - recall: 0.9107 - val_loss: 0.6942 - val_categorical_accuracy: 0.8061 - val_precision: 0.8370 - val_recall: 0.7857\n",
            "Epoch 482/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2937 - categorical_accuracy: 0.9298 - precision: 0.9447 - recall: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2937 - categorical_accuracy: 0.9298 - precision: 0.9447 - recall: 0.9145 - val_loss: 0.7565 - val_categorical_accuracy: 0.7449 - val_precision: 0.7935 - val_recall: 0.7449\n",
            "Epoch 483/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3694 - categorical_accuracy: 0.9056 - precision: 0.9240 - recall: 0.8839"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3694 - categorical_accuracy: 0.9056 - precision: 0.9240 - recall: 0.8839 - val_loss: 0.5395 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 484/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2574 - categorical_accuracy: 0.9490 - precision: 0.9563 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2574 - categorical_accuracy: 0.9490 - precision: 0.9563 - recall: 0.9222 - val_loss: 0.4589 - val_categorical_accuracy: 0.8673 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 485/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2780 - categorical_accuracy: 0.9349 - precision: 0.9553 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2780 - categorical_accuracy: 0.9349 - precision: 0.9553 - recall: 0.9260 - val_loss: 0.7297 - val_categorical_accuracy: 0.7857 - val_precision: 0.8085 - val_recall: 0.7755\n",
            "Epoch 486/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2713 - categorical_accuracy: 0.9324 - precision: 0.9548 - recall: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2713 - categorical_accuracy: 0.9324 - precision: 0.9548 - recall: 0.9158 - val_loss: 0.5435 - val_categorical_accuracy: 0.8163 - val_precision: 0.8696 - val_recall: 0.8163\n",
            "Epoch 487/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2683 - categorical_accuracy: 0.9452 - precision: 0.9551 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2683 - categorical_accuracy: 0.9452 - precision: 0.9551 - recall: 0.9222 - val_loss: 0.5515 - val_categorical_accuracy: 0.8571 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 488/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2718 - categorical_accuracy: 0.9324 - precision: 0.9476 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2718 - categorical_accuracy: 0.9324 - precision: 0.9476 - recall: 0.9222 - val_loss: 0.5589 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 489/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2606 - categorical_accuracy: 0.9375 - precision: 0.9469 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2606 - categorical_accuracy: 0.9375 - precision: 0.9469 - recall: 0.9324 - val_loss: 0.4903 - val_categorical_accuracy: 0.8980 - val_precision: 0.9255 - val_recall: 0.8878\n",
            "Epoch 490/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2738 - categorical_accuracy: 0.9362 - precision: 0.9466 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2738 - categorical_accuracy: 0.9362 - precision: 0.9466 - recall: 0.9273 - val_loss: 0.5374 - val_categorical_accuracy: 0.8776 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 491/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2690 - categorical_accuracy: 0.9401 - precision: 0.9528 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2690 - categorical_accuracy: 0.9401 - precision: 0.9528 - recall: 0.9273 - val_loss: 0.5962 - val_categorical_accuracy: 0.8469 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 492/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2578 - categorical_accuracy: 0.9426 - precision: 0.9595 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2578 - categorical_accuracy: 0.9426 - precision: 0.9595 - recall: 0.9362 - val_loss: 0.4902 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 493/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2651 - categorical_accuracy: 0.9311 - precision: 0.9476 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2651 - categorical_accuracy: 0.9311 - precision: 0.9476 - recall: 0.9222 - val_loss: 0.5948 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 494/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2442 - categorical_accuracy: 0.9452 - precision: 0.9569 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2442 - categorical_accuracy: 0.9452 - precision: 0.9569 - recall: 0.9349 - val_loss: 0.7116 - val_categorical_accuracy: 0.7959 - val_precision: 0.7938 - val_recall: 0.7857\n",
            "Epoch 495/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2667 - categorical_accuracy: 0.9388 - precision: 0.9550 - recall: 0.9196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2667 - categorical_accuracy: 0.9388 - precision: 0.9550 - recall: 0.9196 - val_loss: 0.5455 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 496/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2766 - categorical_accuracy: 0.9324 - precision: 0.9433 - recall: 0.9120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2766 - categorical_accuracy: 0.9324 - precision: 0.9433 - recall: 0.9120 - val_loss: 0.4925 - val_categorical_accuracy: 0.9184 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 497/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2989 - categorical_accuracy: 0.9337 - precision: 0.9460 - recall: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.2989 - categorical_accuracy: 0.9337 - precision: 0.9460 - recall: 0.9158 - val_loss: 0.5018 - val_categorical_accuracy: 0.8776 - val_precision: 0.9032 - val_recall: 0.8571\n",
            "Epoch 498/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2448 - categorical_accuracy: 0.9515 - precision: 0.9648 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2448 - categorical_accuracy: 0.9515 - precision: 0.9648 - recall: 0.9426 - val_loss: 0.6503 - val_categorical_accuracy: 0.8061 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 499/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2887 - categorical_accuracy: 0.9222 - precision: 0.9441 - recall: 0.9056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2887 - categorical_accuracy: 0.9222 - precision: 0.9441 - recall: 0.9056 - val_loss: 0.6692 - val_categorical_accuracy: 0.8367 - val_precision: 0.8804 - val_recall: 0.8265\n",
            "Epoch 500/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2862 - categorical_accuracy: 0.9311 - precision: 0.9409 - recall: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2862 - categorical_accuracy: 0.9311 - precision: 0.9409 - recall: 0.9145 - val_loss: 0.6740 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 501/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2882 - categorical_accuracy: 0.9222 - precision: 0.9430 - recall: 0.9082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2882 - categorical_accuracy: 0.9222 - precision: 0.9430 - recall: 0.9082 - val_loss: 1.0228 - val_categorical_accuracy: 0.6939 - val_precision: 0.7416 - val_recall: 0.6735\n",
            "Epoch 502/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3188 - categorical_accuracy: 0.9120 - precision: 0.9193 - recall: 0.8865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3188 - categorical_accuracy: 0.9120 - precision: 0.9193 - recall: 0.8865 - val_loss: 0.5982 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 503/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2804 - categorical_accuracy: 0.9247 - precision: 0.9410 - recall: 0.9158"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2804 - categorical_accuracy: 0.9247 - precision: 0.9410 - recall: 0.9158 - val_loss: 0.6906 - val_categorical_accuracy: 0.7959 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 504/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2744 - categorical_accuracy: 0.9362 - precision: 0.9501 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2744 - categorical_accuracy: 0.9362 - precision: 0.9501 - recall: 0.9235 - val_loss: 0.5595 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 505/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2512 - categorical_accuracy: 0.9413 - precision: 0.9504 - recall: 0.9286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2512 - categorical_accuracy: 0.9413 - precision: 0.9504 - recall: 0.9286 - val_loss: 0.5298 - val_categorical_accuracy: 0.8673 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 506/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2913 - categorical_accuracy: 0.9337 - precision: 0.9440 - recall: 0.9247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2913 - categorical_accuracy: 0.9337 - precision: 0.9440 - recall: 0.9247 - val_loss: 0.5237 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 507/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2499 - categorical_accuracy: 0.9490 - precision: 0.9533 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2499 - categorical_accuracy: 0.9490 - precision: 0.9533 - recall: 0.9375 - val_loss: 0.5198 - val_categorical_accuracy: 0.8571 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 508/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2588 - categorical_accuracy: 0.9413 - precision: 0.9466 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2588 - categorical_accuracy: 0.9413 - precision: 0.9466 - recall: 0.9273 - val_loss: 0.5397 - val_categorical_accuracy: 0.8571 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 509/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2550 - categorical_accuracy: 0.9337 - precision: 0.9514 - recall: 0.9247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2550 - categorical_accuracy: 0.9337 - precision: 0.9514 - recall: 0.9247 - val_loss: 0.5601 - val_categorical_accuracy: 0.8469 - val_precision: 0.8901 - val_recall: 0.8265\n",
            "Epoch 510/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2671 - categorical_accuracy: 0.9439 - precision: 0.9542 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2671 - categorical_accuracy: 0.9439 - precision: 0.9542 - recall: 0.9298 - val_loss: 0.5821 - val_categorical_accuracy: 0.8367 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 511/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2357 - categorical_accuracy: 0.9464 - precision: 0.9582 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2357 - categorical_accuracy: 0.9464 - precision: 0.9582 - recall: 0.9349 - val_loss: 0.5756 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 512/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2603 - categorical_accuracy: 0.9401 - precision: 0.9617 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2603 - categorical_accuracy: 0.9401 - precision: 0.9617 - recall: 0.9298 - val_loss: 0.5847 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 513/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3011 - categorical_accuracy: 0.9260 - precision: 0.9358 - recall: 0.9107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3011 - categorical_accuracy: 0.9260 - precision: 0.9358 - recall: 0.9107 - val_loss: 0.5730 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 514/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3167 - categorical_accuracy: 0.9133 - precision: 0.9358 - recall: 0.8929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.3167 - categorical_accuracy: 0.9133 - precision: 0.9358 - recall: 0.8929 - val_loss: 0.5946 - val_categorical_accuracy: 0.8265 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 515/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2602 - categorical_accuracy: 0.9401 - precision: 0.9477 - recall: 0.9247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2602 - categorical_accuracy: 0.9401 - precision: 0.9477 - recall: 0.9247 - val_loss: 0.5466 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 516/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3120 - categorical_accuracy: 0.9120 - precision: 0.9229 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3120 - categorical_accuracy: 0.9120 - precision: 0.9229 - recall: 0.9005 - val_loss: 0.6690 - val_categorical_accuracy: 0.8061 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 517/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2575 - categorical_accuracy: 0.9426 - precision: 0.9517 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.2575 - categorical_accuracy: 0.9426 - precision: 0.9517 - recall: 0.9298 - val_loss: 0.5685 - val_categorical_accuracy: 0.8571 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 518/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2408 - categorical_accuracy: 0.9464 - precision: 0.9595 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2408 - categorical_accuracy: 0.9464 - precision: 0.9595 - recall: 0.9362 - val_loss: 0.5055 - val_categorical_accuracy: 0.8571 - val_precision: 0.9032 - val_recall: 0.8571\n",
            "Epoch 519/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2584 - categorical_accuracy: 0.9401 - precision: 0.9553 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2584 - categorical_accuracy: 0.9401 - precision: 0.9553 - recall: 0.9273 - val_loss: 0.7703 - val_categorical_accuracy: 0.7959 - val_precision: 0.8152 - val_recall: 0.7653\n",
            "Epoch 520/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2460 - categorical_accuracy: 0.9477 - precision: 0.9594 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2460 - categorical_accuracy: 0.9477 - precision: 0.9594 - recall: 0.9349 - val_loss: 0.7994 - val_categorical_accuracy: 0.7755 - val_precision: 0.7766 - val_recall: 0.7449\n",
            "Epoch 521/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2783 - categorical_accuracy: 0.9337 - precision: 0.9461 - recall: 0.9171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2783 - categorical_accuracy: 0.9337 - precision: 0.9461 - recall: 0.9171 - val_loss: 0.6326 - val_categorical_accuracy: 0.8265 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 522/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3003 - categorical_accuracy: 0.9133 - precision: 0.9304 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3003 - categorical_accuracy: 0.9133 - precision: 0.9304 - recall: 0.9043 - val_loss: 0.5690 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 523/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2405 - categorical_accuracy: 0.9426 - precision: 0.9565 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2405 - categorical_accuracy: 0.9426 - precision: 0.9565 - recall: 0.9260 - val_loss: 0.5206 - val_categorical_accuracy: 0.8776 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 524/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2516 - categorical_accuracy: 0.9413 - precision: 0.9578 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2516 - categorical_accuracy: 0.9413 - precision: 0.9578 - recall: 0.9273 - val_loss: 0.6096 - val_categorical_accuracy: 0.8163 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 525/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2326 - categorical_accuracy: 0.9452 - precision: 0.9570 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2326 - categorical_accuracy: 0.9452 - precision: 0.9570 - recall: 0.9375 - val_loss: 0.5098 - val_categorical_accuracy: 0.8469 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 526/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2494 - categorical_accuracy: 0.9388 - precision: 0.9592 - recall: 0.9286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2494 - categorical_accuracy: 0.9388 - precision: 0.9592 - recall: 0.9286 - val_loss: 0.5415 - val_categorical_accuracy: 0.8878 - val_precision: 0.9158 - val_recall: 0.8878\n",
            "Epoch 527/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2425 - categorical_accuracy: 0.9490 - precision: 0.9644 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2425 - categorical_accuracy: 0.9490 - precision: 0.9644 - recall: 0.9324 - val_loss: 0.4951 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 528/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2844 - categorical_accuracy: 0.9222 - precision: 0.9396 - recall: 0.9133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2844 - categorical_accuracy: 0.9222 - precision: 0.9396 - recall: 0.9133 - val_loss: 0.6605 - val_categorical_accuracy: 0.8571 - val_precision: 0.8804 - val_recall: 0.8265\n",
            "Epoch 529/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2685 - categorical_accuracy: 0.9311 - precision: 0.9576 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2685 - categorical_accuracy: 0.9311 - precision: 0.9576 - recall: 0.9222 - val_loss: 0.7967 - val_categorical_accuracy: 0.7959 - val_precision: 0.8000 - val_recall: 0.7755\n",
            "Epoch 530/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2323 - categorical_accuracy: 0.9464 - precision: 0.9594 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.2323 - categorical_accuracy: 0.9464 - precision: 0.9594 - recall: 0.9337 - val_loss: 0.5342 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 531/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2744 - categorical_accuracy: 0.9349 - precision: 0.9437 - recall: 0.9196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.2744 - categorical_accuracy: 0.9349 - precision: 0.9437 - recall: 0.9196 - val_loss: 0.7315 - val_categorical_accuracy: 0.7857 - val_precision: 0.7979 - val_recall: 0.7653\n",
            "Epoch 532/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2500 - categorical_accuracy: 0.9490 - precision: 0.9609 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2500 - categorical_accuracy: 0.9490 - precision: 0.9609 - recall: 0.9401 - val_loss: 0.6941 - val_categorical_accuracy: 0.8367 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 533/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2624 - categorical_accuracy: 0.9375 - precision: 0.9524 - recall: 0.9184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2624 - categorical_accuracy: 0.9375 - precision: 0.9524 - recall: 0.9184 - val_loss: 0.7130 - val_categorical_accuracy: 0.8163 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 534/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2657 - categorical_accuracy: 0.9349 - precision: 0.9464 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2657 - categorical_accuracy: 0.9349 - precision: 0.9464 - recall: 0.9235 - val_loss: 0.5289 - val_categorical_accuracy: 0.8469 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 535/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2462 - categorical_accuracy: 0.9503 - precision: 0.9583 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2462 - categorical_accuracy: 0.9503 - precision: 0.9583 - recall: 0.9375 - val_loss: 0.5885 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 536/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2435 - categorical_accuracy: 0.9413 - precision: 0.9491 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 129ms/step - loss: 0.2435 - categorical_accuracy: 0.9413 - precision: 0.9491 - recall: 0.9273 - val_loss: 0.4824 - val_categorical_accuracy: 0.8571 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 537/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2436 - categorical_accuracy: 0.9388 - precision: 0.9505 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 166ms/step - loss: 0.2436 - categorical_accuracy: 0.9388 - precision: 0.9505 - recall: 0.9298 - val_loss: 0.5686 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 538/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2241 - categorical_accuracy: 0.9579 - precision: 0.9635 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 156ms/step - loss: 0.2241 - categorical_accuracy: 0.9579 - precision: 0.9635 - recall: 0.9426 - val_loss: 0.5470 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 539/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2462 - categorical_accuracy: 0.9490 - precision: 0.9568 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.2462 - categorical_accuracy: 0.9490 - precision: 0.9568 - recall: 0.9324 - val_loss: 0.6847 - val_categorical_accuracy: 0.7857 - val_precision: 0.8242 - val_recall: 0.7653\n",
            "Epoch 540/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2888 - categorical_accuracy: 0.9209 - precision: 0.9345 - recall: 0.9094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2888 - categorical_accuracy: 0.9209 - precision: 0.9345 - recall: 0.9094 - val_loss: 0.8058 - val_categorical_accuracy: 0.7755 - val_precision: 0.7917 - val_recall: 0.7755\n",
            "Epoch 541/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3137 - categorical_accuracy: 0.9184 - precision: 0.9351 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3137 - categorical_accuracy: 0.9184 - precision: 0.9351 - recall: 0.9005 - val_loss: 0.5795 - val_categorical_accuracy: 0.8673 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 542/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2456 - categorical_accuracy: 0.9439 - precision: 0.9518 - recall: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2456 - categorical_accuracy: 0.9439 - precision: 0.9518 - recall: 0.9311 - val_loss: 0.6299 - val_categorical_accuracy: 0.8367 - val_precision: 0.8462 - val_recall: 0.7857\n",
            "Epoch 543/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2767 - categorical_accuracy: 0.9209 - precision: 0.9311 - recall: 0.9133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2767 - categorical_accuracy: 0.9209 - precision: 0.9311 - recall: 0.9133 - val_loss: 0.7315 - val_categorical_accuracy: 0.8163 - val_precision: 0.8387 - val_recall: 0.7959\n",
            "Epoch 544/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3176 - categorical_accuracy: 0.9094 - precision: 0.9214 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3176 - categorical_accuracy: 0.9094 - precision: 0.9214 - recall: 0.8967 - val_loss: 0.5220 - val_categorical_accuracy: 0.8673 - val_precision: 0.9111 - val_recall: 0.8367\n",
            "Epoch 545/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2454 - categorical_accuracy: 0.9452 - precision: 0.9529 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2454 - categorical_accuracy: 0.9452 - precision: 0.9529 - recall: 0.9298 - val_loss: 0.6386 - val_categorical_accuracy: 0.8367 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 546/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2627 - categorical_accuracy: 0.9298 - precision: 0.9463 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.2627 - categorical_accuracy: 0.9298 - precision: 0.9463 - recall: 0.9209 - val_loss: 0.5470 - val_categorical_accuracy: 0.8571 - val_precision: 0.8778 - val_recall: 0.8061\n",
            "Epoch 547/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2877 - categorical_accuracy: 0.9235 - precision: 0.9359 - recall: 0.9120"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2877 - categorical_accuracy: 0.9235 - precision: 0.9359 - recall: 0.9120 - val_loss: 0.5558 - val_categorical_accuracy: 0.8469 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 548/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2445 - categorical_accuracy: 0.9464 - precision: 0.9580 - recall: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2445 - categorical_accuracy: 0.9464 - precision: 0.9580 - recall: 0.9311 - val_loss: 0.5877 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 549/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2313 - categorical_accuracy: 0.9554 - precision: 0.9648 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2313 - categorical_accuracy: 0.9554 - precision: 0.9648 - recall: 0.9439 - val_loss: 0.5694 - val_categorical_accuracy: 0.8469 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 550/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2440 - categorical_accuracy: 0.9426 - precision: 0.9505 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2440 - categorical_accuracy: 0.9426 - precision: 0.9505 - recall: 0.9298 - val_loss: 0.6213 - val_categorical_accuracy: 0.8061 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 551/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2251 - categorical_accuracy: 0.9630 - precision: 0.9699 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2251 - categorical_accuracy: 0.9630 - precision: 0.9699 - recall: 0.9464 - val_loss: 0.5583 - val_categorical_accuracy: 0.8776 - val_precision: 0.9022 - val_recall: 0.8469\n",
            "Epoch 552/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2174 - categorical_accuracy: 0.9605 - precision: 0.9674 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2174 - categorical_accuracy: 0.9605 - precision: 0.9674 - recall: 0.9477 - val_loss: 0.5174 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 553/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2312 - categorical_accuracy: 0.9477 - precision: 0.9659 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2312 - categorical_accuracy: 0.9477 - precision: 0.9659 - recall: 0.9401 - val_loss: 0.7341 - val_categorical_accuracy: 0.8061 - val_precision: 0.8444 - val_recall: 0.7755\n",
            "Epoch 554/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3184 - categorical_accuracy: 0.9043 - precision: 0.9154 - recall: 0.8967"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 91ms/step - loss: 0.3184 - categorical_accuracy: 0.9043 - precision: 0.9154 - recall: 0.8967 - val_loss: 0.5740 - val_categorical_accuracy: 0.8878 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 555/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2663 - categorical_accuracy: 0.9388 - precision: 0.9490 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2663 - categorical_accuracy: 0.9388 - precision: 0.9490 - recall: 0.9260 - val_loss: 0.5817 - val_categorical_accuracy: 0.8163 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 556/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2686 - categorical_accuracy: 0.9349 - precision: 0.9426 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 90ms/step - loss: 0.2686 - categorical_accuracy: 0.9349 - precision: 0.9426 - recall: 0.9222 - val_loss: 0.4765 - val_categorical_accuracy: 0.8673 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 557/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2419 - categorical_accuracy: 0.9452 - precision: 0.9580 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2419 - categorical_accuracy: 0.9452 - precision: 0.9580 - recall: 0.9298 - val_loss: 0.4798 - val_categorical_accuracy: 0.8673 - val_precision: 0.9239 - val_recall: 0.8673\n",
            "Epoch 558/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2313 - categorical_accuracy: 0.9503 - precision: 0.9574 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2313 - categorical_accuracy: 0.9503 - precision: 0.9574 - recall: 0.9452 - val_loss: 0.5751 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 559/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2138 - categorical_accuracy: 0.9579 - precision: 0.9648 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2138 - categorical_accuracy: 0.9579 - precision: 0.9648 - recall: 0.9452 - val_loss: 0.5688 - val_categorical_accuracy: 0.8367 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 560/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2055 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2055 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9566 - val_loss: 0.4793 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 561/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2064 - categorical_accuracy: 0.9566 - precision: 0.9621 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2064 - categorical_accuracy: 0.9566 - precision: 0.9621 - recall: 0.9388 - val_loss: 0.5521 - val_categorical_accuracy: 0.8367 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 562/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2299 - categorical_accuracy: 0.9439 - precision: 0.9533 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2299 - categorical_accuracy: 0.9439 - precision: 0.9533 - recall: 0.9375 - val_loss: 0.5600 - val_categorical_accuracy: 0.8571 - val_precision: 0.8913 - val_recall: 0.8367\n",
            "Epoch 563/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2614 - categorical_accuracy: 0.9337 - precision: 0.9475 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2614 - categorical_accuracy: 0.9337 - precision: 0.9475 - recall: 0.9209 - val_loss: 0.6742 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 564/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2506 - categorical_accuracy: 0.9426 - precision: 0.9506 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2506 - categorical_accuracy: 0.9426 - precision: 0.9506 - recall: 0.9337 - val_loss: 0.5597 - val_categorical_accuracy: 0.8571 - val_precision: 0.8804 - val_recall: 0.8265\n",
            "Epoch 565/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2480 - categorical_accuracy: 0.9337 - precision: 0.9403 - recall: 0.9247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2480 - categorical_accuracy: 0.9337 - precision: 0.9403 - recall: 0.9247 - val_loss: 0.6383 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 566/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2157 - categorical_accuracy: 0.9490 - precision: 0.9634 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2157 - categorical_accuracy: 0.9490 - precision: 0.9634 - recall: 0.9388 - val_loss: 0.6872 - val_categorical_accuracy: 0.8061 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 567/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2237 - categorical_accuracy: 0.9464 - precision: 0.9620 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2237 - categorical_accuracy: 0.9464 - precision: 0.9620 - recall: 0.9362 - val_loss: 0.4827 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 568/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2572 - categorical_accuracy: 0.9401 - precision: 0.9481 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2572 - categorical_accuracy: 0.9401 - precision: 0.9481 - recall: 0.9324 - val_loss: 0.9572 - val_categorical_accuracy: 0.7245 - val_precision: 0.7500 - val_recall: 0.7041\n",
            "Epoch 569/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3440 - categorical_accuracy: 0.9082 - precision: 0.9140 - recall: 0.8941"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.3440 - categorical_accuracy: 0.9082 - precision: 0.9140 - recall: 0.8941 - val_loss: 0.5208 - val_categorical_accuracy: 0.8673 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 570/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3076 - categorical_accuracy: 0.9158 - precision: 0.9327 - recall: 0.9018"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.3076 - categorical_accuracy: 0.9158 - precision: 0.9327 - recall: 0.9018 - val_loss: 0.8138 - val_categorical_accuracy: 0.7959 - val_precision: 0.8021 - val_recall: 0.7857\n",
            "Epoch 571/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2799 - categorical_accuracy: 0.9235 - precision: 0.9324 - recall: 0.9145"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2799 - categorical_accuracy: 0.9235 - precision: 0.9324 - recall: 0.9145 - val_loss: 0.5431 - val_categorical_accuracy: 0.8469 - val_precision: 0.8804 - val_recall: 0.8265\n",
            "Epoch 572/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2225 - categorical_accuracy: 0.9566 - precision: 0.9673 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2225 - categorical_accuracy: 0.9566 - precision: 0.9673 - recall: 0.9426 - val_loss: 0.6550 - val_categorical_accuracy: 0.8163 - val_precision: 0.8478 - val_recall: 0.7959\n",
            "Epoch 573/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2404 - categorical_accuracy: 0.9464 - precision: 0.9581 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2404 - categorical_accuracy: 0.9464 - precision: 0.9581 - recall: 0.9324 - val_loss: 0.6281 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 574/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2575 - categorical_accuracy: 0.9184 - precision: 0.9393 - recall: 0.9082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2575 - categorical_accuracy: 0.9184 - precision: 0.9393 - recall: 0.9082 - val_loss: 0.6009 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 575/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2605 - categorical_accuracy: 0.9324 - precision: 0.9541 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2605 - categorical_accuracy: 0.9324 - precision: 0.9541 - recall: 0.9273 - val_loss: 0.7245 - val_categorical_accuracy: 0.8163 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 576/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2327 - categorical_accuracy: 0.9426 - precision: 0.9556 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2327 - categorical_accuracy: 0.9426 - precision: 0.9556 - recall: 0.9324 - val_loss: 0.5483 - val_categorical_accuracy: 0.8571 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 577/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2327 - categorical_accuracy: 0.9477 - precision: 0.9594 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2327 - categorical_accuracy: 0.9477 - precision: 0.9594 - recall: 0.9349 - val_loss: 0.5463 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 578/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3046 - categorical_accuracy: 0.9184 - precision: 0.9399 - recall: 0.8980"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.3046 - categorical_accuracy: 0.9184 - precision: 0.9399 - recall: 0.8980 - val_loss: 0.7084 - val_categorical_accuracy: 0.8061 - val_precision: 0.8172 - val_recall: 0.7755\n",
            "Epoch 579/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2699 - categorical_accuracy: 0.9401 - precision: 0.9517 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2699 - categorical_accuracy: 0.9401 - precision: 0.9517 - recall: 0.9298 - val_loss: 0.5775 - val_categorical_accuracy: 0.8265 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 580/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2499 - categorical_accuracy: 0.9401 - precision: 0.9490 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2499 - categorical_accuracy: 0.9401 - precision: 0.9490 - recall: 0.9260 - val_loss: 0.5960 - val_categorical_accuracy: 0.8061 - val_precision: 0.8478 - val_recall: 0.7959\n",
            "Epoch 581/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2558 - categorical_accuracy: 0.9349 - precision: 0.9476 - recall: 0.9222"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2558 - categorical_accuracy: 0.9349 - precision: 0.9476 - recall: 0.9222 - val_loss: 0.5356 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 582/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9362 - precision: 0.9488 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2496 - categorical_accuracy: 0.9362 - precision: 0.9488 - recall: 0.9209 - val_loss: 0.6440 - val_categorical_accuracy: 0.8163 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 583/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2915 - categorical_accuracy: 0.9069 - precision: 0.9254 - recall: 0.8865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2915 - categorical_accuracy: 0.9069 - precision: 0.9254 - recall: 0.8865 - val_loss: 0.6692 - val_categorical_accuracy: 0.8265 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 584/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3129 - categorical_accuracy: 0.9171 - precision: 0.9314 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3129 - categorical_accuracy: 0.9171 - precision: 0.9314 - recall: 0.9005 - val_loss: 0.6991 - val_categorical_accuracy: 0.8061 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 585/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3169 - categorical_accuracy: 0.9082 - precision: 0.9229 - recall: 0.8852"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.3169 - categorical_accuracy: 0.9082 - precision: 0.9229 - recall: 0.8852 - val_loss: 0.5825 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 586/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3266 - categorical_accuracy: 0.9094 - precision: 0.9193 - recall: 0.9005"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.3266 - categorical_accuracy: 0.9094 - precision: 0.9193 - recall: 0.9005 - val_loss: 0.5758 - val_categorical_accuracy: 0.8673 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 587/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2373 - categorical_accuracy: 0.9452 - precision: 0.9531 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2373 - categorical_accuracy: 0.9452 - precision: 0.9531 - recall: 0.9337 - val_loss: 0.4935 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 588/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1967 - categorical_accuracy: 0.9605 - precision: 0.9764 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1967 - categorical_accuracy: 0.9605 - precision: 0.9764 - recall: 0.9515 - val_loss: 0.4892 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 589/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2079 - categorical_accuracy: 0.9592 - precision: 0.9639 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2079 - categorical_accuracy: 0.9592 - precision: 0.9639 - recall: 0.9528 - val_loss: 0.5258 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 590/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2069 - categorical_accuracy: 0.9617 - precision: 0.9639 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2069 - categorical_accuracy: 0.9617 - precision: 0.9639 - recall: 0.9541 - val_loss: 0.5631 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 591/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2155 - categorical_accuracy: 0.9541 - precision: 0.9611 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2155 - categorical_accuracy: 0.9541 - precision: 0.9611 - recall: 0.9464 - val_loss: 0.4985 - val_categorical_accuracy: 0.8776 - val_precision: 0.9247 - val_recall: 0.8776\n",
            "Epoch 592/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1936 - categorical_accuracy: 0.9592 - precision: 0.9677 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1936 - categorical_accuracy: 0.9592 - precision: 0.9677 - recall: 0.9541 - val_loss: 0.5627 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 593/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1929 - categorical_accuracy: 0.9668 - precision: 0.9702 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1929 - categorical_accuracy: 0.9668 - precision: 0.9702 - recall: 0.9541 - val_loss: 0.6384 - val_categorical_accuracy: 0.8265 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 594/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1892 - categorical_accuracy: 0.9566 - precision: 0.9676 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1892 - categorical_accuracy: 0.9566 - precision: 0.9676 - recall: 0.9515 - val_loss: 0.5833 - val_categorical_accuracy: 0.8776 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 595/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2176 - categorical_accuracy: 0.9439 - precision: 0.9471 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2176 - categorical_accuracy: 0.9439 - precision: 0.9471 - recall: 0.9362 - val_loss: 0.6703 - val_categorical_accuracy: 0.7857 - val_precision: 0.8105 - val_recall: 0.7857\n",
            "Epoch 596/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2074 - categorical_accuracy: 0.9554 - precision: 0.9649 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2074 - categorical_accuracy: 0.9554 - precision: 0.9649 - recall: 0.9464 - val_loss: 0.5571 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 597/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2088 - categorical_accuracy: 0.9490 - precision: 0.9549 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2088 - categorical_accuracy: 0.9490 - precision: 0.9549 - recall: 0.9452 - val_loss: 0.5424 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 598/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2481 - categorical_accuracy: 0.9401 - precision: 0.9470 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2481 - categorical_accuracy: 0.9401 - precision: 0.9470 - recall: 0.9349 - val_loss: 0.5791 - val_categorical_accuracy: 0.8367 - val_precision: 0.8791 - val_recall: 0.8163\n",
            "Epoch 599/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2020 - categorical_accuracy: 0.9592 - precision: 0.9638 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2020 - categorical_accuracy: 0.9592 - precision: 0.9638 - recall: 0.9503 - val_loss: 0.5506 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 600/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2078 - categorical_accuracy: 0.9554 - precision: 0.9612 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2078 - categorical_accuracy: 0.9554 - precision: 0.9612 - recall: 0.9490 - val_loss: 0.4819 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 601/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1953 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1953 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9528 - val_loss: 0.5009 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 602/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2030 - categorical_accuracy: 0.9515 - precision: 0.9572 - recall: 0.9413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2030 - categorical_accuracy: 0.9515 - precision: 0.9572 - recall: 0.9413 - val_loss: 0.4744 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 603/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2167 - categorical_accuracy: 0.9515 - precision: 0.9633 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2167 - categorical_accuracy: 0.9515 - precision: 0.9633 - recall: 0.9375 - val_loss: 0.5893 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 604/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2623 - categorical_accuracy: 0.9337 - precision: 0.9379 - recall: 0.9247"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2623 - categorical_accuracy: 0.9337 - precision: 0.9379 - recall: 0.9247 - val_loss: 0.5480 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 605/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2496 - categorical_accuracy: 0.9413 - precision: 0.9501 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2496 - categorical_accuracy: 0.9413 - precision: 0.9501 - recall: 0.9235 - val_loss: 0.7369 - val_categorical_accuracy: 0.8061 - val_precision: 0.8280 - val_recall: 0.7857\n",
            "Epoch 606/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2256 - categorical_accuracy: 0.9464 - precision: 0.9569 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2256 - categorical_accuracy: 0.9464 - precision: 0.9569 - recall: 0.9349 - val_loss: 0.4381 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 607/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2254 - categorical_accuracy: 0.9426 - precision: 0.9554 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2254 - categorical_accuracy: 0.9426 - precision: 0.9554 - recall: 0.9298 - val_loss: 0.6215 - val_categorical_accuracy: 0.8265 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 608/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1946 - categorical_accuracy: 0.9528 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1946 - categorical_accuracy: 0.9528 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.5241 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 609/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1854 - categorical_accuracy: 0.9656 - precision: 0.9690 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1854 - categorical_accuracy: 0.9656 - precision: 0.9690 - recall: 0.9554 - val_loss: 0.4306 - val_categorical_accuracy: 0.8980 - val_precision: 0.9149 - val_recall: 0.8776\n",
            "Epoch 610/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1825 - categorical_accuracy: 0.9630 - precision: 0.9715 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1825 - categorical_accuracy: 0.9630 - precision: 0.9715 - recall: 0.9566 - val_loss: 0.4747 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 611/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1988 - categorical_accuracy: 0.9579 - precision: 0.9649 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1988 - categorical_accuracy: 0.9579 - precision: 0.9649 - recall: 0.9464 - val_loss: 0.4746 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 612/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2127 - categorical_accuracy: 0.9541 - precision: 0.9648 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.2127 - categorical_accuracy: 0.9541 - precision: 0.9648 - recall: 0.9426 - val_loss: 0.5678 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 613/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2078 - categorical_accuracy: 0.9528 - precision: 0.9588 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2078 - categorical_accuracy: 0.9528 - precision: 0.9588 - recall: 0.9490 - val_loss: 0.5322 - val_categorical_accuracy: 0.8776 - val_precision: 0.9149 - val_recall: 0.8776\n",
            "Epoch 614/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2187 - categorical_accuracy: 0.9464 - precision: 0.9583 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2187 - categorical_accuracy: 0.9464 - precision: 0.9583 - recall: 0.9375 - val_loss: 0.6219 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 615/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2326 - categorical_accuracy: 0.9490 - precision: 0.9523 - recall: 0.9413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2326 - categorical_accuracy: 0.9490 - precision: 0.9523 - recall: 0.9413 - val_loss: 0.4376 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 616/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2344 - categorical_accuracy: 0.9401 - precision: 0.9494 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2344 - categorical_accuracy: 0.9401 - precision: 0.9494 - recall: 0.9337 - val_loss: 0.5449 - val_categorical_accuracy: 0.8163 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 617/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2338 - categorical_accuracy: 0.9464 - precision: 0.9521 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2338 - categorical_accuracy: 0.9464 - precision: 0.9521 - recall: 0.9375 - val_loss: 0.6562 - val_categorical_accuracy: 0.8265 - val_precision: 0.8587 - val_recall: 0.8061\n",
            "Epoch 618/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2495 - categorical_accuracy: 0.9337 - precision: 0.9476 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2495 - categorical_accuracy: 0.9337 - precision: 0.9476 - recall: 0.9235 - val_loss: 0.5778 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 619/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2085 - categorical_accuracy: 0.9515 - precision: 0.9585 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2085 - categorical_accuracy: 0.9515 - precision: 0.9585 - recall: 0.9439 - val_loss: 0.6555 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 620/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2439 - categorical_accuracy: 0.9413 - precision: 0.9518 - recall: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2439 - categorical_accuracy: 0.9413 - precision: 0.9518 - recall: 0.9311 - val_loss: 0.5810 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 621/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2022 - categorical_accuracy: 0.9554 - precision: 0.9636 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2022 - categorical_accuracy: 0.9554 - precision: 0.9636 - recall: 0.9464 - val_loss: 0.7174 - val_categorical_accuracy: 0.8163 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 622/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1992 - categorical_accuracy: 0.9579 - precision: 0.9674 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1992 - categorical_accuracy: 0.9579 - precision: 0.9674 - recall: 0.9477 - val_loss: 0.5095 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 623/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1764 - categorical_accuracy: 0.9745 - precision: 0.9793 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1764 - categorical_accuracy: 0.9745 - precision: 0.9793 - recall: 0.9643 - val_loss: 0.4851 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 624/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1830 - categorical_accuracy: 0.9541 - precision: 0.9597 - recall: 0.9413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1830 - categorical_accuracy: 0.9541 - precision: 0.9597 - recall: 0.9413 - val_loss: 0.4923 - val_categorical_accuracy: 0.8980 - val_precision: 0.9239 - val_recall: 0.8673\n",
            "Epoch 625/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1801 - categorical_accuracy: 0.9694 - precision: 0.9780 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1801 - categorical_accuracy: 0.9694 - precision: 0.9780 - recall: 0.9617 - val_loss: 0.6345 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 626/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1908 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1908 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9554 - val_loss: 0.4932 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 627/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2031 - categorical_accuracy: 0.9579 - precision: 0.9689 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2031 - categorical_accuracy: 0.9579 - precision: 0.9689 - recall: 0.9528 - val_loss: 0.4322 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 628/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2077 - categorical_accuracy: 0.9464 - precision: 0.9571 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2077 - categorical_accuracy: 0.9464 - precision: 0.9571 - recall: 0.9388 - val_loss: 0.5747 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 629/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2011 - categorical_accuracy: 0.9541 - precision: 0.9662 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2011 - categorical_accuracy: 0.9541 - precision: 0.9662 - recall: 0.9477 - val_loss: 0.4373 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 630/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1914 - categorical_accuracy: 0.9617 - precision: 0.9714 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1914 - categorical_accuracy: 0.9617 - precision: 0.9714 - recall: 0.9541 - val_loss: 0.4960 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 631/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.9605 - precision: 0.9715 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1885 - categorical_accuracy: 0.9605 - precision: 0.9715 - recall: 0.9554 - val_loss: 0.6635 - val_categorical_accuracy: 0.8061 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 632/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1915 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1915 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9554 - val_loss: 0.6612 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 633/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1859 - categorical_accuracy: 0.9592 - precision: 0.9714 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1859 - categorical_accuracy: 0.9592 - precision: 0.9714 - recall: 0.9515 - val_loss: 0.7767 - val_categorical_accuracy: 0.8163 - val_precision: 0.8144 - val_recall: 0.8061\n",
            "Epoch 634/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2203 - categorical_accuracy: 0.9528 - precision: 0.9636 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2203 - categorical_accuracy: 0.9528 - precision: 0.9636 - recall: 0.9452 - val_loss: 0.4621 - val_categorical_accuracy: 0.8776 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 635/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2097 - categorical_accuracy: 0.9515 - precision: 0.9647 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 149ms/step - loss: 0.2097 - categorical_accuracy: 0.9515 - precision: 0.9647 - recall: 0.9401 - val_loss: 0.7048 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 636/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2064 - categorical_accuracy: 0.9566 - precision: 0.9638 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 173ms/step - loss: 0.2064 - categorical_accuracy: 0.9566 - precision: 0.9638 - recall: 0.9515 - val_loss: 0.5306 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 637/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1785 - categorical_accuracy: 0.9656 - precision: 0.9766 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 146ms/step - loss: 0.1785 - categorical_accuracy: 0.9656 - precision: 0.9766 - recall: 0.9579 - val_loss: 0.4789 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 638/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1807 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1807 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9605 - val_loss: 0.5688 - val_categorical_accuracy: 0.8265 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 639/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2240 - categorical_accuracy: 0.9439 - precision: 0.9558 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2240 - categorical_accuracy: 0.9439 - precision: 0.9558 - recall: 0.9375 - val_loss: 0.5526 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 640/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2535 - categorical_accuracy: 0.9324 - precision: 0.9389 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2535 - categorical_accuracy: 0.9324 - precision: 0.9389 - recall: 0.9209 - val_loss: 0.5524 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 641/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.3013 - categorical_accuracy: 0.9273 - precision: 0.9400 - recall: 0.9196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.3013 - categorical_accuracy: 0.9273 - precision: 0.9400 - recall: 0.9196 - val_loss: 1.0010 - val_categorical_accuracy: 0.7653 - val_precision: 0.7684 - val_recall: 0.7449\n",
            "Epoch 642/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2448 - categorical_accuracy: 0.9324 - precision: 0.9436 - recall: 0.9171"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2448 - categorical_accuracy: 0.9324 - precision: 0.9436 - recall: 0.9171 - val_loss: 0.7043 - val_categorical_accuracy: 0.8061 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 643/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2745 - categorical_accuracy: 0.9222 - precision: 0.9329 - recall: 0.9043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2745 - categorical_accuracy: 0.9222 - precision: 0.9329 - recall: 0.9043 - val_loss: 0.7711 - val_categorical_accuracy: 0.7347 - val_precision: 0.7423 - val_recall: 0.7347\n",
            "Epoch 644/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2166 - categorical_accuracy: 0.9566 - precision: 0.9635 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2166 - categorical_accuracy: 0.9566 - precision: 0.9635 - recall: 0.9426 - val_loss: 0.5189 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 645/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1688 - categorical_accuracy: 0.9732 - precision: 0.9768 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1688 - categorical_accuracy: 0.9732 - precision: 0.9768 - recall: 0.9681 - val_loss: 0.5017 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 646/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1914 - categorical_accuracy: 0.9630 - precision: 0.9701 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1914 - categorical_accuracy: 0.9630 - precision: 0.9701 - recall: 0.9528 - val_loss: 0.8114 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 647/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2855 - categorical_accuracy: 0.9286 - precision: 0.9444 - recall: 0.9107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2855 - categorical_accuracy: 0.9286 - precision: 0.9444 - recall: 0.9107 - val_loss: 0.6315 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 648/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2591 - categorical_accuracy: 0.9311 - precision: 0.9378 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2591 - categorical_accuracy: 0.9311 - precision: 0.9378 - recall: 0.9235 - val_loss: 0.7640 - val_categorical_accuracy: 0.8163 - val_precision: 0.8261 - val_recall: 0.7755\n",
            "Epoch 649/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2188 - categorical_accuracy: 0.9401 - precision: 0.9506 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2188 - categorical_accuracy: 0.9401 - precision: 0.9506 - recall: 0.9324 - val_loss: 0.4263 - val_categorical_accuracy: 0.8776 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 650/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1892 - categorical_accuracy: 0.9579 - precision: 0.9651 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1892 - categorical_accuracy: 0.9579 - precision: 0.9651 - recall: 0.9515 - val_loss: 0.5533 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 651/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1875 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1875 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9579 - val_loss: 0.8979 - val_categorical_accuracy: 0.7755 - val_precision: 0.7835 - val_recall: 0.7755\n",
            "Epoch 652/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1811 - categorical_accuracy: 0.9630 - precision: 0.9665 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1811 - categorical_accuracy: 0.9630 - precision: 0.9665 - recall: 0.9566 - val_loss: 0.5334 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 653/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1848 - categorical_accuracy: 0.9605 - precision: 0.9689 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1848 - categorical_accuracy: 0.9605 - precision: 0.9689 - recall: 0.9528 - val_loss: 0.4512 - val_categorical_accuracy: 0.8878 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 654/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1958 - categorical_accuracy: 0.9668 - precision: 0.9728 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1958 - categorical_accuracy: 0.9668 - precision: 0.9728 - recall: 0.9579 - val_loss: 0.5828 - val_categorical_accuracy: 0.8367 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 655/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1909 - categorical_accuracy: 0.9566 - precision: 0.9688 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1909 - categorical_accuracy: 0.9566 - precision: 0.9688 - recall: 0.9503 - val_loss: 0.5833 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 656/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1927 - categorical_accuracy: 0.9617 - precision: 0.9674 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1927 - categorical_accuracy: 0.9617 - precision: 0.9674 - recall: 0.9477 - val_loss: 0.5604 - val_categorical_accuracy: 0.8469 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 657/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1639 - categorical_accuracy: 0.9707 - precision: 0.9768 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1639 - categorical_accuracy: 0.9707 - precision: 0.9768 - recall: 0.9656 - val_loss: 0.4997 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 658/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9592 - precision: 0.9662 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1882 - categorical_accuracy: 0.9592 - precision: 0.9662 - recall: 0.9490 - val_loss: 0.5297 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 659/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2250 - categorical_accuracy: 0.9452 - precision: 0.9519 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2250 - categorical_accuracy: 0.9452 - precision: 0.9519 - recall: 0.9337 - val_loss: 0.6076 - val_categorical_accuracy: 0.8265 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 660/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2275 - categorical_accuracy: 0.9464 - precision: 0.9547 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2275 - categorical_accuracy: 0.9464 - precision: 0.9547 - recall: 0.9401 - val_loss: 0.5462 - val_categorical_accuracy: 0.8571 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 661/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1873 - categorical_accuracy: 0.9566 - precision: 0.9639 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1873 - categorical_accuracy: 0.9566 - precision: 0.9639 - recall: 0.9528 - val_loss: 0.5355 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 662/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2031 - categorical_accuracy: 0.9630 - precision: 0.9676 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2031 - categorical_accuracy: 0.9630 - precision: 0.9676 - recall: 0.9515 - val_loss: 0.5420 - val_categorical_accuracy: 0.8776 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 663/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2118 - categorical_accuracy: 0.9490 - precision: 0.9573 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2118 - categorical_accuracy: 0.9490 - precision: 0.9573 - recall: 0.9426 - val_loss: 0.4977 - val_categorical_accuracy: 0.8776 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 664/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2231 - categorical_accuracy: 0.9452 - precision: 0.9499 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2231 - categorical_accuracy: 0.9452 - precision: 0.9499 - recall: 0.9439 - val_loss: 0.5919 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 665/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1720 - categorical_accuracy: 0.9707 - precision: 0.9743 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1720 - categorical_accuracy: 0.9707 - precision: 0.9743 - recall: 0.9656 - val_loss: 0.6514 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 666/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1802 - categorical_accuracy: 0.9681 - precision: 0.9716 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1802 - categorical_accuracy: 0.9681 - precision: 0.9716 - recall: 0.9617 - val_loss: 0.5506 - val_categorical_accuracy: 0.8776 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 667/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2191 - categorical_accuracy: 0.9426 - precision: 0.9531 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2191 - categorical_accuracy: 0.9426 - precision: 0.9531 - recall: 0.9337 - val_loss: 0.5797 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 668/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1813 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1813 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9605 - val_loss: 0.6875 - val_categorical_accuracy: 0.8469 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 669/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1899 - categorical_accuracy: 0.9643 - precision: 0.9728 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1899 - categorical_accuracy: 0.9643 - precision: 0.9728 - recall: 0.9592 - val_loss: 0.4237 - val_categorical_accuracy: 0.8776 - val_precision: 0.9149 - val_recall: 0.8776\n",
            "Epoch 670/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1900 - categorical_accuracy: 0.9579 - precision: 0.9623 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1900 - categorical_accuracy: 0.9579 - precision: 0.9623 - recall: 0.9452 - val_loss: 0.6906 - val_categorical_accuracy: 0.8061 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 671/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2004 - categorical_accuracy: 0.9541 - precision: 0.9597 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2004 - categorical_accuracy: 0.9541 - precision: 0.9597 - recall: 0.9426 - val_loss: 0.5700 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 672/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2439 - categorical_accuracy: 0.9337 - precision: 0.9389 - recall: 0.9209"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2439 - categorical_accuracy: 0.9337 - precision: 0.9389 - recall: 0.9209 - val_loss: 0.8005 - val_categorical_accuracy: 0.7959 - val_precision: 0.8387 - val_recall: 0.7959\n",
            "Epoch 673/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2107 - categorical_accuracy: 0.9515 - precision: 0.9610 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2107 - categorical_accuracy: 0.9515 - precision: 0.9610 - recall: 0.9426 - val_loss: 0.7954 - val_categorical_accuracy: 0.8061 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 674/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2219 - categorical_accuracy: 0.9503 - precision: 0.9560 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.2219 - categorical_accuracy: 0.9503 - precision: 0.9560 - recall: 0.9426 - val_loss: 0.6334 - val_categorical_accuracy: 0.7959 - val_precision: 0.8191 - val_recall: 0.7857\n",
            "Epoch 675/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2507 - categorical_accuracy: 0.9375 - precision: 0.9406 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2507 - categorical_accuracy: 0.9375 - precision: 0.9406 - recall: 0.9298 - val_loss: 0.6809 - val_categorical_accuracy: 0.8061 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 676/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2289 - categorical_accuracy: 0.9375 - precision: 0.9516 - recall: 0.9286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.2289 - categorical_accuracy: 0.9375 - precision: 0.9516 - recall: 0.9286 - val_loss: 0.5691 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 677/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1993 - categorical_accuracy: 0.9592 - precision: 0.9662 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1993 - categorical_accuracy: 0.9592 - precision: 0.9662 - recall: 0.9490 - val_loss: 0.5496 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 678/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2034 - categorical_accuracy: 0.9503 - precision: 0.9559 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2034 - categorical_accuracy: 0.9503 - precision: 0.9559 - recall: 0.9401 - val_loss: 0.5508 - val_categorical_accuracy: 0.8163 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 679/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1933 - categorical_accuracy: 0.9579 - precision: 0.9650 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1933 - categorical_accuracy: 0.9579 - precision: 0.9650 - recall: 0.9503 - val_loss: 0.5412 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 680/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1798 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1798 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579 - val_loss: 0.4353 - val_categorical_accuracy: 0.8980 - val_precision: 0.9149 - val_recall: 0.8776\n",
            "Epoch 681/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1642 - categorical_accuracy: 0.9668 - precision: 0.9717 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1642 - categorical_accuracy: 0.9668 - precision: 0.9717 - recall: 0.9630 - val_loss: 0.4587 - val_categorical_accuracy: 0.9082 - val_precision: 0.9368 - val_recall: 0.9082\n",
            "Epoch 682/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2059 - categorical_accuracy: 0.9566 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2059 - categorical_accuracy: 0.9566 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.5494 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 683/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1725 - categorical_accuracy: 0.9668 - precision: 0.9691 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1725 - categorical_accuracy: 0.9668 - precision: 0.9691 - recall: 0.9592 - val_loss: 0.4247 - val_categorical_accuracy: 0.8776 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 684/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2137 - categorical_accuracy: 0.9452 - precision: 0.9558 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2137 - categorical_accuracy: 0.9452 - precision: 0.9558 - recall: 0.9388 - val_loss: 0.7238 - val_categorical_accuracy: 0.7959 - val_precision: 0.8125 - val_recall: 0.7959\n",
            "Epoch 685/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1846 - categorical_accuracy: 0.9579 - precision: 0.9590 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1846 - categorical_accuracy: 0.9579 - precision: 0.9590 - recall: 0.9541 - val_loss: 0.5453 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 686/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1790 - categorical_accuracy: 0.9579 - precision: 0.9638 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1790 - categorical_accuracy: 0.9579 - precision: 0.9638 - recall: 0.9503 - val_loss: 0.4889 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 687/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1813 - categorical_accuracy: 0.9643 - precision: 0.9716 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1813 - categorical_accuracy: 0.9643 - precision: 0.9716 - recall: 0.9592 - val_loss: 0.6115 - val_categorical_accuracy: 0.8265 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 688/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1713 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1713 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9566 - val_loss: 0.5301 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 689/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1684 - categorical_accuracy: 0.9668 - precision: 0.9753 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1684 - categorical_accuracy: 0.9668 - precision: 0.9753 - recall: 0.9554 - val_loss: 0.5870 - val_categorical_accuracy: 0.8469 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 690/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1796 - categorical_accuracy: 0.9592 - precision: 0.9675 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1796 - categorical_accuracy: 0.9592 - precision: 0.9675 - recall: 0.9503 - val_loss: 0.5780 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 691/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1876 - categorical_accuracy: 0.9503 - precision: 0.9611 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1876 - categorical_accuracy: 0.9503 - precision: 0.9611 - recall: 0.9452 - val_loss: 0.6222 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 692/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2269 - categorical_accuracy: 0.9439 - precision: 0.9484 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2269 - categorical_accuracy: 0.9439 - precision: 0.9484 - recall: 0.9375 - val_loss: 0.4468 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 693/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1952 - categorical_accuracy: 0.9528 - precision: 0.9611 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1952 - categorical_accuracy: 0.9528 - precision: 0.9611 - recall: 0.9464 - val_loss: 0.5310 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 694/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1555 - categorical_accuracy: 0.9719 - precision: 0.9768 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1555 - categorical_accuracy: 0.9719 - precision: 0.9768 - recall: 0.9668 - val_loss: 0.5848 - val_categorical_accuracy: 0.8163 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 695/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9605 - precision: 0.9626 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1660 - categorical_accuracy: 0.9605 - precision: 0.9626 - recall: 0.9528 - val_loss: 0.4482 - val_categorical_accuracy: 0.8980 - val_precision: 0.9255 - val_recall: 0.8878\n",
            "Epoch 696/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1710 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1710 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9617 - val_loss: 0.6938 - val_categorical_accuracy: 0.8061 - val_precision: 0.8280 - val_recall: 0.7857\n",
            "Epoch 697/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1690 - categorical_accuracy: 0.9643 - precision: 0.9716 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1690 - categorical_accuracy: 0.9643 - precision: 0.9716 - recall: 0.9592 - val_loss: 0.5719 - val_categorical_accuracy: 0.8469 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 698/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2205 - categorical_accuracy: 0.9503 - precision: 0.9570 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.2205 - categorical_accuracy: 0.9503 - precision: 0.9570 - recall: 0.9375 - val_loss: 0.5639 - val_categorical_accuracy: 0.8673 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 699/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2918 - categorical_accuracy: 0.9120 - precision: 0.9281 - recall: 0.9056"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.2918 - categorical_accuracy: 0.9120 - precision: 0.9281 - recall: 0.9056 - val_loss: 0.7833 - val_categorical_accuracy: 0.7653 - val_precision: 0.7812 - val_recall: 0.7653\n",
            "Epoch 700/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2230 - categorical_accuracy: 0.9426 - precision: 0.9553 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2230 - categorical_accuracy: 0.9426 - precision: 0.9553 - recall: 0.9273 - val_loss: 0.5403 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 701/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1833 - categorical_accuracy: 0.9541 - precision: 0.9673 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1833 - categorical_accuracy: 0.9541 - precision: 0.9673 - recall: 0.9439 - val_loss: 0.6458 - val_categorical_accuracy: 0.8367 - val_precision: 0.8696 - val_recall: 0.8163\n",
            "Epoch 702/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1899 - categorical_accuracy: 0.9554 - precision: 0.9613 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 92ms/step - loss: 0.1899 - categorical_accuracy: 0.9554 - precision: 0.9613 - recall: 0.9503 - val_loss: 0.6458 - val_categorical_accuracy: 0.8367 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 703/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1806 - categorical_accuracy: 0.9630 - precision: 0.9715 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1806 - categorical_accuracy: 0.9630 - precision: 0.9715 - recall: 0.9566 - val_loss: 0.5415 - val_categorical_accuracy: 0.8469 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 704/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1891 - categorical_accuracy: 0.9566 - precision: 0.9625 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 93ms/step - loss: 0.1891 - categorical_accuracy: 0.9566 - precision: 0.9625 - recall: 0.9490 - val_loss: 0.5020 - val_categorical_accuracy: 0.8878 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 705/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1810 - categorical_accuracy: 0.9630 - precision: 0.9689 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1810 - categorical_accuracy: 0.9630 - precision: 0.9689 - recall: 0.9528 - val_loss: 0.5166 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 706/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2040 - categorical_accuracy: 0.9515 - precision: 0.9599 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2040 - categorical_accuracy: 0.9515 - precision: 0.9599 - recall: 0.9477 - val_loss: 0.8503 - val_categorical_accuracy: 0.7959 - val_precision: 0.7959 - val_recall: 0.7959\n",
            "Epoch 707/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2000 - categorical_accuracy: 0.9515 - precision: 0.9611 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2000 - categorical_accuracy: 0.9515 - precision: 0.9611 - recall: 0.9452 - val_loss: 0.5262 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 708/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1596 - categorical_accuracy: 0.9656 - precision: 0.9691 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1596 - categorical_accuracy: 0.9656 - precision: 0.9691 - recall: 0.9605 - val_loss: 0.4179 - val_categorical_accuracy: 0.8980 - val_precision: 0.9158 - val_recall: 0.8878\n",
            "Epoch 709/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1623 - categorical_accuracy: 0.9694 - precision: 0.9766 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1623 - categorical_accuracy: 0.9694 - precision: 0.9766 - recall: 0.9592 - val_loss: 0.5818 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 710/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1445 - categorical_accuracy: 0.9745 - precision: 0.9768 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1445 - categorical_accuracy: 0.9745 - precision: 0.9768 - recall: 0.9681 - val_loss: 0.5423 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 711/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1516 - categorical_accuracy: 0.9745 - precision: 0.9769 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1516 - categorical_accuracy: 0.9745 - precision: 0.9769 - recall: 0.9694 - val_loss: 0.4664 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 712/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1942 - categorical_accuracy: 0.9566 - precision: 0.9612 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1942 - categorical_accuracy: 0.9566 - precision: 0.9612 - recall: 0.9477 - val_loss: 0.6406 - val_categorical_accuracy: 0.8265 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 713/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2107 - categorical_accuracy: 0.9515 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2107 - categorical_accuracy: 0.9515 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.5278 - val_categorical_accuracy: 0.8776 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 714/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1905 - categorical_accuracy: 0.9566 - precision: 0.9626 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1905 - categorical_accuracy: 0.9566 - precision: 0.9626 - recall: 0.9515 - val_loss: 0.5229 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 715/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1450 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1450 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681 - val_loss: 0.4894 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 716/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1609 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9732 - val_loss: 0.5193 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 717/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1509 - categorical_accuracy: 0.9745 - precision: 0.9819 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1509 - categorical_accuracy: 0.9745 - precision: 0.9819 - recall: 0.9681 - val_loss: 0.4414 - val_categorical_accuracy: 0.8980 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 718/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9707 - precision: 0.9741 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1704 - categorical_accuracy: 0.9707 - precision: 0.9741 - recall: 0.9592 - val_loss: 0.4914 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 719/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2343 - categorical_accuracy: 0.9388 - precision: 0.9457 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2343 - categorical_accuracy: 0.9388 - precision: 0.9457 - recall: 0.9324 - val_loss: 0.5279 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 720/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1975 - categorical_accuracy: 0.9554 - precision: 0.9587 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1975 - categorical_accuracy: 0.9554 - precision: 0.9587 - recall: 0.9464 - val_loss: 0.8065 - val_categorical_accuracy: 0.7959 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 721/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1784 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1784 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9528 - val_loss: 0.5385 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 722/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1628 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1628 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9605 - val_loss: 0.5305 - val_categorical_accuracy: 0.8571 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 723/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1869 - categorical_accuracy: 0.9579 - precision: 0.9640 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1869 - categorical_accuracy: 0.9579 - precision: 0.9640 - recall: 0.9554 - val_loss: 0.6321 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 724/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1639 - categorical_accuracy: 0.9694 - precision: 0.9742 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1639 - categorical_accuracy: 0.9694 - precision: 0.9742 - recall: 0.9643 - val_loss: 0.4236 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 725/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1910 - categorical_accuracy: 0.9541 - precision: 0.9561 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1910 - categorical_accuracy: 0.9541 - precision: 0.9561 - recall: 0.9439 - val_loss: 0.5373 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 726/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1662 - categorical_accuracy: 0.9681 - precision: 0.9716 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1662 - categorical_accuracy: 0.9681 - precision: 0.9716 - recall: 0.9592 - val_loss: 0.6399 - val_categorical_accuracy: 0.8265 - val_precision: 0.8511 - val_recall: 0.8163\n",
            "Epoch 727/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2247 - categorical_accuracy: 0.9401 - precision: 0.9483 - recall: 0.9362"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2247 - categorical_accuracy: 0.9401 - precision: 0.9483 - recall: 0.9362 - val_loss: 0.6343 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 728/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2254 - categorical_accuracy: 0.9464 - precision: 0.9512 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2254 - categorical_accuracy: 0.9464 - precision: 0.9512 - recall: 0.9452 - val_loss: 0.5074 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 729/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1694 - categorical_accuracy: 0.9681 - precision: 0.9692 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1694 - categorical_accuracy: 0.9681 - precision: 0.9692 - recall: 0.9643 - val_loss: 0.5361 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 730/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1673 - categorical_accuracy: 0.9617 - precision: 0.9690 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 164ms/step - loss: 0.1673 - categorical_accuracy: 0.9617 - precision: 0.9690 - recall: 0.9579 - val_loss: 0.5879 - val_categorical_accuracy: 0.8367 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 731/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1643 - categorical_accuracy: 0.9579 - precision: 0.9676 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 163ms/step - loss: 0.1643 - categorical_accuracy: 0.9579 - precision: 0.9676 - recall: 0.9528 - val_loss: 0.5580 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 732/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1591 - categorical_accuracy: 0.9656 - precision: 0.9729 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 149ms/step - loss: 0.1591 - categorical_accuracy: 0.9656 - precision: 0.9729 - recall: 0.9617 - val_loss: 0.5629 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 733/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1567 - categorical_accuracy: 0.9694 - precision: 0.9767 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1567 - categorical_accuracy: 0.9694 - precision: 0.9767 - recall: 0.9630 - val_loss: 0.7676 - val_categorical_accuracy: 0.8061 - val_precision: 0.8125 - val_recall: 0.7959\n",
            "Epoch 734/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1937 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1937 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9566 - val_loss: 0.7107 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 735/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1814 - categorical_accuracy: 0.9515 - precision: 0.9611 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1814 - categorical_accuracy: 0.9515 - precision: 0.9611 - recall: 0.9452 - val_loss: 0.9111 - val_categorical_accuracy: 0.7959 - val_precision: 0.8085 - val_recall: 0.7755\n",
            "Epoch 736/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1933 - categorical_accuracy: 0.9554 - precision: 0.9599 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1933 - categorical_accuracy: 0.9554 - precision: 0.9599 - recall: 0.9464 - val_loss: 0.4320 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 737/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1957 - categorical_accuracy: 0.9515 - precision: 0.9587 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1957 - categorical_accuracy: 0.9515 - precision: 0.9587 - recall: 0.9477 - val_loss: 0.5670 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 738/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1597 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1597 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9656 - val_loss: 0.4553 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 739/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1747 - categorical_accuracy: 0.9592 - precision: 0.9665 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1747 - categorical_accuracy: 0.9592 - precision: 0.9665 - recall: 0.9566 - val_loss: 0.5169 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 740/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1773 - categorical_accuracy: 0.9630 - precision: 0.9702 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1773 - categorical_accuracy: 0.9630 - precision: 0.9702 - recall: 0.9541 - val_loss: 0.4675 - val_categorical_accuracy: 0.8673 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 741/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1589 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1589 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9643 - val_loss: 0.6490 - val_categorical_accuracy: 0.8367 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 742/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2011 - categorical_accuracy: 0.9566 - precision: 0.9638 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2011 - categorical_accuracy: 0.9566 - precision: 0.9638 - recall: 0.9515 - val_loss: 0.7663 - val_categorical_accuracy: 0.8163 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 743/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1915 - categorical_accuracy: 0.9528 - precision: 0.9586 - recall: 0.9452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1915 - categorical_accuracy: 0.9528 - precision: 0.9586 - recall: 0.9452 - val_loss: 0.5866 - val_categorical_accuracy: 0.8571 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 744/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2445 - categorical_accuracy: 0.9362 - precision: 0.9457 - recall: 0.9337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2445 - categorical_accuracy: 0.9362 - precision: 0.9457 - recall: 0.9337 - val_loss: 0.5562 - val_categorical_accuracy: 0.8469 - val_precision: 0.8817 - val_recall: 0.8367\n",
            "Epoch 745/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1803 - categorical_accuracy: 0.9554 - precision: 0.9626 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1803 - categorical_accuracy: 0.9554 - precision: 0.9626 - recall: 0.9515 - val_loss: 0.4685 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 746/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1979 - categorical_accuracy: 0.9554 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1979 - categorical_accuracy: 0.9554 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.7163 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 747/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1629 - categorical_accuracy: 0.9656 - precision: 0.9703 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1629 - categorical_accuracy: 0.9656 - precision: 0.9703 - recall: 0.9579 - val_loss: 0.5590 - val_categorical_accuracy: 0.8469 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 748/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1377 - categorical_accuracy: 0.9872 - precision: 0.9884 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1377 - categorical_accuracy: 0.9872 - precision: 0.9884 - recall: 0.9821 - val_loss: 0.5206 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 749/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1832 - categorical_accuracy: 0.9541 - precision: 0.9612 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1832 - categorical_accuracy: 0.9541 - precision: 0.9612 - recall: 0.9477 - val_loss: 0.6003 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 750/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1703 - categorical_accuracy: 0.9617 - precision: 0.9641 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1703 - categorical_accuracy: 0.9617 - precision: 0.9641 - recall: 0.9592 - val_loss: 0.4862 - val_categorical_accuracy: 0.8776 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 751/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.9668 - precision: 0.9715 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1609 - categorical_accuracy: 0.9668 - precision: 0.9715 - recall: 0.9566 - val_loss: 0.4848 - val_categorical_accuracy: 0.8878 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 752/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1619 - categorical_accuracy: 0.9694 - precision: 0.9730 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1619 - categorical_accuracy: 0.9694 - precision: 0.9730 - recall: 0.9643 - val_loss: 0.5224 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 753/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1467 - categorical_accuracy: 0.9668 - precision: 0.9705 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1467 - categorical_accuracy: 0.9668 - precision: 0.9705 - recall: 0.9656 - val_loss: 0.4699 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 754/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1715 - categorical_accuracy: 0.9707 - precision: 0.9755 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1715 - categorical_accuracy: 0.9707 - precision: 0.9755 - recall: 0.9656 - val_loss: 0.5319 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 755/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1535 - categorical_accuracy: 0.9707 - precision: 0.9715 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1535 - categorical_accuracy: 0.9707 - precision: 0.9715 - recall: 0.9566 - val_loss: 0.4983 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 756/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1497 - categorical_accuracy: 0.9681 - precision: 0.9754 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1497 - categorical_accuracy: 0.9681 - precision: 0.9754 - recall: 0.9617 - val_loss: 0.6594 - val_categorical_accuracy: 0.8469 - val_precision: 0.8710 - val_recall: 0.8265\n",
            "Epoch 757/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2647 - categorical_accuracy: 0.9349 - precision: 0.9469 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2647 - categorical_accuracy: 0.9349 - precision: 0.9469 - recall: 0.9324 - val_loss: 1.0844 - val_categorical_accuracy: 0.7755 - val_precision: 0.7917 - val_recall: 0.7755\n",
            "Epoch 758/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2586 - categorical_accuracy: 0.9311 - precision: 0.9354 - recall: 0.9235"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2586 - categorical_accuracy: 0.9311 - precision: 0.9354 - recall: 0.9235 - val_loss: 0.6671 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 759/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1948 - categorical_accuracy: 0.9464 - precision: 0.9571 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1948 - categorical_accuracy: 0.9464 - precision: 0.9571 - recall: 0.9388 - val_loss: 0.7066 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 760/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1711 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1711 - categorical_accuracy: 0.9617 - precision: 0.9702 - recall: 0.9554 - val_loss: 0.5334 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 761/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1684 - categorical_accuracy: 0.9605 - precision: 0.9641 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1684 - categorical_accuracy: 0.9605 - precision: 0.9641 - recall: 0.9579 - val_loss: 0.4357 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 762/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1662 - categorical_accuracy: 0.9694 - precision: 0.9728 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1662 - categorical_accuracy: 0.9694 - precision: 0.9728 - recall: 0.9592 - val_loss: 0.4263 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 763/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1657 - categorical_accuracy: 0.9643 - precision: 0.9729 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1657 - categorical_accuracy: 0.9643 - precision: 0.9729 - recall: 0.9605 - val_loss: 0.4939 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 764/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1535 - categorical_accuracy: 0.9745 - precision: 0.9795 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1535 - categorical_accuracy: 0.9745 - precision: 0.9795 - recall: 0.9732 - val_loss: 0.7038 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 765/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1685 - categorical_accuracy: 0.9668 - precision: 0.9704 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1685 - categorical_accuracy: 0.9668 - precision: 0.9704 - recall: 0.9605 - val_loss: 0.5465 - val_categorical_accuracy: 0.8673 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 766/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1360 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 94ms/step - loss: 0.1360 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.5842 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 767/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2131 - categorical_accuracy: 0.9541 - precision: 0.9599 - recall: 0.9464"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2131 - categorical_accuracy: 0.9541 - precision: 0.9599 - recall: 0.9464 - val_loss: 0.3995 - val_categorical_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 768/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2357 - categorical_accuracy: 0.9362 - precision: 0.9443 - recall: 0.9298"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.2357 - categorical_accuracy: 0.9362 - precision: 0.9443 - recall: 0.9298 - val_loss: 0.5600 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 769/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1705 - categorical_accuracy: 0.9643 - precision: 0.9728 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1705 - categorical_accuracy: 0.9643 - precision: 0.9728 - recall: 0.9579 - val_loss: 0.5847 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 770/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1673 - categorical_accuracy: 0.9656 - precision: 0.9715 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1673 - categorical_accuracy: 0.9656 - precision: 0.9715 - recall: 0.9579 - val_loss: 0.5583 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 771/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1562 - categorical_accuracy: 0.9668 - precision: 0.9693 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1562 - categorical_accuracy: 0.9668 - precision: 0.9693 - recall: 0.9656 - val_loss: 0.5597 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 772/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1818 - categorical_accuracy: 0.9579 - precision: 0.9614 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1818 - categorical_accuracy: 0.9579 - precision: 0.9614 - recall: 0.9541 - val_loss: 0.5568 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 773/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1644 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1644 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9605 - val_loss: 0.4694 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 774/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1413 - categorical_accuracy: 0.9732 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1413 - categorical_accuracy: 0.9732 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.6192 - val_categorical_accuracy: 0.8367 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 775/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1630 - categorical_accuracy: 0.9605 - precision: 0.9702 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1630 - categorical_accuracy: 0.9605 - precision: 0.9702 - recall: 0.9554 - val_loss: 0.5074 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 776/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2561 - categorical_accuracy: 0.9388 - precision: 0.9456 - recall: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.2561 - categorical_accuracy: 0.9388 - precision: 0.9456 - recall: 0.9311 - val_loss: 0.5130 - val_categorical_accuracy: 0.8571 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 777/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1664 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1664 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9617 - val_loss: 0.6195 - val_categorical_accuracy: 0.8469 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 778/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1631 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1631 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9592 - val_loss: 0.5288 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 779/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1745 - categorical_accuracy: 0.9592 - precision: 0.9641 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1745 - categorical_accuracy: 0.9592 - precision: 0.9641 - recall: 0.9579 - val_loss: 0.6037 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 780/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1565 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1565 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9630 - val_loss: 0.5228 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 781/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1307 - categorical_accuracy: 0.9770 - precision: 0.9820 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1307 - categorical_accuracy: 0.9770 - precision: 0.9820 - recall: 0.9758 - val_loss: 0.5219 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 782/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1500 - categorical_accuracy: 0.9694 - precision: 0.9717 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1500 - categorical_accuracy: 0.9694 - precision: 0.9717 - recall: 0.9630 - val_loss: 0.5509 - val_categorical_accuracy: 0.8673 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 783/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2294 - categorical_accuracy: 0.9388 - precision: 0.9458 - recall: 0.9349"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.2294 - categorical_accuracy: 0.9388 - precision: 0.9458 - recall: 0.9349 - val_loss: 0.8618 - val_categorical_accuracy: 0.7959 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 784/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1837 - categorical_accuracy: 0.9503 - precision: 0.9598 - recall: 0.9439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1837 - categorical_accuracy: 0.9503 - precision: 0.9598 - recall: 0.9439 - val_loss: 0.5259 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 785/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1363 - categorical_accuracy: 0.9770 - precision: 0.9832 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1363 - categorical_accuracy: 0.9770 - precision: 0.9832 - recall: 0.9707 - val_loss: 0.6275 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 786/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1433 - categorical_accuracy: 0.9758 - precision: 0.9819 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1433 - categorical_accuracy: 0.9758 - precision: 0.9819 - recall: 0.9707 - val_loss: 0.4844 - val_categorical_accuracy: 0.8571 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 787/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1277 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1277 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9821 - val_loss: 0.4498 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 788/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1290 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1290 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.6787 - val_categorical_accuracy: 0.8367 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 789/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1714 - categorical_accuracy: 0.9592 - precision: 0.9665 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1714 - categorical_accuracy: 0.9592 - precision: 0.9665 - recall: 0.9579 - val_loss: 0.4444 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 790/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1406 - categorical_accuracy: 0.9719 - precision: 0.9718 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1406 - categorical_accuracy: 0.9719 - precision: 0.9718 - recall: 0.9668 - val_loss: 0.4692 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 791/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1830 - categorical_accuracy: 0.9605 - precision: 0.9650 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1830 - categorical_accuracy: 0.9605 - precision: 0.9650 - recall: 0.9503 - val_loss: 0.4815 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 792/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1561 - categorical_accuracy: 0.9656 - precision: 0.9691 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1561 - categorical_accuracy: 0.9656 - precision: 0.9691 - recall: 0.9592 - val_loss: 0.8241 - val_categorical_accuracy: 0.7959 - val_precision: 0.7959 - val_recall: 0.7959\n",
            "Epoch 793/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1686 - categorical_accuracy: 0.9617 - precision: 0.9639 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1686 - categorical_accuracy: 0.9617 - precision: 0.9639 - recall: 0.9541 - val_loss: 0.4694 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 794/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2080 - categorical_accuracy: 0.9541 - precision: 0.9599 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2080 - categorical_accuracy: 0.9541 - precision: 0.9599 - recall: 0.9477 - val_loss: 0.5667 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 795/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1618 - categorical_accuracy: 0.9579 - precision: 0.9664 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1618 - categorical_accuracy: 0.9579 - precision: 0.9664 - recall: 0.9528 - val_loss: 0.5588 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 796/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.9783 - precision: 0.9845 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1327 - categorical_accuracy: 0.9783 - precision: 0.9845 - recall: 0.9745 - val_loss: 0.5495 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 797/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1776 - categorical_accuracy: 0.9630 - precision: 0.9653 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1776 - categorical_accuracy: 0.9630 - precision: 0.9653 - recall: 0.9566 - val_loss: 0.6295 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 798/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2321 - categorical_accuracy: 0.9362 - precision: 0.9432 - recall: 0.9311"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2321 - categorical_accuracy: 0.9362 - precision: 0.9432 - recall: 0.9311 - val_loss: 0.9454 - val_categorical_accuracy: 0.7449 - val_precision: 0.7553 - val_recall: 0.7245\n",
            "Epoch 799/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2191 - categorical_accuracy: 0.9477 - precision: 0.9534 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.2191 - categorical_accuracy: 0.9477 - precision: 0.9534 - recall: 0.9388 - val_loss: 0.6159 - val_categorical_accuracy: 0.8571 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 800/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1627 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1627 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579 - val_loss: 0.4998 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 801/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1484 - categorical_accuracy: 0.9694 - precision: 0.9793 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1484 - categorical_accuracy: 0.9694 - precision: 0.9793 - recall: 0.9643 - val_loss: 0.4229 - val_categorical_accuracy: 0.9286 - val_precision: 0.9368 - val_recall: 0.9082\n",
            "Epoch 802/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1704 - categorical_accuracy: 0.9643 - precision: 0.9690 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1704 - categorical_accuracy: 0.9643 - precision: 0.9690 - recall: 0.9554 - val_loss: 0.5047 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 803/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1301 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1301 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.7356 - val_categorical_accuracy: 0.8061 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 804/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1467 - categorical_accuracy: 0.9745 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1467 - categorical_accuracy: 0.9745 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.5468 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 805/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1239 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1239 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9770 - val_loss: 0.6061 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 806/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1350 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.5942 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 807/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1366 - categorical_accuracy: 0.9732 - precision: 0.9756 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1366 - categorical_accuracy: 0.9732 - precision: 0.9756 - recall: 0.9694 - val_loss: 0.6856 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 808/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1428 - categorical_accuracy: 0.9719 - precision: 0.9794 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1428 - categorical_accuracy: 0.9719 - precision: 0.9794 - recall: 0.9694 - val_loss: 0.5374 - val_categorical_accuracy: 0.8367 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 809/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1654 - categorical_accuracy: 0.9605 - precision: 0.9651 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1654 - categorical_accuracy: 0.9605 - precision: 0.9651 - recall: 0.9515 - val_loss: 0.6830 - val_categorical_accuracy: 0.8163 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 810/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2353 - categorical_accuracy: 0.9375 - precision: 0.9399 - recall: 0.9184"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.2353 - categorical_accuracy: 0.9375 - precision: 0.9399 - recall: 0.9184 - val_loss: 0.5596 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 811/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1839 - categorical_accuracy: 0.9605 - precision: 0.9651 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1839 - categorical_accuracy: 0.9605 - precision: 0.9651 - recall: 0.9515 - val_loss: 0.4692 - val_categorical_accuracy: 0.8878 - val_precision: 0.9158 - val_recall: 0.8878\n",
            "Epoch 812/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1563 - categorical_accuracy: 0.9605 - precision: 0.9703 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1563 - categorical_accuracy: 0.9605 - precision: 0.9703 - recall: 0.9592 - val_loss: 0.5302 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 813/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1457 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1457 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9732 - val_loss: 0.5375 - val_categorical_accuracy: 0.9184 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 814/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2136 - categorical_accuracy: 0.9413 - precision: 0.9497 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.2136 - categorical_accuracy: 0.9413 - precision: 0.9497 - recall: 0.9388 - val_loss: 0.6750 - val_categorical_accuracy: 0.8367 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 815/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1636 - categorical_accuracy: 0.9707 - precision: 0.9767 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1636 - categorical_accuracy: 0.9707 - precision: 0.9767 - recall: 0.9605 - val_loss: 0.4526 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 816/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1218 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9745 - val_loss: 0.4971 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 817/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1218 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1218 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809 - val_loss: 0.6102 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 818/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1342 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1342 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9809 - val_loss: 0.4773 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 819/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1453 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1453 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9617 - val_loss: 0.8051 - val_categorical_accuracy: 0.8061 - val_precision: 0.8125 - val_recall: 0.7959\n",
            "Epoch 820/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1539 - categorical_accuracy: 0.9605 - precision: 0.9690 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1539 - categorical_accuracy: 0.9605 - precision: 0.9690 - recall: 0.9566 - val_loss: 0.5253 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 821/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1200 - categorical_accuracy: 0.9796 - precision: 0.9858 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1200 - categorical_accuracy: 0.9796 - precision: 0.9858 - recall: 0.9732 - val_loss: 0.5188 - val_categorical_accuracy: 0.8571 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 822/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1383 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1383 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9656 - val_loss: 0.4781 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 823/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1348 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.1348 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9656 - val_loss: 0.5422 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 824/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1492 - categorical_accuracy: 0.9681 - precision: 0.9705 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1492 - categorical_accuracy: 0.9681 - precision: 0.9705 - recall: 0.9656 - val_loss: 0.6512 - val_categorical_accuracy: 0.8163 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 825/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1266 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 138ms/step - loss: 0.1266 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9770 - val_loss: 0.5065 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 826/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 165ms/step - loss: 0.1297 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9732 - val_loss: 0.5787 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 827/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1602 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 165ms/step - loss: 0.1602 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9694 - val_loss: 0.5164 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 828/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1508 - categorical_accuracy: 0.9694 - precision: 0.9755 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.1508 - categorical_accuracy: 0.9694 - precision: 0.9755 - recall: 0.9630 - val_loss: 0.5928 - val_categorical_accuracy: 0.8469 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 829/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1418 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1418 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.5760 - val_categorical_accuracy: 0.8265 - val_precision: 0.8495 - val_recall: 0.8061\n",
            "Epoch 830/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1375 - categorical_accuracy: 0.9643 - precision: 0.9692 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1375 - categorical_accuracy: 0.9643 - precision: 0.9692 - recall: 0.9617 - val_loss: 0.5478 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 831/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1491 - categorical_accuracy: 0.9707 - precision: 0.9730 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1491 - categorical_accuracy: 0.9707 - precision: 0.9730 - recall: 0.9643 - val_loss: 0.6072 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 832/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2091 - categorical_accuracy: 0.9554 - precision: 0.9612 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2091 - categorical_accuracy: 0.9554 - precision: 0.9612 - recall: 0.9490 - val_loss: 0.6844 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 833/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2149 - categorical_accuracy: 0.9426 - precision: 0.9485 - recall: 0.9401"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2149 - categorical_accuracy: 0.9426 - precision: 0.9485 - recall: 0.9401 - val_loss: 0.5323 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 834/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1900 - categorical_accuracy: 0.9541 - precision: 0.9576 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1900 - categorical_accuracy: 0.9541 - precision: 0.9576 - recall: 0.9503 - val_loss: 0.6036 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 835/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1307 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1307 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.6697 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 836/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1515 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1515 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9566 - val_loss: 0.4667 - val_categorical_accuracy: 0.9082 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 837/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1695 - categorical_accuracy: 0.9668 - precision: 0.9715 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1695 - categorical_accuracy: 0.9668 - precision: 0.9715 - recall: 0.9566 - val_loss: 0.6695 - val_categorical_accuracy: 0.8061 - val_precision: 0.8298 - val_recall: 0.7959\n",
            "Epoch 838/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1646 - categorical_accuracy: 0.9592 - precision: 0.9626 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1646 - categorical_accuracy: 0.9592 - precision: 0.9626 - recall: 0.9528 - val_loss: 0.5922 - val_categorical_accuracy: 0.8673 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 839/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1420 - categorical_accuracy: 0.9656 - precision: 0.9717 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1420 - categorical_accuracy: 0.9656 - precision: 0.9717 - recall: 0.9643 - val_loss: 0.4906 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 840/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1593 - categorical_accuracy: 0.9681 - precision: 0.9680 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1593 - categorical_accuracy: 0.9681 - precision: 0.9680 - recall: 0.9643 - val_loss: 0.6946 - val_categorical_accuracy: 0.8061 - val_precision: 0.8144 - val_recall: 0.8061\n",
            "Epoch 841/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1341 - categorical_accuracy: 0.9719 - precision: 0.9756 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1341 - categorical_accuracy: 0.9719 - precision: 0.9756 - recall: 0.9694 - val_loss: 0.4582 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 842/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1319 - categorical_accuracy: 0.9707 - precision: 0.9755 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1319 - categorical_accuracy: 0.9707 - precision: 0.9755 - recall: 0.9656 - val_loss: 0.4738 - val_categorical_accuracy: 0.8980 - val_precision: 0.9149 - val_recall: 0.8776\n",
            "Epoch 843/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1746 - categorical_accuracy: 0.9630 - precision: 0.9651 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1746 - categorical_accuracy: 0.9630 - precision: 0.9651 - recall: 0.9528 - val_loss: 0.7242 - val_categorical_accuracy: 0.8163 - val_precision: 0.8144 - val_recall: 0.8061\n",
            "Epoch 844/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1448 - categorical_accuracy: 0.9745 - precision: 0.9794 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1448 - categorical_accuracy: 0.9745 - precision: 0.9794 - recall: 0.9719 - val_loss: 0.6050 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 845/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1412 - categorical_accuracy: 0.9707 - precision: 0.9742 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1412 - categorical_accuracy: 0.9707 - precision: 0.9742 - recall: 0.9630 - val_loss: 0.6734 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 846/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1636 - categorical_accuracy: 0.9592 - precision: 0.9640 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1636 - categorical_accuracy: 0.9592 - precision: 0.9640 - recall: 0.9566 - val_loss: 0.5363 - val_categorical_accuracy: 0.8469 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 847/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1788 - categorical_accuracy: 0.9515 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1788 - categorical_accuracy: 0.9515 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.4849 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 848/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1250 - categorical_accuracy: 0.9783 - precision: 0.9846 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1250 - categorical_accuracy: 0.9783 - precision: 0.9846 - recall: 0.9783 - val_loss: 0.4591 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 849/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1237 - categorical_accuracy: 0.9796 - precision: 0.9807 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1237 - categorical_accuracy: 0.9796 - precision: 0.9807 - recall: 0.9719 - val_loss: 0.3580 - val_categorical_accuracy: 0.9184 - val_precision: 0.9375 - val_recall: 0.9184\n",
            "Epoch 850/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1337 - categorical_accuracy: 0.9732 - precision: 0.9769 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1337 - categorical_accuracy: 0.9732 - precision: 0.9769 - recall: 0.9707 - val_loss: 0.4506 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 851/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1331 - categorical_accuracy: 0.9732 - precision: 0.9769 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1331 - categorical_accuracy: 0.9732 - precision: 0.9769 - recall: 0.9694 - val_loss: 0.4431 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 852/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1439 - categorical_accuracy: 0.9707 - precision: 0.9793 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1439 - categorical_accuracy: 0.9707 - precision: 0.9793 - recall: 0.9656 - val_loss: 0.7177 - val_categorical_accuracy: 0.8163 - val_precision: 0.8404 - val_recall: 0.8061\n",
            "Epoch 853/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1340 - categorical_accuracy: 0.9758 - precision: 0.9819 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1340 - categorical_accuracy: 0.9758 - precision: 0.9819 - recall: 0.9707 - val_loss: 0.4622 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 854/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1177 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1177 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.5553 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 855/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1273 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1273 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.5819 - val_categorical_accuracy: 0.8776 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 856/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1260 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1260 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.4541 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 857/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1684 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1684 - categorical_accuracy: 0.9656 - precision: 0.9716 - recall: 0.9617 - val_loss: 0.6978 - val_categorical_accuracy: 0.8673 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 858/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1350 - categorical_accuracy: 0.9770 - precision: 0.9806 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1350 - categorical_accuracy: 0.9770 - precision: 0.9806 - recall: 0.9681 - val_loss: 0.4406 - val_categorical_accuracy: 0.8673 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 859/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.9809 - precision: 0.9820 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1271 - categorical_accuracy: 0.9809 - precision: 0.9820 - recall: 0.9758 - val_loss: 0.5558 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 860/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1378 - categorical_accuracy: 0.9707 - precision: 0.9769 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1378 - categorical_accuracy: 0.9707 - precision: 0.9769 - recall: 0.9707 - val_loss: 0.4796 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 861/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1339 - categorical_accuracy: 0.9745 - precision: 0.9794 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1339 - categorical_accuracy: 0.9745 - precision: 0.9794 - recall: 0.9681 - val_loss: 0.4442 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 862/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1672 - categorical_accuracy: 0.9630 - precision: 0.9642 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1672 - categorical_accuracy: 0.9630 - precision: 0.9642 - recall: 0.9617 - val_loss: 0.4273 - val_categorical_accuracy: 0.9184 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 863/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1394 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1394 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681 - val_loss: 0.5567 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 864/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1353 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.6006 - val_categorical_accuracy: 0.8571 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 865/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1390 - categorical_accuracy: 0.9770 - precision: 0.9782 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1390 - categorical_accuracy: 0.9770 - precision: 0.9782 - recall: 0.9732 - val_loss: 0.4885 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 866/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1581 - categorical_accuracy: 0.9656 - precision: 0.9667 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1581 - categorical_accuracy: 0.9656 - precision: 0.9667 - recall: 0.9630 - val_loss: 0.5055 - val_categorical_accuracy: 0.8878 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 867/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1368 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1368 - categorical_accuracy: 0.9719 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.4726 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 868/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1340 - categorical_accuracy: 0.9707 - precision: 0.9744 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1340 - categorical_accuracy: 0.9707 - precision: 0.9744 - recall: 0.9707 - val_loss: 0.4230 - val_categorical_accuracy: 0.9388 - val_precision: 0.9388 - val_recall: 0.9388\n",
            "Epoch 869/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1169 - categorical_accuracy: 0.9821 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1169 - categorical_accuracy: 0.9821 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.4286 - val_categorical_accuracy: 0.9286 - val_precision: 0.9375 - val_recall: 0.9184\n",
            "Epoch 870/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1297 - categorical_accuracy: 0.9758 - precision: 0.9782 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1297 - categorical_accuracy: 0.9758 - precision: 0.9782 - recall: 0.9745 - val_loss: 0.5257 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 871/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1555 - categorical_accuracy: 0.9681 - precision: 0.9729 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1555 - categorical_accuracy: 0.9681 - precision: 0.9729 - recall: 0.9617 - val_loss: 0.4829 - val_categorical_accuracy: 0.9184 - val_precision: 0.9263 - val_recall: 0.8980\n",
            "Epoch 872/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1154 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1154 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9809 - val_loss: 0.4629 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 873/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1345 - categorical_accuracy: 0.9643 - precision: 0.9729 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1345 - categorical_accuracy: 0.9643 - precision: 0.9729 - recall: 0.9605 - val_loss: 0.4726 - val_categorical_accuracy: 0.8980 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 874/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1537 - categorical_accuracy: 0.9668 - precision: 0.9728 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1537 - categorical_accuracy: 0.9668 - precision: 0.9728 - recall: 0.9579 - val_loss: 0.6092 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 875/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1327 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1327 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.4684 - val_categorical_accuracy: 0.8980 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 876/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1039 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1039 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847 - val_loss: 0.4797 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 877/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1087 - categorical_accuracy: 0.9885 - precision: 0.9897 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1087 - categorical_accuracy: 0.9885 - precision: 0.9897 - recall: 0.9847 - val_loss: 0.4895 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 878/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1120 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1120 - categorical_accuracy: 0.9834 - precision: 0.9884 - recall: 0.9821 - val_loss: 0.4862 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 879/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1069 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1069 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9821 - val_loss: 0.5730 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 880/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1286 - categorical_accuracy: 0.9758 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1286 - categorical_accuracy: 0.9758 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.4841 - val_categorical_accuracy: 0.8878 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 881/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1391 - categorical_accuracy: 0.9694 - precision: 0.9768 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1391 - categorical_accuracy: 0.9694 - precision: 0.9768 - recall: 0.9668 - val_loss: 0.5922 - val_categorical_accuracy: 0.8265 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 882/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1346 - categorical_accuracy: 0.9707 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1346 - categorical_accuracy: 0.9707 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.5367 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 883/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1307 - categorical_accuracy: 0.9719 - precision: 0.9732 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1307 - categorical_accuracy: 0.9719 - precision: 0.9732 - recall: 0.9719 - val_loss: 0.5664 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 884/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1290 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1290 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9707 - val_loss: 0.5112 - val_categorical_accuracy: 0.8673 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 885/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1224 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1224 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9758 - val_loss: 0.4166 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 886/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2289 - categorical_accuracy: 0.9388 - precision: 0.9454 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2289 - categorical_accuracy: 0.9388 - precision: 0.9454 - recall: 0.9273 - val_loss: 0.8831 - val_categorical_accuracy: 0.8061 - val_precision: 0.8041 - val_recall: 0.7959\n",
            "Epoch 887/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1707 - categorical_accuracy: 0.9541 - precision: 0.9613 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1707 - categorical_accuracy: 0.9541 - precision: 0.9613 - recall: 0.9503 - val_loss: 0.4395 - val_categorical_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 888/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1562 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1562 - categorical_accuracy: 0.9630 - precision: 0.9678 - recall: 0.9579 - val_loss: 0.5849 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 889/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.9821 - precision: 0.9821 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1110 - categorical_accuracy: 0.9821 - precision: 0.9821 - recall: 0.9809 - val_loss: 0.4431 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 890/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0947 - categorical_accuracy: 0.9898 - precision: 0.9936 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.0947 - categorical_accuracy: 0.9898 - precision: 0.9936 - recall: 0.9860 - val_loss: 0.4944 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 891/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1086 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1086 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.4630 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 892/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1047 - categorical_accuracy: 0.9872 - precision: 0.9884 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1047 - categorical_accuracy: 0.9872 - precision: 0.9884 - recall: 0.9809 - val_loss: 0.4898 - val_categorical_accuracy: 0.8571 - val_precision: 0.8723 - val_recall: 0.8367\n",
            "Epoch 893/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1264 - categorical_accuracy: 0.9783 - precision: 0.9833 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1264 - categorical_accuracy: 0.9783 - precision: 0.9833 - recall: 0.9758 - val_loss: 0.6064 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 894/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1668 - categorical_accuracy: 0.9605 - precision: 0.9615 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1668 - categorical_accuracy: 0.9605 - precision: 0.9615 - recall: 0.9566 - val_loss: 0.8296 - val_categorical_accuracy: 0.7959 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 895/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1564 - categorical_accuracy: 0.9656 - precision: 0.9692 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1564 - categorical_accuracy: 0.9656 - precision: 0.9692 - recall: 0.9617 - val_loss: 0.4880 - val_categorical_accuracy: 0.8673 - val_precision: 0.8830 - val_recall: 0.8469\n",
            "Epoch 896/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1368 - categorical_accuracy: 0.9732 - precision: 0.9743 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1368 - categorical_accuracy: 0.9732 - precision: 0.9743 - recall: 0.9681 - val_loss: 0.5967 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 897/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1111 - categorical_accuracy: 0.9821 - precision: 0.9858 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1111 - categorical_accuracy: 0.9821 - precision: 0.9858 - recall: 0.9745 - val_loss: 0.4824 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 898/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1076 - categorical_accuracy: 0.9821 - precision: 0.9859 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1076 - categorical_accuracy: 0.9821 - precision: 0.9859 - recall: 0.9821 - val_loss: 0.5290 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 899/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1288 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1288 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.3895 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 900/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1329 - categorical_accuracy: 0.9745 - precision: 0.9756 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1329 - categorical_accuracy: 0.9745 - precision: 0.9756 - recall: 0.9707 - val_loss: 0.6106 - val_categorical_accuracy: 0.8061 - val_precision: 0.8144 - val_recall: 0.8061\n",
            "Epoch 901/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1328 - categorical_accuracy: 0.9668 - precision: 0.9680 - recall: 0.9656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1328 - categorical_accuracy: 0.9668 - precision: 0.9680 - recall: 0.9656 - val_loss: 0.5979 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 902/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1145 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1145 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809 - val_loss: 0.5484 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 903/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1165 - categorical_accuracy: 0.9796 - precision: 0.9846 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1165 - categorical_accuracy: 0.9796 - precision: 0.9846 - recall: 0.9758 - val_loss: 0.5072 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 904/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1677 - categorical_accuracy: 0.9579 - precision: 0.9614 - recall: 0.9528"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1677 - categorical_accuracy: 0.9579 - precision: 0.9614 - recall: 0.9528 - val_loss: 0.7141 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 905/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1552 - categorical_accuracy: 0.9656 - precision: 0.9668 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1552 - categorical_accuracy: 0.9656 - precision: 0.9668 - recall: 0.9643 - val_loss: 0.5248 - val_categorical_accuracy: 0.8673 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 906/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1168 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9770 - val_loss: 0.5436 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 907/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1193 - categorical_accuracy: 0.9783 - precision: 0.9846 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1193 - categorical_accuracy: 0.9783 - precision: 0.9846 - recall: 0.9770 - val_loss: 0.3925 - val_categorical_accuracy: 0.8980 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 908/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1097 - categorical_accuracy: 0.9834 - precision: 0.9846 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1097 - categorical_accuracy: 0.9834 - precision: 0.9846 - recall: 0.9770 - val_loss: 0.4400 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 909/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.9783 - precision: 0.9794 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1213 - categorical_accuracy: 0.9783 - precision: 0.9794 - recall: 0.9719 - val_loss: 0.7489 - val_categorical_accuracy: 0.8061 - val_precision: 0.8105 - val_recall: 0.7857\n",
            "Epoch 910/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1703 - categorical_accuracy: 0.9541 - precision: 0.9600 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1703 - categorical_accuracy: 0.9541 - precision: 0.9600 - recall: 0.9490 - val_loss: 0.7066 - val_categorical_accuracy: 0.7959 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 911/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1536 - categorical_accuracy: 0.9656 - precision: 0.9703 - recall: 0.9592"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1536 - categorical_accuracy: 0.9656 - precision: 0.9703 - recall: 0.9592 - val_loss: 0.6370 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 912/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1407 - categorical_accuracy: 0.9719 - precision: 0.9768 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1407 - categorical_accuracy: 0.9719 - precision: 0.9768 - recall: 0.9668 - val_loss: 0.5838 - val_categorical_accuracy: 0.8469 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 913/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1099 - categorical_accuracy: 0.9809 - precision: 0.9859 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1099 - categorical_accuracy: 0.9809 - precision: 0.9859 - recall: 0.9809 - val_loss: 0.4061 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 914/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0954 - categorical_accuracy: 0.9885 - precision: 0.9897 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0954 - categorical_accuracy: 0.9885 - precision: 0.9897 - recall: 0.9821 - val_loss: 0.4709 - val_categorical_accuracy: 0.9184 - val_precision: 0.9375 - val_recall: 0.9184\n",
            "Epoch 915/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1216 - categorical_accuracy: 0.9783 - precision: 0.9820 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1216 - categorical_accuracy: 0.9783 - precision: 0.9820 - recall: 0.9745 - val_loss: 0.6437 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 916/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1008 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 139ms/step - loss: 0.1008 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9860 - val_loss: 0.4810 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 917/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1079 - categorical_accuracy: 0.9796 - precision: 0.9821 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 172ms/step - loss: 0.1079 - categorical_accuracy: 0.9796 - precision: 0.9821 - recall: 0.9783 - val_loss: 0.5773 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 918/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2930 - categorical_accuracy: 0.9235 - precision: 0.9339 - recall: 0.9196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 162ms/step - loss: 0.2930 - categorical_accuracy: 0.9235 - precision: 0.9339 - recall: 0.9196 - val_loss: 0.6840 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 919/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2630 - categorical_accuracy: 0.9298 - precision: 0.9393 - recall: 0.9273"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.2630 - categorical_accuracy: 0.9298 - precision: 0.9393 - recall: 0.9273 - val_loss: 0.9379 - val_categorical_accuracy: 0.8061 - val_precision: 0.8211 - val_recall: 0.7959\n",
            "Epoch 920/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2033 - categorical_accuracy: 0.9439 - precision: 0.9469 - recall: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.2033 - categorical_accuracy: 0.9439 - precision: 0.9469 - recall: 0.9324 - val_loss: 0.6457 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 921/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1731 - categorical_accuracy: 0.9490 - precision: 0.9622 - recall: 0.9413"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1731 - categorical_accuracy: 0.9490 - precision: 0.9622 - recall: 0.9413 - val_loss: 0.7372 - val_categorical_accuracy: 0.7857 - val_precision: 0.8105 - val_recall: 0.7857\n",
            "Epoch 922/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.9745 - precision: 0.9744 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1321 - categorical_accuracy: 0.9745 - precision: 0.9744 - recall: 0.9707 - val_loss: 0.4930 - val_categorical_accuracy: 0.8776 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 923/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1101 - categorical_accuracy: 0.9860 - precision: 0.9885 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1101 - categorical_accuracy: 0.9860 - precision: 0.9885 - recall: 0.9834 - val_loss: 0.4483 - val_categorical_accuracy: 0.9082 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 924/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1108 - categorical_accuracy: 0.9796 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1108 - categorical_accuracy: 0.9796 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.4096 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 925/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0986 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0986 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9885 - val_loss: 0.4983 - val_categorical_accuracy: 0.9082 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 926/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0932 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0932 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9911 - val_loss: 0.5159 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 927/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1188 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1188 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9707 - val_loss: 0.4429 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 928/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.9834 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1044 - categorical_accuracy: 0.9834 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.5283 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 929/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1125 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1125 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9783 - val_loss: 0.5166 - val_categorical_accuracy: 0.8673 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 930/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1341 - categorical_accuracy: 0.9732 - precision: 0.9756 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1341 - categorical_accuracy: 0.9732 - precision: 0.9756 - recall: 0.9707 - val_loss: 0.5373 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 931/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2725 - categorical_accuracy: 0.9209 - precision: 0.9239 - recall: 0.9133"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.2725 - categorical_accuracy: 0.9209 - precision: 0.9239 - recall: 0.9133 - val_loss: 1.0170 - val_categorical_accuracy: 0.7551 - val_precision: 0.7708 - val_recall: 0.7551\n",
            "Epoch 932/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1918 - categorical_accuracy: 0.9490 - precision: 0.9533 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1918 - categorical_accuracy: 0.9490 - precision: 0.9533 - recall: 0.9375 - val_loss: 0.4339 - val_categorical_accuracy: 0.9184 - val_precision: 0.9368 - val_recall: 0.9082\n",
            "Epoch 933/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1631 - categorical_accuracy: 0.9643 - precision: 0.9654 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1631 - categorical_accuracy: 0.9643 - precision: 0.9654 - recall: 0.9605 - val_loss: 0.5642 - val_categorical_accuracy: 0.8776 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 934/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1113 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1113 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9796 - val_loss: 0.4879 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 935/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1212 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1212 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9783 - val_loss: 0.5890 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 936/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1188 - categorical_accuracy: 0.9809 - precision: 0.9820 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1188 - categorical_accuracy: 0.9809 - precision: 0.9820 - recall: 0.9758 - val_loss: 0.5458 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 937/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1335 - categorical_accuracy: 0.9719 - precision: 0.9781 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1335 - categorical_accuracy: 0.9719 - precision: 0.9781 - recall: 0.9681 - val_loss: 0.5048 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 938/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1103 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1103 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.6119 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 939/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0924 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0924 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.4663 - val_categorical_accuracy: 0.8980 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 940/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0944 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.0944 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.4264 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 941/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1134 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1134 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.5956 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 942/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2076 - categorical_accuracy: 0.9464 - precision: 0.9474 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.2076 - categorical_accuracy: 0.9464 - precision: 0.9474 - recall: 0.9426 - val_loss: 0.5431 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 943/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1256 - categorical_accuracy: 0.9745 - precision: 0.9820 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1256 - categorical_accuracy: 0.9745 - precision: 0.9820 - recall: 0.9745 - val_loss: 0.4919 - val_categorical_accuracy: 0.8980 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 944/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1089 - categorical_accuracy: 0.9809 - precision: 0.9832 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1089 - categorical_accuracy: 0.9809 - precision: 0.9832 - recall: 0.9732 - val_loss: 0.5419 - val_categorical_accuracy: 0.8878 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 945/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1107 - categorical_accuracy: 0.9809 - precision: 0.9845 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1107 - categorical_accuracy: 0.9809 - precision: 0.9845 - recall: 0.9745 - val_loss: 0.4343 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 946/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0897 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0897 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923 - val_loss: 0.4366 - val_categorical_accuracy: 0.9286 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 947/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0982 - categorical_accuracy: 0.9898 - precision: 0.9936 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0982 - categorical_accuracy: 0.9898 - precision: 0.9936 - recall: 0.9860 - val_loss: 0.5164 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 948/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1102 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1102 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719 - val_loss: 0.5414 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 949/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1110 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1110 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9809 - val_loss: 0.4978 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 950/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1213 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1213 - categorical_accuracy: 0.9732 - precision: 0.9794 - recall: 0.9681 - val_loss: 0.7217 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 951/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1030 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1030 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796 - val_loss: 0.7072 - val_categorical_accuracy: 0.8776 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 952/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1055 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1055 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.5163 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 953/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0873 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.0873 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898 - val_loss: 0.4464 - val_categorical_accuracy: 0.9082 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 954/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0953 - categorical_accuracy: 0.9885 - precision: 0.9923 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0953 - categorical_accuracy: 0.9885 - precision: 0.9923 - recall: 0.9860 - val_loss: 0.6215 - val_categorical_accuracy: 0.8163 - val_precision: 0.8316 - val_recall: 0.8061\n",
            "Epoch 955/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1204 - categorical_accuracy: 0.9732 - precision: 0.9731 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.1204 - categorical_accuracy: 0.9732 - precision: 0.9731 - recall: 0.9694 - val_loss: 0.4633 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 956/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1333 - categorical_accuracy: 0.9758 - precision: 0.9781 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1333 - categorical_accuracy: 0.9758 - precision: 0.9781 - recall: 0.9668 - val_loss: 0.4962 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 957/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1042 - categorical_accuracy: 0.9860 - precision: 0.9884 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1042 - categorical_accuracy: 0.9860 - precision: 0.9884 - recall: 0.9821 - val_loss: 0.4416 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 958/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0925 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0925 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.6353 - val_categorical_accuracy: 0.8469 - val_precision: 0.8421 - val_recall: 0.8163\n",
            "Epoch 959/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1081 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1081 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.4374 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 960/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0940 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.0940 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9821 - val_loss: 0.4588 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 961/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1353 - categorical_accuracy: 0.9719 - precision: 0.9767 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1353 - categorical_accuracy: 0.9719 - precision: 0.9767 - recall: 0.9643 - val_loss: 0.5885 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 962/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1080 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1080 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9770 - val_loss: 0.6229 - val_categorical_accuracy: 0.8571 - val_precision: 0.8925 - val_recall: 0.8469\n",
            "Epoch 963/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1287 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1287 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719 - val_loss: 0.6205 - val_categorical_accuracy: 0.8265 - val_precision: 0.8265 - val_recall: 0.8265\n",
            "Epoch 964/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1168 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9796 - val_loss: 0.4404 - val_categorical_accuracy: 0.9082 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 965/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1505 - categorical_accuracy: 0.9630 - precision: 0.9692 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1505 - categorical_accuracy: 0.9630 - precision: 0.9692 - recall: 0.9617 - val_loss: 0.7828 - val_categorical_accuracy: 0.8469 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 966/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1170 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1170 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9732 - val_loss: 0.5501 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 967/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1150 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1150 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9770 - val_loss: 0.5444 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 968/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1022 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1022 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.6037 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 969/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1008 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1008 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9809 - val_loss: 0.4843 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 970/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1089 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1089 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9770 - val_loss: 0.6919 - val_categorical_accuracy: 0.8265 - val_precision: 0.8247 - val_recall: 0.8163\n",
            "Epoch 971/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1054 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1054 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9783 - val_loss: 0.6561 - val_categorical_accuracy: 0.8571 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 972/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1038 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1038 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.5751 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 973/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1303 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1303 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9732 - val_loss: 0.4584 - val_categorical_accuracy: 0.9082 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 974/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1604 - categorical_accuracy: 0.9630 - precision: 0.9629 - recall: 0.9605"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1604 - categorical_accuracy: 0.9630 - precision: 0.9629 - recall: 0.9605 - val_loss: 0.7149 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 975/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1832 - categorical_accuracy: 0.9401 - precision: 0.9459 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1832 - categorical_accuracy: 0.9401 - precision: 0.9459 - recall: 0.9375 - val_loss: 0.7591 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 976/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1284 - categorical_accuracy: 0.9745 - precision: 0.9769 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1284 - categorical_accuracy: 0.9745 - precision: 0.9769 - recall: 0.9707 - val_loss: 0.5494 - val_categorical_accuracy: 0.8776 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 977/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1059 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1059 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.5974 - val_categorical_accuracy: 0.8469 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 978/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1186 - categorical_accuracy: 0.9783 - precision: 0.9833 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1186 - categorical_accuracy: 0.9783 - precision: 0.9833 - recall: 0.9758 - val_loss: 0.4751 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 979/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1155 - categorical_accuracy: 0.9847 - precision: 0.9859 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1155 - categorical_accuracy: 0.9847 - precision: 0.9859 - recall: 0.9834 - val_loss: 0.4272 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 980/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1564 - categorical_accuracy: 0.9579 - precision: 0.9627 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1564 - categorical_accuracy: 0.9579 - precision: 0.9627 - recall: 0.9554 - val_loss: 0.4330 - val_categorical_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 981/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1758 - categorical_accuracy: 0.9541 - precision: 0.9588 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1758 - categorical_accuracy: 0.9541 - precision: 0.9588 - recall: 0.9490 - val_loss: 0.7825 - val_categorical_accuracy: 0.8061 - val_precision: 0.8125 - val_recall: 0.7959\n",
            "Epoch 982/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1853 - categorical_accuracy: 0.9515 - precision: 0.9550 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1853 - categorical_accuracy: 0.9515 - precision: 0.9550 - recall: 0.9477 - val_loss: 0.9986 - val_categorical_accuracy: 0.7143 - val_precision: 0.7216 - val_recall: 0.7143\n",
            "Epoch 983/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1853 - categorical_accuracy: 0.9566 - precision: 0.9599 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1853 - categorical_accuracy: 0.9566 - precision: 0.9599 - recall: 0.9477 - val_loss: 0.6150 - val_categorical_accuracy: 0.8673 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 984/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1308 - categorical_accuracy: 0.9707 - precision: 0.9730 - recall: 0.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.1308 - categorical_accuracy: 0.9707 - precision: 0.9730 - recall: 0.9668 - val_loss: 0.4972 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 985/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0996 - categorical_accuracy: 0.9847 - precision: 0.9871 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0996 - categorical_accuracy: 0.9847 - precision: 0.9871 - recall: 0.9796 - val_loss: 0.4210 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 986/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0854 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0854 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9923 - val_loss: 0.4509 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 987/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0867 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.0867 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923 - val_loss: 0.4373 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 988/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0865 - categorical_accuracy: 0.9885 - precision: 0.9923 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.0865 - categorical_accuracy: 0.9885 - precision: 0.9923 - recall: 0.9872 - val_loss: 0.5230 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 989/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0802 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 95ms/step - loss: 0.0802 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923 - val_loss: 0.4671 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 990/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1574 - categorical_accuracy: 0.9617 - precision: 0.9627 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1574 - categorical_accuracy: 0.9617 - precision: 0.9627 - recall: 0.9554 - val_loss: 0.5971 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 991/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1521 - categorical_accuracy: 0.9579 - precision: 0.9627 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1521 - categorical_accuracy: 0.9579 - precision: 0.9627 - recall: 0.9554 - val_loss: 0.6202 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 992/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1556 - categorical_accuracy: 0.9656 - precision: 0.9692 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1556 - categorical_accuracy: 0.9656 - precision: 0.9692 - recall: 0.9643 - val_loss: 1.1190 - val_categorical_accuracy: 0.7551 - val_precision: 0.7629 - val_recall: 0.7551\n",
            "Epoch 993/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1657 - categorical_accuracy: 0.9503 - precision: 0.9535 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1657 - categorical_accuracy: 0.9503 - precision: 0.9535 - recall: 0.9426 - val_loss: 1.0237 - val_categorical_accuracy: 0.7347 - val_precision: 0.7396 - val_recall: 0.7245\n",
            "Epoch 994/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1550 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1550 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9566 - val_loss: 0.5216 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 995/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1274 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1274 - categorical_accuracy: 0.9719 - precision: 0.9769 - recall: 0.9707 - val_loss: 0.5086 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 996/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1008 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1008 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.5855 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 997/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0884 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0884 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.5920 - val_categorical_accuracy: 0.8469 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 998/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0968 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0968 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.5038 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 999/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0994 - categorical_accuracy: 0.9860 - precision: 0.9885 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.0994 - categorical_accuracy: 0.9860 - precision: 0.9885 - recall: 0.9847 - val_loss: 0.4980 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1000/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0882 - categorical_accuracy: 0.9898 - precision: 0.9948 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0882 - categorical_accuracy: 0.9898 - precision: 0.9948 - recall: 0.9834 - val_loss: 0.5147 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1001/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0774 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0774 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923 - val_loss: 0.4925 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1002/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1035 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1035 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9821 - val_loss: 0.4685 - val_categorical_accuracy: 0.8878 - val_precision: 0.9053 - val_recall: 0.8776\n",
            "Epoch 1003/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1098 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1098 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796 - val_loss: 0.4272 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1004/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0982 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0982 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9834 - val_loss: 0.4870 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1005/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0967 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 96ms/step - loss: 0.0967 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9847 - val_loss: 0.6020 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 1006/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1162 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1162 - categorical_accuracy: 0.9770 - precision: 0.9807 - recall: 0.9745 - val_loss: 0.5325 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 1007/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1668 - categorical_accuracy: 0.9541 - precision: 0.9575 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.1668 - categorical_accuracy: 0.9541 - precision: 0.9575 - recall: 0.9490 - val_loss: 1.0507 - val_categorical_accuracy: 0.7653 - val_precision: 0.7732 - val_recall: 0.7653\n",
            "Epoch 1008/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1843 - categorical_accuracy: 0.9554 - precision: 0.9601 - recall: 0.9515"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 171ms/step - loss: 0.1843 - categorical_accuracy: 0.9554 - precision: 0.9601 - recall: 0.9515 - val_loss: 0.5722 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 1009/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1173 - categorical_accuracy: 0.9770 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 168ms/step - loss: 0.1173 - categorical_accuracy: 0.9770 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.4732 - val_categorical_accuracy: 0.8571 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 1010/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1166 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 146ms/step - loss: 0.1166 - categorical_accuracy: 0.9796 - precision: 0.9833 - recall: 0.9783 - val_loss: 0.4874 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1011/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1131 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.1131 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9758 - val_loss: 0.4602 - val_categorical_accuracy: 0.9184 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1012/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0867 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0867 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.4232 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1013/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0814 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9885 - val_loss: 0.4931 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1014/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0942 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 97ms/step - loss: 0.0942 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9834 - val_loss: 0.5338 - val_categorical_accuracy: 0.8367 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 1015/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0992 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0992 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9834 - val_loss: 0.5146 - val_categorical_accuracy: 0.8571 - val_precision: 0.8842 - val_recall: 0.8571\n",
            "Epoch 1016/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1140 - categorical_accuracy: 0.9796 - precision: 0.9795 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1140 - categorical_accuracy: 0.9796 - precision: 0.9795 - recall: 0.9770 - val_loss: 0.5038 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1017/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0932 - categorical_accuracy: 0.9847 - precision: 0.9910 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0932 - categorical_accuracy: 0.9847 - precision: 0.9910 - recall: 0.9821 - val_loss: 0.5183 - val_categorical_accuracy: 0.8673 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1018/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0785 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 100ms/step - loss: 0.0785 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.4094 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1019/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0774 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0774 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898 - val_loss: 0.4224 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1020/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0956 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0956 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9860 - val_loss: 0.4215 - val_categorical_accuracy: 0.9286 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 1021/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0961 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0961 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9834 - val_loss: 0.6714 - val_categorical_accuracy: 0.8265 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 1022/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1335 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1335 - categorical_accuracy: 0.9681 - precision: 0.9704 - recall: 0.9630 - val_loss: 0.5174 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1023/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1574 - categorical_accuracy: 0.9630 - precision: 0.9664 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1574 - categorical_accuracy: 0.9630 - precision: 0.9664 - recall: 0.9541 - val_loss: 1.4472 - val_categorical_accuracy: 0.7041 - val_precision: 0.7188 - val_recall: 0.7041\n",
            "Epoch 1024/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1685 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9554"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1685 - categorical_accuracy: 0.9605 - precision: 0.9665 - recall: 0.9554 - val_loss: 0.4385 - val_categorical_accuracy: 0.9184 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1025/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1051 - categorical_accuracy: 0.9796 - precision: 0.9846 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1051 - categorical_accuracy: 0.9796 - precision: 0.9846 - recall: 0.9783 - val_loss: 0.4608 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1026/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1293 - categorical_accuracy: 0.9745 - precision: 0.9744 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1293 - categorical_accuracy: 0.9745 - precision: 0.9744 - recall: 0.9719 - val_loss: 0.5010 - val_categorical_accuracy: 0.8878 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 1027/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1953 - categorical_accuracy: 0.9528 - precision: 0.9562 - recall: 0.9477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1953 - categorical_accuracy: 0.9528 - precision: 0.9562 - recall: 0.9477 - val_loss: 0.5163 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1028/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1304 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 106ms/step - loss: 0.1304 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9630 - val_loss: 0.4645 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1029/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1190 - categorical_accuracy: 0.9796 - precision: 0.9821 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1190 - categorical_accuracy: 0.9796 - precision: 0.9821 - recall: 0.9796 - val_loss: 0.5029 - val_categorical_accuracy: 0.9184 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1030/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0940 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0940 - categorical_accuracy: 0.9834 - precision: 0.9859 - recall: 0.9821 - val_loss: 0.4607 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1031/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0742 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923 - val_loss: 0.4973 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1032/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.9847 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1034 - categorical_accuracy: 0.9847 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.5475 - val_categorical_accuracy: 0.8878 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1033/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1019 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1019 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9809 - val_loss: 0.5986 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1034/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0988 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0988 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9770 - val_loss: 0.4523 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1035/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1179 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1179 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.6184 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 1036/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1552 - categorical_accuracy: 0.9515 - precision: 0.9527 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1552 - categorical_accuracy: 0.9515 - precision: 0.9527 - recall: 0.9503 - val_loss: 0.6339 - val_categorical_accuracy: 0.8367 - val_precision: 0.8602 - val_recall: 0.8163\n",
            "Epoch 1037/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1085 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1085 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9783 - val_loss: 0.5009 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 1038/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0843 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0843 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.4781 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1039/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0773 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0773 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.4475 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1040/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0974 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0974 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9821 - val_loss: 0.4818 - val_categorical_accuracy: 0.9082 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1041/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0867 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0867 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.6184 - val_categorical_accuracy: 0.8367 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 1042/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1082 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1082 - categorical_accuracy: 0.9809 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.5492 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 1043/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1321 - categorical_accuracy: 0.9694 - precision: 0.9730 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1321 - categorical_accuracy: 0.9694 - precision: 0.9730 - recall: 0.9643 - val_loss: 0.4769 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 1044/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1413 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1413 - categorical_accuracy: 0.9643 - precision: 0.9704 - recall: 0.9617 - val_loss: 0.6557 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 1045/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1188 - categorical_accuracy: 0.9796 - precision: 0.9832 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.1188 - categorical_accuracy: 0.9796 - precision: 0.9832 - recall: 0.9719 - val_loss: 0.5138 - val_categorical_accuracy: 0.8878 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 1046/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1036 - categorical_accuracy: 0.9847 - precision: 0.9859 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1036 - categorical_accuracy: 0.9847 - precision: 0.9859 - recall: 0.9834 - val_loss: 0.4586 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1047/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0947 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0947 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9821 - val_loss: 0.4501 - val_categorical_accuracy: 0.9082 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1048/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0971 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0971 - categorical_accuracy: 0.9847 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.4112 - val_categorical_accuracy: 0.8980 - val_precision: 0.9263 - val_recall: 0.8980\n",
            "Epoch 1049/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0821 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 106ms/step - loss: 0.0821 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.5045 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 1050/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0953 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0953 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9847 - val_loss: 0.4403 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1051/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0766 - categorical_accuracy: 0.9898 - precision: 0.9911 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0766 - categorical_accuracy: 0.9898 - precision: 0.9911 - recall: 0.9898 - val_loss: 0.4483 - val_categorical_accuracy: 0.8980 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 1052/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0804 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0804 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.5595 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1053/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0856 - categorical_accuracy: 0.9872 - precision: 0.9910 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.0856 - categorical_accuracy: 0.9872 - precision: 0.9910 - recall: 0.9860 - val_loss: 0.5589 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 1054/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0824 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0824 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9898 - val_loss: 0.4286 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1055/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0827 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0827 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9885 - val_loss: 0.4536 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1056/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0962 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.0962 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.6562 - val_categorical_accuracy: 0.8571 - val_precision: 0.8632 - val_recall: 0.8367\n",
            "Epoch 1057/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1175 - categorical_accuracy: 0.9732 - precision: 0.9781 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1175 - categorical_accuracy: 0.9732 - precision: 0.9781 - recall: 0.9707 - val_loss: 0.5913 - val_categorical_accuracy: 0.8265 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 1058/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1191 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9707"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1191 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9707 - val_loss: 0.8906 - val_categorical_accuracy: 0.8265 - val_precision: 0.8229 - val_recall: 0.8061\n",
            "Epoch 1059/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1504 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1504 - categorical_accuracy: 0.9605 - precision: 0.9664 - recall: 0.9541 - val_loss: 0.7966 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 1060/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1378 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1378 - categorical_accuracy: 0.9681 - precision: 0.9730 - recall: 0.9643 - val_loss: 0.5825 - val_categorical_accuracy: 0.8469 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 1061/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1220 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1220 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9719 - val_loss: 0.5587 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 1062/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1130 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1130 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9745 - val_loss: 0.5414 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 1063/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0961 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0961 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - val_loss: 0.5789 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 1064/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1284 - categorical_accuracy: 0.9719 - precision: 0.9744 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1284 - categorical_accuracy: 0.9719 - precision: 0.9744 - recall: 0.9694 - val_loss: 0.5345 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1065/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0927 - categorical_accuracy: 0.9898 - precision: 0.9911 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.0927 - categorical_accuracy: 0.9898 - precision: 0.9911 - recall: 0.9898 - val_loss: 0.4058 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1066/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0806 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0806 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9872 - val_loss: 0.4577 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 1067/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0779 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0779 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9923 - val_loss: 0.4540 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1068/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0909 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 108ms/step - loss: 0.0909 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.4208 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1069/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1075 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1075 - categorical_accuracy: 0.9783 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.4400 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1070/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0968 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0968 - categorical_accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - val_loss: 0.5179 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1071/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0867 - categorical_accuracy: 0.9821 - precision: 0.9871 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0867 - categorical_accuracy: 0.9821 - precision: 0.9871 - recall: 0.9796 - val_loss: 0.5266 - val_categorical_accuracy: 0.8980 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 1072/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0925 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.0925 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9834 - val_loss: 0.5710 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 1073/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1112 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1112 - categorical_accuracy: 0.9783 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.5435 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1074/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1633 - categorical_accuracy: 0.9541 - precision: 0.9638 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1633 - categorical_accuracy: 0.9541 - precision: 0.9638 - recall: 0.9503 - val_loss: 0.5202 - val_categorical_accuracy: 0.8878 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1075/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1620 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1620 - categorical_accuracy: 0.9630 - precision: 0.9690 - recall: 0.9566 - val_loss: 0.5699 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 1076/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2287 - categorical_accuracy: 0.9311 - precision: 0.9356 - recall: 0.9260"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.2287 - categorical_accuracy: 0.9311 - precision: 0.9356 - recall: 0.9260 - val_loss: 0.5742 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1077/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1903 - categorical_accuracy: 0.9566 - precision: 0.9614 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1903 - categorical_accuracy: 0.9566 - precision: 0.9614 - recall: 0.9541 - val_loss: 0.6002 - val_categorical_accuracy: 0.8776 - val_precision: 0.8936 - val_recall: 0.8571\n",
            "Epoch 1078/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1932 - categorical_accuracy: 0.9490 - precision: 0.9523 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1932 - categorical_accuracy: 0.9490 - precision: 0.9523 - recall: 0.9426 - val_loss: 0.4841 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 1079/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1181 - categorical_accuracy: 0.9770 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1181 - categorical_accuracy: 0.9770 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.3830 - val_categorical_accuracy: 0.9184 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 1080/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0792 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.0792 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9885 - val_loss: 0.4950 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 1081/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9949 - precision: 0.9962 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0805 - categorical_accuracy: 0.9949 - precision: 0.9962 - recall: 0.9923 - val_loss: 0.4176 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1082/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0775 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0775 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911 - val_loss: 0.4063 - val_categorical_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286\n",
            "Epoch 1083/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0824 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0824 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.4134 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1084/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0719 - categorical_accuracy: 0.9962 - precision: 0.9962 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0719 - categorical_accuracy: 0.9962 - precision: 0.9962 - recall: 0.9923 - val_loss: 0.3978 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1085/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1015 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1015 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9809 - val_loss: 0.5210 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1086/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1007 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1007 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.3919 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1087/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1176 - categorical_accuracy: 0.9745 - precision: 0.9756 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1176 - categorical_accuracy: 0.9745 - precision: 0.9756 - recall: 0.9694 - val_loss: 0.3888 - val_categorical_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 1088/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0739 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 130ms/step - loss: 0.0739 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911 - val_loss: 0.3707 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1089/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0747 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 168ms/step - loss: 0.0747 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9936 - val_loss: 0.3802 - val_categorical_accuracy: 0.9286 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 1090/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0761 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 168ms/step - loss: 0.0761 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.5130 - val_categorical_accuracy: 0.8980 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 1091/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0925 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 125ms/step - loss: 0.0925 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847 - val_loss: 0.4760 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1092/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0916 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0916 - categorical_accuracy: 0.9860 - precision: 0.9859 - recall: 0.9834 - val_loss: 0.4671 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1093/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0889 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0889 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.5017 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 1094/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0856 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0856 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.4272 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1095/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0882 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0882 - categorical_accuracy: 0.9783 - precision: 0.9807 - recall: 0.9745 - val_loss: 0.5460 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1096/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0805 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9898 - val_loss: 0.4996 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1097/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0762 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0762 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.4303 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 1098/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0784 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0784 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.4240 - val_categorical_accuracy: 0.9082 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1099/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0913 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0913 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9847 - val_loss: 0.6140 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 1100/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0814 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0814 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9872 - val_loss: 0.6248 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1101/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0755 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 106ms/step - loss: 0.0755 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9911 - val_loss: 0.5663 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1102/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0799 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0799 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.5044 - val_categorical_accuracy: 0.8878 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 1103/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0662 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0662 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.4316 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1104/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0778 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0778 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9911 - val_loss: 0.5006 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 1105/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1097 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1097 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9783 - val_loss: 0.5390 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 1106/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0951 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0951 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9821 - val_loss: 0.5716 - val_categorical_accuracy: 0.8776 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 1107/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0931 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.0931 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.5650 - val_categorical_accuracy: 0.8571 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 1108/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1103 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1103 - categorical_accuracy: 0.9796 - precision: 0.9808 - recall: 0.9770 - val_loss: 0.7290 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1109/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1392 - categorical_accuracy: 0.9630 - precision: 0.9679 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1392 - categorical_accuracy: 0.9630 - precision: 0.9679 - recall: 0.9617 - val_loss: 0.6015 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1110/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1559 - categorical_accuracy: 0.9605 - precision: 0.9640 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1559 - categorical_accuracy: 0.9605 - precision: 0.9640 - recall: 0.9566 - val_loss: 0.5318 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1111/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1174 - categorical_accuracy: 0.9758 - precision: 0.9782 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1174 - categorical_accuracy: 0.9758 - precision: 0.9782 - recall: 0.9732 - val_loss: 0.4262 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1112/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0837 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0837 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9885 - val_loss: 0.4680 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1113/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0940 - categorical_accuracy: 0.9821 - precision: 0.9821 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0940 - categorical_accuracy: 0.9821 - precision: 0.9821 - recall: 0.9809 - val_loss: 0.4695 - val_categorical_accuracy: 0.9082 - val_precision: 0.9062 - val_recall: 0.8878\n",
            "Epoch 1114/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1172 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1172 - categorical_accuracy: 0.9758 - precision: 0.9794 - recall: 0.9694 - val_loss: 0.5249 - val_categorical_accuracy: 0.8265 - val_precision: 0.8333 - val_recall: 0.8163\n",
            "Epoch 1115/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0906 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0906 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.4206 - val_categorical_accuracy: 0.8980 - val_precision: 0.8980 - val_recall: 0.8980\n",
            "Epoch 1116/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0889 - categorical_accuracy: 0.9872 - precision: 0.9898 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0889 - categorical_accuracy: 0.9872 - precision: 0.9898 - recall: 0.9872 - val_loss: 0.3958 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1117/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0710 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0710 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.4452 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1118/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0932 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.0932 - categorical_accuracy: 0.9821 - precision: 0.9846 - recall: 0.9796 - val_loss: 0.4177 - val_categorical_accuracy: 0.9082 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1119/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0931 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0931 - categorical_accuracy: 0.9860 - precision: 0.9872 - recall: 0.9847 - val_loss: 0.5401 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1120/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1006 - categorical_accuracy: 0.9821 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1006 - categorical_accuracy: 0.9821 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.6943 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1121/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0899 - categorical_accuracy: 0.9898 - precision: 0.9910 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0899 - categorical_accuracy: 0.9898 - precision: 0.9910 - recall: 0.9872 - val_loss: 0.5028 - val_categorical_accuracy: 0.8878 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1122/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0760 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0760 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9936 - val_loss: 0.4203 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1123/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0759 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0759 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9898 - val_loss: 0.3999 - val_categorical_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286\n",
            "Epoch 1124/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0802 - categorical_accuracy: 0.9898 - precision: 0.9923 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0802 - categorical_accuracy: 0.9898 - precision: 0.9923 - recall: 0.9898 - val_loss: 0.4633 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1125/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1117 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1117 - categorical_accuracy: 0.9758 - precision: 0.9770 - recall: 0.9745 - val_loss: 0.5556 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1126/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1122 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1122 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9745 - val_loss: 0.3788 - val_categorical_accuracy: 0.9286 - val_precision: 0.9381 - val_recall: 0.9286\n",
            "Epoch 1127/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1108 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9758"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1108 - categorical_accuracy: 0.9770 - precision: 0.9795 - recall: 0.9758 - val_loss: 0.5773 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 1128/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1689 - categorical_accuracy: 0.9554 - precision: 0.9590 - recall: 0.9541"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.1689 - categorical_accuracy: 0.9554 - precision: 0.9590 - recall: 0.9541 - val_loss: 0.8030 - val_categorical_accuracy: 0.7857 - val_precision: 0.8000 - val_recall: 0.7755\n",
            "Epoch 1129/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1475 - categorical_accuracy: 0.9554 - precision: 0.9588 - recall: 0.9503"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1475 - categorical_accuracy: 0.9554 - precision: 0.9588 - recall: 0.9503 - val_loss: 0.6616 - val_categorical_accuracy: 0.8571 - val_precision: 0.8660 - val_recall: 0.8571\n",
            "Epoch 1130/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1282 - categorical_accuracy: 0.9694 - precision: 0.9706 - recall: 0.9681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 105ms/step - loss: 0.1282 - categorical_accuracy: 0.9694 - precision: 0.9706 - recall: 0.9681 - val_loss: 0.7432 - val_categorical_accuracy: 0.8469 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 1131/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1281 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9630"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1281 - categorical_accuracy: 0.9668 - precision: 0.9692 - recall: 0.9630 - val_loss: 0.5849 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 1132/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0912 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0912 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9834 - val_loss: 0.5244 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1133/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1034 - categorical_accuracy: 0.9796 - precision: 0.9807 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1034 - categorical_accuracy: 0.9796 - precision: 0.9807 - recall: 0.9745 - val_loss: 0.6965 - val_categorical_accuracy: 0.8061 - val_precision: 0.8105 - val_recall: 0.7857\n",
            "Epoch 1134/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1005 - categorical_accuracy: 0.9809 - precision: 0.9808 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.1005 - categorical_accuracy: 0.9809 - precision: 0.9808 - recall: 0.9783 - val_loss: 0.6488 - val_categorical_accuracy: 0.8469 - val_precision: 0.8526 - val_recall: 0.8265\n",
            "Epoch 1135/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1398 - categorical_accuracy: 0.9643 - precision: 0.9679 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1398 - categorical_accuracy: 0.9643 - precision: 0.9679 - recall: 0.9617 - val_loss: 0.4381 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1136/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1083 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1083 - categorical_accuracy: 0.9821 - precision: 0.9834 - recall: 0.9796 - val_loss: 0.4589 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1137/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1009 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1009 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9821 - val_loss: 0.6807 - val_categorical_accuracy: 0.8469 - val_precision: 0.8469 - val_recall: 0.8469\n",
            "Epoch 1138/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0978 - categorical_accuracy: 0.9809 - precision: 0.9808 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0978 - categorical_accuracy: 0.9809 - precision: 0.9808 - recall: 0.9796 - val_loss: 0.4927 - val_categorical_accuracy: 0.8878 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 1139/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0920 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.0920 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847 - val_loss: 0.5275 - val_categorical_accuracy: 0.8878 - val_precision: 0.9043 - val_recall: 0.8673\n",
            "Epoch 1140/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0848 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0848 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9847 - val_loss: 0.5525 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1141/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0880 - categorical_accuracy: 0.9860 - precision: 0.9898 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0880 - categorical_accuracy: 0.9860 - precision: 0.9898 - recall: 0.9860 - val_loss: 0.4809 - val_categorical_accuracy: 0.8878 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1142/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0943 - categorical_accuracy: 0.9809 - precision: 0.9859 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 107ms/step - loss: 0.0943 - categorical_accuracy: 0.9809 - precision: 0.9859 - recall: 0.9783 - val_loss: 0.5894 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1143/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0868 - categorical_accuracy: 0.9834 - precision: 0.9872 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0868 - categorical_accuracy: 0.9834 - precision: 0.9872 - recall: 0.9821 - val_loss: 0.4668 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1144/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0751 - categorical_accuracy: 0.9885 - precision: 0.9898 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0751 - categorical_accuracy: 0.9885 - precision: 0.9898 - recall: 0.9872 - val_loss: 0.4846 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1145/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0865 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0865 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.5646 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1146/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0751 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0751 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9936 - val_loss: 0.4925 - val_categorical_accuracy: 0.8878 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1147/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0668 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0668 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.3822 - val_categorical_accuracy: 0.9184 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1148/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0660 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9936"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 106ms/step - loss: 0.0660 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9936 - val_loss: 0.4843 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1149/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0635 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0635 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9923 - val_loss: 0.5209 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1150/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0705 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0705 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.6062 - val_categorical_accuracy: 0.8367 - val_precision: 0.8438 - val_recall: 0.8265\n",
            "Epoch 1151/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0648 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0648 - categorical_accuracy: 0.9936 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.4264 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1152/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0629 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0629 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9911 - val_loss: 0.4453 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1153/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0696 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0696 - categorical_accuracy: 0.9923 - precision: 0.9936 - recall: 0.9885 - val_loss: 0.5340 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1154/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0740 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0740 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9898 - val_loss: 0.4397 - val_categorical_accuracy: 0.8980 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1155/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0900 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0900 - categorical_accuracy: 0.9860 - precision: 0.9860 - recall: 0.9860 - val_loss: 0.9940 - val_categorical_accuracy: 0.8163 - val_precision: 0.8163 - val_recall: 0.8163\n",
            "Epoch 1156/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1609 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9617"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1609 - categorical_accuracy: 0.9656 - precision: 0.9679 - recall: 0.9617 - val_loss: 0.6503 - val_categorical_accuracy: 0.8469 - val_precision: 0.8617 - val_recall: 0.8265\n",
            "Epoch 1157/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.2000 - categorical_accuracy: 0.9426 - precision: 0.9448 - recall: 0.9388"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.2000 - categorical_accuracy: 0.9426 - precision: 0.9448 - recall: 0.9388 - val_loss: 1.0702 - val_categorical_accuracy: 0.7551 - val_precision: 0.7660 - val_recall: 0.7347\n",
            "Epoch 1158/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1817 - categorical_accuracy: 0.9592 - precision: 0.9603 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1817 - categorical_accuracy: 0.9592 - precision: 0.9603 - recall: 0.9566 - val_loss: 0.6060 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 1159/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1645 - categorical_accuracy: 0.9566 - precision: 0.9591 - recall: 0.9566"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1645 - categorical_accuracy: 0.9566 - precision: 0.9591 - recall: 0.9566 - val_loss: 0.6522 - val_categorical_accuracy: 0.8469 - val_precision: 0.8646 - val_recall: 0.8469\n",
            "Epoch 1160/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1909 - categorical_accuracy: 0.9464 - precision: 0.9535 - recall: 0.9426"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1909 - categorical_accuracy: 0.9464 - precision: 0.9535 - recall: 0.9426 - val_loss: 0.5694 - val_categorical_accuracy: 0.8367 - val_precision: 0.8367 - val_recall: 0.8367\n",
            "Epoch 1161/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1168 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9745"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1168 - categorical_accuracy: 0.9758 - precision: 0.9795 - recall: 0.9745 - val_loss: 0.4519 - val_categorical_accuracy: 0.8673 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 1162/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1209 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1209 - categorical_accuracy: 0.9745 - precision: 0.9782 - recall: 0.9719 - val_loss: 0.5723 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 1163/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0969 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0969 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9796 - val_loss: 0.5859 - val_categorical_accuracy: 0.8571 - val_precision: 0.8571 - val_recall: 0.8571\n",
            "Epoch 1164/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0900 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0900 - categorical_accuracy: 0.9834 - precision: 0.9834 - recall: 0.9834 - val_loss: 0.4323 - val_categorical_accuracy: 0.9286 - val_precision: 0.9381 - val_recall: 0.9286\n",
            "Epoch 1165/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1113 - categorical_accuracy: 0.9719 - precision: 0.9794 - recall: 0.9694"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1113 - categorical_accuracy: 0.9719 - precision: 0.9794 - recall: 0.9694 - val_loss: 0.5990 - val_categorical_accuracy: 0.8265 - val_precision: 0.8265 - val_recall: 0.8265\n",
            "Epoch 1166/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0894 - categorical_accuracy: 0.9847 - precision: 0.9846 - recall: 0.9809"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0894 - categorical_accuracy: 0.9847 - precision: 0.9846 - recall: 0.9809 - val_loss: 0.4366 - val_categorical_accuracy: 0.8673 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 1167/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0686 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0686 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.6486 - val_categorical_accuracy: 0.8265 - val_precision: 0.8351 - val_recall: 0.8265\n",
            "Epoch 1168/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0701 - categorical_accuracy: 0.9923 - precision: 0.9949 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0701 - categorical_accuracy: 0.9923 - precision: 0.9949 - recall: 0.9923 - val_loss: 0.4456 - val_categorical_accuracy: 0.8980 - val_precision: 0.9072 - val_recall: 0.8980\n",
            "Epoch 1169/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0740 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0740 - categorical_accuracy: 0.9936 - precision: 0.9949 - recall: 0.9923 - val_loss: 0.5089 - val_categorical_accuracy: 0.9082 - val_precision: 0.9167 - val_recall: 0.8980\n",
            "Epoch 1170/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0650 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0650 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949 - val_loss: 0.4144 - val_categorical_accuracy: 0.9286 - val_precision: 0.9381 - val_recall: 0.9286\n",
            "Epoch 1171/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0712 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0712 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9923 - val_loss: 0.3878 - val_categorical_accuracy: 0.9388 - val_precision: 0.9485 - val_recall: 0.9388\n",
            "Epoch 1172/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0684 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0684 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.4318 - val_categorical_accuracy: 0.9286 - val_precision: 0.9286 - val_recall: 0.9286\n",
            "Epoch 1173/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0744 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0744 - categorical_accuracy: 0.9923 - precision: 0.9923 - recall: 0.9898 - val_loss: 0.3226 - val_categorical_accuracy: 0.9184 - val_precision: 0.9278 - val_recall: 0.9184\n",
            "Epoch 1174/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0742 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 156ms/step - loss: 0.0742 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9885 - val_loss: 0.4397 - val_categorical_accuracy: 0.8673 - val_precision: 0.8947 - val_recall: 0.8673\n",
            "Epoch 1175/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0732 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 158ms/step - loss: 0.0732 - categorical_accuracy: 0.9911 - precision: 0.9911 - recall: 0.9911 - val_loss: 0.4234 - val_categorical_accuracy: 0.9184 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 1176/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0604 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 4s 160ms/step - loss: 0.0604 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9962 - val_loss: 0.5672 - val_categorical_accuracy: 0.8776 - val_precision: 0.8958 - val_recall: 0.8776\n",
            "Epoch 1177/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0625 - categorical_accuracy: 0.9974 - precision: 0.9987 - recall: 0.9962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 110ms/step - loss: 0.0625 - categorical_accuracy: 0.9974 - precision: 0.9987 - recall: 0.9962 - val_loss: 0.4927 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1178/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0598 - categorical_accuracy: 0.9962 - precision: 0.9962 - recall: 0.9949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 99ms/step - loss: 0.0598 - categorical_accuracy: 0.9962 - precision: 0.9962 - recall: 0.9949 - val_loss: 0.3915 - val_categorical_accuracy: 0.9184 - val_precision: 0.9271 - val_recall: 0.9082\n",
            "Epoch 1179/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0644 - categorical_accuracy: 0.9949 - precision: 0.9962 - recall: 0.9923"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0644 - categorical_accuracy: 0.9949 - precision: 0.9962 - recall: 0.9923 - val_loss: 0.5770 - val_categorical_accuracy: 0.8673 - val_precision: 0.8673 - val_recall: 0.8673\n",
            "Epoch 1180/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0712 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0712 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949 - val_loss: 0.4921 - val_categorical_accuracy: 0.8878 - val_precision: 0.8969 - val_recall: 0.8878\n",
            "Epoch 1181/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0807 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0807 - categorical_accuracy: 0.9834 - precision: 0.9847 - recall: 0.9821 - val_loss: 0.4343 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1182/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0801 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0801 - categorical_accuracy: 0.9885 - precision: 0.9910 - recall: 0.9860 - val_loss: 0.4784 - val_categorical_accuracy: 0.8878 - val_precision: 0.8878 - val_recall: 0.8878\n",
            "Epoch 1183/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0712 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0712 - categorical_accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898 - val_loss: 0.3822 - val_categorical_accuracy: 0.9184 - val_precision: 0.9184 - val_recall: 0.9184\n",
            "Epoch 1184/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0693 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0693 - categorical_accuracy: 0.9949 - precision: 0.9949 - recall: 0.9949 - val_loss: 0.3716 - val_categorical_accuracy: 0.9490 - val_precision: 0.9490 - val_recall: 0.9490\n",
            "Epoch 1185/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0806 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0806 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.5728 - val_categorical_accuracy: 0.8571 - val_precision: 0.8750 - val_recall: 0.8571\n",
            "Epoch 1186/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1091 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9732"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.1091 - categorical_accuracy: 0.9745 - precision: 0.9757 - recall: 0.9732 - val_loss: 0.5784 - val_categorical_accuracy: 0.8367 - val_precision: 0.8454 - val_recall: 0.8367\n",
            "Epoch 1187/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1631 - categorical_accuracy: 0.9541 - precision: 0.9575 - recall: 0.9490"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.1631 - categorical_accuracy: 0.9541 - precision: 0.9575 - recall: 0.9490 - val_loss: 0.4881 - val_categorical_accuracy: 0.9082 - val_precision: 0.9158 - val_recall: 0.8878\n",
            "Epoch 1188/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1814 - categorical_accuracy: 0.9426 - precision: 0.9484 - recall: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.1814 - categorical_accuracy: 0.9426 - precision: 0.9484 - recall: 0.9375 - val_loss: 0.6071 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 1189/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0983 - categorical_accuracy: 0.9796 - precision: 0.9859 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 100ms/step - loss: 0.0983 - categorical_accuracy: 0.9796 - precision: 0.9859 - recall: 0.9783 - val_loss: 0.6648 - val_categorical_accuracy: 0.8776 - val_precision: 0.8854 - val_recall: 0.8673\n",
            "Epoch 1190/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0876 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0876 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9783 - val_loss: 0.4081 - val_categorical_accuracy: 0.9184 - val_precision: 0.9175 - val_recall: 0.9082\n",
            "Epoch 1191/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0819 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0819 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9872 - val_loss: 0.4895 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1192/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0709 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 103ms/step - loss: 0.0709 - categorical_accuracy: 0.9911 - precision: 0.9923 - recall: 0.9911 - val_loss: 0.4830 - val_categorical_accuracy: 0.8673 - val_precision: 0.8737 - val_recall: 0.8469\n",
            "Epoch 1193/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9821"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0805 - categorical_accuracy: 0.9860 - precision: 0.9897 - recall: 0.9821 - val_loss: 0.3653 - val_categorical_accuracy: 0.9082 - val_precision: 0.9082 - val_recall: 0.9082\n",
            "Epoch 1194/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0784 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9834"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.0784 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9834 - val_loss: 0.4824 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1195/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0617 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 99ms/step - loss: 0.0617 - categorical_accuracy: 0.9974 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.5978 - val_categorical_accuracy: 0.8469 - val_precision: 0.8542 - val_recall: 0.8367\n",
            "Epoch 1196/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0730 - categorical_accuracy: 0.9898 - precision: 0.9910 - recall: 0.9885"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 101ms/step - loss: 0.0730 - categorical_accuracy: 0.9898 - precision: 0.9910 - recall: 0.9885 - val_loss: 0.5851 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n",
            "Epoch 1197/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0798 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 98ms/step - loss: 0.0798 - categorical_accuracy: 0.9885 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.5476 - val_categorical_accuracy: 0.8673 - val_precision: 0.8763 - val_recall: 0.8673\n",
            "Epoch 1198/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.1151 - categorical_accuracy: 0.9758 - precision: 0.9769 - recall: 0.9719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 102ms/step - loss: 0.1151 - categorical_accuracy: 0.9758 - precision: 0.9769 - recall: 0.9719 - val_loss: 0.5378 - val_categorical_accuracy: 0.8776 - val_precision: 0.8776 - val_recall: 0.8776\n",
            "Epoch 1199/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0976 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9796"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0976 - categorical_accuracy: 0.9809 - precision: 0.9821 - recall: 0.9796 - val_loss: 0.4371 - val_categorical_accuracy: 0.8776 - val_precision: 0.8866 - val_recall: 0.8776\n",
            "Epoch 1200/1200\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.0745 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9860"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 3s 104ms/step - loss: 0.0745 - categorical_accuracy: 0.9872 - precision: 0.9885 - recall: 0.9860 - val_loss: 0.5473 - val_categorical_accuracy: 0.8469 - val_precision: 0.8557 - val_recall: 0.8469\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73f9b05dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape\n",
        "#check output of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94haq1rAb0V",
        "outputId": "a54ffba7-5958-4a5c-d155-990d13dbad2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model weight are loaded into the variable. This line can be perfomed when the model has already been trained and saved,  and the arquitecture has been run\n",
        "model.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "id": "zlJ62hcNapF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save and load Models"
      ],
      "metadata": {
        "id": "5iDZh8PgFaWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save and load for dynamic/continous sign recognition models"
      ],
      "metadata": {
        "id": "7YrkolpJ26J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#### Create path for dynamic/continous sign recognition models\n",
        "\n",
        "LSTM_MODEL_PATH = 'dynamic_experiment_lstm_v4.h5'\n",
        "GRU_MODEL_PATH= 'dynamic_experiment_lstm_v7.h5'\n",
        "\n",
        "#Creates model path\n",
        "\n",
        "MODEL_PATH = os.path.join(DYNAMIC_DATA,'models', LSTM_MODEL_PATH)\n",
        "\n",
        "#The path of the model (LSTM/GRU) can be changed accordingly"
      ],
      "metadata": {
        "id": "GNEqMI2XFSXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90e21d7-38ba-45d4-fccc-7cb223609466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Save only dynamic/continous sign recognition model\n",
        "model.save(filepath=MODEL_PATH)\n"
      ],
      "metadata": {
        "id": "kkIkB8D6dA10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model #by changing \"model\" variable it can delete the current weights of the model stored in the variable"
      ],
      "metadata": {
        "id": "Nj0fLDpOFSZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Load only dynamic/continous sign recognition model\n",
        "\n",
        "model.load_weights( filepath = MODEL_PATH)"
      ],
      "metadata": {
        "id": "NVwadEkdFeRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save and load for static sign recognition models"
      ],
      "metadata": {
        "id": "vzJtdPdT2_z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Create path for static sign recognition models\n",
        "\n",
        "HIST_GRAD_BOOST_MODEL=\"models_histgrad_v2\"\n",
        "SVM_MODEL = \"models_svm_v2\"\n",
        "\n",
        "#Creates model path\n",
        "\n",
        "MODEL_PATH_STATIC = os.path.join(STATIC_DATA, SVM_MODEL) \n",
        "#The path of the model (SVM/GBL) can be changed accordingly"
      ],
      "metadata": {
        "id": "XpxygkEtedov"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save static sign recognition model\n",
        "joblib.dump(final_model, MODEL_PATH_STATIC)\n"
      ],
      "metadata": {
        "id": "FUon9kPpt3Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load static model\n",
        "\n",
        "print(os.path.exists(os.path.join(MODEL_PATH_STATIC)))\n",
        "loaded_model = joblib.load(MODEL_PATH_STATIC)"
      ],
      "metadata": {
        "id": "o7gHDocmt332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb5664b-11ba-4f61-92ee-3d76cb7cb103"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zhfYtf9eHo0",
        "outputId": "2179efc4-2a4d-41a6-dfce-748ed6d1971e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
            "             param_grid={'C': [0.1, 1, 10, 100, 800, 1000, 1200],\n",
            "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
            "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print params of loaded model\n",
        "print(loaded_model)\n",
        "print(\"Hiperparametros\", loaded_model.best_params_)\n",
        "\n",
        "'''\n",
        "GBL\n",
        "params_grid={'loss':['categorical_crossentropy'], \n",
        "             'learning_rate':[ 0.09, 0.1, 0.11, 0.125, 0.15], \n",
        "             'max_iter':[100, 150, 200, 250, 300, 350],\n",
        "             }\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "t0EooYOqM1UY",
        "outputId": "66d495bd-0752-473e-a286-4dff478baa1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
            "             param_grid={'C': [0.1, 1, 10, 100, 800, 1000, 1200],\n",
            "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
            "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']})\n",
            "Hiperparametros {'C': 1200, 'gamma': 0.1, 'kernel': 'poly'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nGradient boosting \\nparams_grid={'loss':['categorical_crossentropy'], \\n             'learning_rate':[ 0.09, 0.1, 0.11, 0.125, 0.15], \\n             'max_iter':[100, 150, 200, 250, 300, 350],\\n             }\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix and evaluation metrics for static signs"
      ],
      "metadata": {
        "id": "_RF3zA5cOJbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix display"
      ],
      "metadata": {
        "id": "9GQqizYInJPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying a model to predict the values\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "#get the confusion matrix from the predicted values vs groundtruth values\n",
        "conf_mx = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "#setting up the confusion matrix for better visualization\n",
        "table = pd.DataFrame(conf_mx, columns = static_alphabets, index =static_alphabets )\n",
        "plt.figure(figsize = (28,21))\n",
        "ax = sns.heatmap(table/np.sum(table), annot = True , fmt='.2%', cmap = 'Blues', linewidth=.5)\n",
        "\n",
        "#plt.matshow(conf_mx, cmap='Blues' )\n",
        "print(\"\\n\")\n",
        "#show cliassical report\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "### check main accuracy value from the model according to its assigned value per stage\n",
        "print(\"Training set score: %f\" % loaded_model.score(X_train , y_train))\n",
        "print(\"Testing  set score: %f\" % loaded_model.score(X_test , y_test ))\n",
        "print(\"Validation  set score: %f\" % loaded_model.score(X_val , y_val ))\n",
        "\n",
        "#STATIC SHOW ATRIBUTES\n",
        "loaded_model.score\n",
        "\n",
        "\n",
        "#loaded_model\n",
        "#clf.score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ca256tM-8cZN",
        "outputId": "76ace9b1-e48a-4547-adc7-684de43ebdef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       1.00      0.86      0.92        14\n",
            "           3       0.80      0.80      0.80         5\n",
            "           4       0.88      1.00      0.93         7\n",
            "           5       1.00      0.92      0.96        12\n",
            "           6       1.00      0.78      0.88         9\n",
            "           7       1.00      0.73      0.84        11\n",
            "           8       0.92      1.00      0.96        11\n",
            "           9       0.88      0.88      0.88         8\n",
            "          10       1.00      0.88      0.93         8\n",
            "          11       1.00      1.00      1.00         6\n",
            "          12       0.94      1.00      0.97        16\n",
            "          13       1.00      1.00      1.00        12\n",
            "          14       0.67      1.00      0.80         4\n",
            "          15       0.78      1.00      0.88         7\n",
            "          16       1.00      1.00      1.00         6\n",
            "          17       1.00      1.00      1.00         8\n",
            "          18       1.00      1.00      1.00        10\n",
            "          19       1.00      1.00      1.00        11\n",
            "          20       0.92      0.86      0.89        14\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       1.00      1.00      1.00         8\n",
            "          23       1.00      1.00      1.00         5\n",
            "          24       0.82      1.00      0.90         9\n",
            "          25       0.92      1.00      0.96        12\n",
            "          26       0.89      0.89      0.89         9\n",
            "          27       0.88      1.00      0.93         7\n",
            "          28       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.94       270\n",
            "   macro avg       0.94      0.94      0.94       270\n",
            "weighted avg       0.95      0.94      0.94       270\n",
            "\n",
            "Training set score: 0.993043\n",
            "Testing  set score: 0.940741\n",
            "Validation  set score: 0.914815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseSearchCV.score of GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 800, 1000, 1200],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf', 'linear', 'poly', 'sigmoid']})>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x1512 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#get predicted values for validation stage\n",
        "y_pred_val = loaded_model.predict(X_val)\n",
        "\n",
        "#geenrate confusion matrix values\n",
        "conf_mx = confusion_matrix(y_val, y_pred_val)\n",
        "\n",
        "#setting up confusion matrix for better visualization\n",
        "table = pd.DataFrame(conf_mx, columns = static_alphabets, index =static_alphabets )\n",
        "plt.figure(figsize = (28,21))\n",
        "ax = sns.heatmap(table/np.sum(table), annot = True , fmt='.2%', cmap = 'Blues', linewidth=.5)\n",
        "\n",
        "#plt.matshow(conf_mx, cmap='Blues' )\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_val,y_pred_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "yS5HmonenmM-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "470670f5-35a3-438c-86b6-1dc581bf8399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       1.00      0.75      0.86         8\n",
            "           3       0.92      0.92      0.92        13\n",
            "           4       0.86      0.86      0.86         7\n",
            "           5       1.00      0.75      0.86         8\n",
            "           6       0.82      1.00      0.90        14\n",
            "           7       0.89      0.89      0.89         9\n",
            "           8       1.00      0.90      0.95        10\n",
            "           9       0.92      1.00      0.96        11\n",
            "          10       0.90      1.00      0.95         9\n",
            "          11       1.00      1.00      1.00        11\n",
            "          12       1.00      0.92      0.96        13\n",
            "          13       1.00      1.00      1.00        11\n",
            "          14       0.80      0.80      0.80         5\n",
            "          15       0.92      0.92      0.92        12\n",
            "          16       1.00      0.93      0.96        14\n",
            "          17       1.00      1.00      1.00        11\n",
            "          18       0.88      0.88      0.88         8\n",
            "          19       0.89      0.89      0.89         9\n",
            "          20       0.88      1.00      0.93         7\n",
            "          21       1.00      0.71      0.83         7\n",
            "          22       1.00      0.83      0.91         6\n",
            "          23       0.79      1.00      0.88        11\n",
            "          24       0.90      0.82      0.86        11\n",
            "          25       0.83      0.83      0.83         6\n",
            "          26       0.85      1.00      0.92        11\n",
            "          27       0.92      1.00      0.96        12\n",
            "          28       1.00      0.89      0.94         9\n",
            "\n",
            "    accuracy                           0.91       270\n",
            "   macro avg       0.91      0.90      0.90       270\n",
            "weighted avg       0.92      0.91      0.91       270\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x1512 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation Metrics"
      ],
      "metadata": {
        "id": "ndahigvxmxMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code gets per stage of the data distribution (Training, testing and validation ) all the evaluation metrics (accuracy, precision, recall , and f-1 score) according to its type (micro, macro and weighted) \n",
        "#TRAIN\n",
        "print(\"\\n\",\"_________TRAINNING_________\")\n",
        "y_pred_train = loaded_model.predict(X_train)\n",
        "print(y_train.shape, y_pred_train.shape)\n",
        "print(\"Accuracy for Test\", accuracy_score(y_train, y_pred_train), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Test\", precision_score(y_train, y_pred_train, average=\"micro\"))\n",
        "print(\"Precision_macro for Test\", precision_score(y_train, y_pred_train, average=\"macro\"))\n",
        "print(\"Precision_weighted for Test\", precision_score(y_train, y_pred_train, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Test\", recall_score(y_train, y_pred_train, average=\"micro\"))\n",
        "print(\"Recall_macro for Test\", recall_score(y_train, y_pred_train, average=\"macro\"))\n",
        "print(\"Recall_weighted for Test\", recall_score(y_train, y_pred_train, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Test\", f1_score(y_train, y_pred_train, average=\"micro\"))\n",
        "print(\"F1_score_macro for Test\", f1_score(y_train, y_pred_train, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Test\", f1_score(y_train, y_pred_train, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "\n",
        "#TEST\n",
        "print(\"\\n\",\"_________TEST_________\")\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "print(y_test.shape, y_pred.shape)\n",
        "print(\"Accuracy for Test\", accuracy_score(y_test, y_pred), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Test\", precision_score(y_test, y_pred, average=\"micro\"))\n",
        "print(\"Precision_macro for Test\", precision_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Precision_weighted for Test\", precision_score(y_test, y_pred, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Test\", recall_score(y_test, y_pred, average=\"micro\"))\n",
        "print(\"Recall_macro for Test\", recall_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"Recall_weighted for Test\", recall_score(y_test, y_pred, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Test\", f1_score(y_test, y_pred, average=\"micro\"))\n",
        "print(\"F1_score_macro for Test\", f1_score(y_test, y_pred, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Test\", f1_score(y_test, y_pred, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "#print(\"Roc_auc_ovr for Test\", roc_auc_score(y_test, y_pred, average=\"None\" , multi_class=\"ovo\"))\n",
        "#VALIDATION\n",
        "print(\"\\n\",\"_________VALIDATION_________\")\n",
        "y_pred_val = loaded_model.predict(X_val)\n",
        "print(y_val.shape, y_pred_val.shape)\n",
        "print(\"Accuracy for Validation\", accuracy_score(y_val, y_pred_val), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Validation\", precision_score(y_val, y_pred_val, average=\"micro\"))\n",
        "print(\"Precision_macro for Validation\", precision_score(y_val, y_pred_val, average=\"macro\"))\n",
        "print(\"Precision_weighted for Validation\", precision_score(y_val, y_pred_val, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Validation\", recall_score(y_val, y_pred_val, average=\"micro\"))\n",
        "print(\"Recall_macro for Validation\", recall_score(y_val, y_pred_val, average=\"macro\"))\n",
        "print(\"Recall_weighted for Validation\", recall_score(y_val, y_pred_val, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Validation\", f1_score(y_val, y_pred_val, average=\"micro\"))\n",
        "print(\"F1_score_macro for Validation\", f1_score(y_val, y_pred_val, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Validation\", f1_score(y_val, y_pred_val, average=\"weighted\"), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEcASdKootIG",
        "outputId": "9df9f648-6d7f-47d0-d334-c15c3e2f7ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " _________TRAINNING_________\n",
            "(2156,) (2156,)\n",
            "Accuracy for Test 0.9930426716141002 \n",
            "\n",
            "Precision_micro for Test 0.9930426716141002\n",
            "Precision_macro for Test 0.9933648487497414\n",
            "Precision_weighted for Test 0.9931204438887682 \n",
            "\n",
            "Recall_micro for Test 0.9930426716141002\n",
            "Recall_macro for Test 0.9930085537494541\n",
            "Recall_weighted for Test 0.9930426716141002 \n",
            "\n",
            "F1_score_micro for Test 0.9930426716141002\n",
            "F1_score_macro for Test 0.9931467674853517\n",
            "F1_score_weighted for Test 0.9930417049664075 \n",
            "\n",
            "\n",
            " _________TEST_________\n",
            "(270,) (270,)\n",
            "Accuracy for Test 0.9407407407407408 \n",
            "\n",
            "Precision_micro for Test 0.9407407407407408\n",
            "Precision_macro for Test 0.9372590391353068\n",
            "Precision_weighted for Test 0.9476552012499725 \n",
            "\n",
            "Recall_micro for Test 0.9407407407407408\n",
            "Recall_macro for Test 0.9424839528287804\n",
            "Recall_weighted for Test 0.9407407407407408 \n",
            "\n",
            "F1_score_micro for Test 0.9407407407407408\n",
            "F1_score_macro for Test 0.9356474943119778\n",
            "F1_score_weighted for Test 0.9405951947121538 \n",
            "\n",
            "\n",
            " _________VALIDATION_________\n",
            "(270,) (270,)\n",
            "Accuracy for Validation 0.9148148148148149 \n",
            "\n",
            "Precision_micro for Validation 0.9148148148148149\n",
            "Precision_macro for Validation 0.9093036330358845\n",
            "Precision_weighted for Validation 0.9216612998475744 \n",
            "\n",
            "Recall_micro for Validation 0.9148148148148149\n",
            "Recall_macro for Validation 0.8996322642874366\n",
            "Recall_weighted for Validation 0.9148148148148149 \n",
            "\n",
            "F1_score_micro for Validation 0.9148148148148149\n",
            "F1_score_macro for Validation 0.8990393399915707\n",
            "F1_score_weighted for Validation 0.9139989113639589 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation Confusion matrix"
      ],
      "metadata": {
        "id": "gVNhmaDIA28a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix display for validation stage\n",
        "conf_mx = confusion_matrix(y_val, y_pred_val)\n",
        "table = pd.DataFrame(conf_mx, columns = static_alphabets, index =static_alphabets )\n",
        "plt.figure(figsize = (28,21))\n",
        "ax = sns.heatmap(table/np.sum(table), annot = True , fmt='.2%', cmap = 'Blues', linewidth=.5)\n",
        "\n",
        "#plt.matshow(conf_mx, cmap='Blues' )\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_val,y_pred_val))"
      ],
      "metadata": {
        "id": "yM7BJc3qA2CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix and evaluation metrics for dynamic/continous signs"
      ],
      "metadata": {
        "id": "uTknxDe-43QL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables reformating for confusion matrix input for continous signs variables"
      ],
      "metadata": {
        "id": "mC6xnm3Mnhdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions for every stage\n",
        "y_pred_train = model.predict(X_train) #train\n",
        "y_pred = model.predict(X_test) #test \n",
        "y_pred_val = model.predict(X_val) #validation\n",
        "\n",
        "#Format adaptation\n",
        "\n",
        "#True\n",
        "y_train_static = np.zeros(y_train.shape[0])\n",
        "y_test_static = np.zeros(y_test.shape[0])\n",
        "y_val_static = np.zeros(y_val.shape[0])\n",
        "#Pred\n",
        "y_pred_train_static = np.zeros(y_pred_train.shape[0])\n",
        "y_pred_static = np.zeros(y_pred.shape[0])\n",
        "y_pred_val_static = np.zeros(y_pred_val.shape[0])\n",
        "\n",
        "\n",
        "#train\n",
        "for i in range(y_train.shape[0]):\n",
        "  #True\n",
        "  y_train_static[i] = np.argmax(y_train[i])\n",
        "\n",
        "for i in range(y_pred_train.shape[0]):\n",
        "  #Pred\n",
        "  y_pred_train_static[i] = np.argmax(y_pred_train[i])\n",
        "\n",
        "\n",
        "#test\n",
        "for i in range(y_pred.shape[0]):\n",
        "  #true\n",
        "  y_test_static[i] = np.argmax(y_test[i])\n",
        "\n",
        "  #pred\n",
        "  y_pred_static[i] =np.argmax(y_pred[i])\n",
        "\n",
        "\n",
        "#val\n",
        "for i in range(y_pred_val.shape[0]):\n",
        "  #true\n",
        "  y_val_static[i] =np.argmax(y_val[i])\n",
        "  #pred\n",
        "  y_pred_val_static[i] = np.argmax(y_pred_val[i])\n",
        "\n",
        "print(\" Train \", y_train_static.shape, \"\\n\",\n",
        "      \"Test \",y_test_static.shape, \"\\n\",\n",
        "      \"Val \",y_val_static.shape, \"\\n\",\n",
        "      \"Pred Train \",y_pred_train_static.shape, \"\\n\",\n",
        "      \"Pred Test \",y_pred_static.shape, \"\\n\",\n",
        "      \"Pred Val \",y_pred_val_static.shape, \"\\n\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "gfqhHaDpQLPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e4a0442-8ad7-4949-d639-dfb338d140c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 30ms/step\n",
            "4/4 [==============================] - 0s 35ms/step\n",
            "4/4 [==============================] - 0s 25ms/step\n",
            " Train  (784,) \n",
            " Test  (98,) \n",
            " Val  (99,) \n",
            " Pred Train  (784,) \n",
            " Pred Test  (98,) \n",
            " Pred Val  (99,) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P25p9_YiYmeI",
        "outputId": "2b26bfff-4e43-47d6-b816-60933a8818be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Confusion matrix display"
      ],
      "metadata": {
        "id": "Ga2ap2Glnsmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix for continous signs\n",
        "\n",
        "conf_mx = confusion_matrix(y_test_static, y_pred_static)\n",
        "table = pd.DataFrame(conf_mx, columns = dinamyc_alphabets, index =dinamyc_alphabets )\n",
        "plt.figure(figsize = (28,21))\n",
        "ax = sns.heatmap(table/np.sum(table), annot = True , fmt='.2%', cmap = 'Blues', linewidth=.5)\n",
        "\n",
        "#plt.matshow(conf_mx, cmap='Blues' )\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test_static,y_pred_static))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lEs6aijnnmnp",
        "outputId": "f449207f-cc98-4f00-b34f-8fe5b7e4ba7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.78      0.74         9\n",
            "         1.0       0.90      0.82      0.86        11\n",
            "         2.0       1.00      1.00      1.00         9\n",
            "         3.0       0.56      0.45      0.50        11\n",
            "         4.0       0.75      0.90      0.82        10\n",
            "         5.0       0.73      0.89      0.80         9\n",
            "         6.0       0.89      1.00      0.94         8\n",
            "         7.0       0.91      0.83      0.87        12\n",
            "         8.0       0.60      0.55      0.57        11\n",
            "         9.0       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.80        98\n",
            "   macro avg       0.80      0.81      0.80        98\n",
            "weighted avg       0.80      0.80      0.79        98\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x1512 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation Metrics"
      ],
      "metadata": {
        "id": "cJw_82eGnyzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the following code gets per stage of the data distribution (Training, testing and validation ) all the evaluation metrics (accuracy, precision, recall , and f-1 score) according to its type (micro, macro and weighted) \n",
        "\n",
        "#TRAIN\n",
        "print(\"\\n\",\"_________TRAINNING_________\")\n",
        "print(y_train_static.shape, y_pred_train_static.shape)\n",
        "print(\"Accuracy for Test\", accuracy_score(y_train_static, y_pred_train_static), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Test\", precision_score(y_train_static, y_pred_train_static, average=\"micro\"))\n",
        "print(\"Precision_macro for Test\", precision_score(y_train_static, y_pred_train_static, average=\"macro\"))\n",
        "print(\"Precision_weighted for Test\", precision_score(y_train_static, y_pred_train_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Test\", recall_score(y_train_static, y_pred_train_static, average=\"micro\"))\n",
        "print(\"Recall_macro for Test\", recall_score(y_train_static, y_pred_train_static, average=\"macro\"))\n",
        "print(\"Recall_weighted for Test\", recall_score(y_train_static, y_pred_train_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Test\", f1_score(y_train_static, y_pred_train_static, average=\"micro\"))\n",
        "print(\"F1_score_macro for Test\", f1_score(y_train_static, y_pred_train_static, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Test\", f1_score(y_train_static, y_pred_train_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "\n",
        "#TEST\n",
        "print(\"\\n\",\"_________TEST_________\")\n",
        "print(y_test_static.shape, y_pred_static.shape)\n",
        "print(\"Accuracy for Test\", accuracy_score(y_test_static, y_pred_static), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Test\", precision_score(y_test_static, y_pred_static, average=\"micro\"))\n",
        "print(\"Precision_macro for Test\", precision_score(y_test_static, y_pred_static, average=\"macro\"))\n",
        "print(\"Precision_weighted for Test\", precision_score(y_test_static, y_pred_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Test\", recall_score(y_test_static, y_pred_static, average=\"micro\"))\n",
        "print(\"Recall_macro for Test\", recall_score(y_test_static, y_pred_static, average=\"macro\"))\n",
        "print(\"Recall_weighted for Test\", recall_score(y_test_static, y_pred_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Test\", f1_score(y_test_static, y_pred_static, average=\"micro\"))\n",
        "print(\"F1_score_macro for Test\", f1_score(y_test_static, y_pred_static, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Test\", f1_score(y_test_static, y_pred_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "#VALIDATION\n",
        "print(\"\\n\",\"_________VALIDATION_________\")\n",
        "print(y_val_static.shape, y_pred_val_static.shape)\n",
        "print(\"Accuracy for Validation\", accuracy_score(y_val_static, y_pred_val_static), \"\\n\")\n",
        "\n",
        "print(\"Precision_micro for Validation\", precision_score(y_val_static, y_pred_val_static, average=\"micro\"))\n",
        "print(\"Precision_macro for Validation\", precision_score(y_val_static, y_pred_val_static, average=\"macro\"))\n",
        "print(\"Precision_weighted for Validation\", precision_score(y_val_static, y_pred_val_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"Recall_micro for Validation\", recall_score(y_val_static, y_pred_val_static, average=\"micro\"))\n",
        "print(\"Recall_macro for Validation\", recall_score(y_val_static, y_pred_val_static, average=\"macro\"))\n",
        "print(\"Recall_weighted for Validation\", recall_score(y_val_static, y_pred_val_static, average=\"weighted\"), \"\\n\")\n",
        "\n",
        "print(\"F1_score_micro for Validation\", f1_score(y_val_static, y_pred_val_static, average=\"micro\"))\n",
        "print(\"F1_score_macro for Validation\", f1_score(y_val_static, y_pred_val_static, average=\"macro\"))\n",
        "print(\"F1_score_weighted for Validation\", f1_score(y_val_static, y_pred_val_static, average=\"weighted\"), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33jyW38_yZvu",
        "outputId": "7c6595a3-326a-4356-c938-9ddc79403b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " _________TRAINNING_________\n",
            "(784,) (784,)\n",
            "Accuracy for Test 0.9591836734693877 \n",
            "\n",
            "Precision_micro for Test 0.9591836734693877\n",
            "Precision_macro for Test 0.9589091438306104\n",
            "Precision_weighted for Test 0.9594154214857795 \n",
            "\n",
            "Recall_micro for Test 0.9591836734693877\n",
            "Recall_macro for Test 0.9600507600385013\n",
            "Recall_weighted for Test 0.9591836734693877 \n",
            "\n",
            "F1_score_micro for Test 0.9591836734693877\n",
            "F1_score_macro for Test 0.9589921727479493\n",
            "F1_score_weighted for Test 0.9588239500891489 \n",
            "\n",
            "\n",
            " _________TEST_________\n",
            "(98,) (98,)\n",
            "Accuracy for Test 0.7959183673469388 \n",
            "\n",
            "Precision_micro for Test 0.7959183673469388\n",
            "Precision_macro for Test 0.8030808080808081\n",
            "Precision_weighted for Test 0.7956813028241599 \n",
            "\n",
            "Recall_micro for Test 0.7959183673469388\n",
            "Recall_macro for Test 0.8093181818181818\n",
            "Recall_weighted for Test 0.7959183673469388 \n",
            "\n",
            "F1_score_micro for Test 0.7959183673469388\n",
            "F1_score_macro for Test 0.8027670373329278\n",
            "F1_score_weighted for Test 0.7924341212606175 \n",
            "\n",
            "\n",
            " _________VALIDATION_________\n",
            "(99,) (99,)\n",
            "Accuracy for Validation 0.7676767676767676 \n",
            "\n",
            "Precision_micro for Validation 0.7676767676767676\n",
            "Precision_macro for Validation 0.7587496816908581\n",
            "Precision_weighted for Validation 0.7588695717037963 \n",
            "\n",
            "Recall_micro for Validation 0.7676767676767676\n",
            "Recall_macro for Validation 0.7746031746031744\n",
            "Recall_weighted for Validation 0.7676767676767676 \n",
            "\n",
            "F1_score_micro for Validation 0.7676767676767676\n",
            "F1_score_macro for Validation 0.7600000806838874\n",
            "F1_score_weighted for Validation 0.7570915226760256 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Validation Confusion matrix"
      ],
      "metadata": {
        "id": "BYrJDewKQclb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix for continou sign for validation\n",
        "\n",
        "conf_mx = confusion_matrix(y_val_static, y_pred_val_static)\n",
        "table = pd.DataFrame(conf_mx, columns = dinamyc_alphabets, index =dinamyc_alphabets )\n",
        "plt.figure(figsize = (28,21))\n",
        "ax = sns.heatmap(table/np.sum(table), annot = True , fmt='.2%', cmap = 'Blues', linewidth=.5)\n",
        "\n",
        "#plt.matshow(conf_mx, cmap='Blues' )\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_val_static,y_pred_val_static))\n"
      ],
      "metadata": {
        "id": "tQPiF3TFP02l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "285b6c22-e541-4da8-f100-98e21a84b0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.91      0.95        11\n",
            "         1.0       0.80      0.80      0.80        10\n",
            "         2.0       0.75      1.00      0.86         9\n",
            "         3.0       0.75      0.55      0.63        11\n",
            "         4.0       0.94      1.00      0.97        16\n",
            "         5.0       0.29      0.20      0.24        10\n",
            "         6.0       0.83      1.00      0.91         5\n",
            "         7.0       0.73      0.89      0.80         9\n",
            "         8.0       0.50      0.55      0.52        11\n",
            "         9.0       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.77        99\n",
            "   macro avg       0.76      0.77      0.76        99\n",
            "weighted avg       0.76      0.77      0.76        99\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2016x1512 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensorboard display"
      ],
      "metadata": {
        "id": "XA8uVB6v6Kg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#declare tensorboard path to call the training data to check\n",
        "tf_direction_path= \"/content/drive/MyDrive/Base de datos/key_points/dynamic_data/Logs/fit/train\"\n",
        "!tensorboard --logdir=tf_direction_path --load_fast true --bind_all\n",
        "\n",
        "#It is recommended to display tensorboard locally in your own terminal for easier display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ_l_jIu6Nn_",
        "outputId": "0bc61e3e-cc8f-4c5b-ffc8-614fd8e3e2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorBoard 2.12.0a20221225 at http://e89a5bebad69:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prediction in real time with webcam in Google Collab"
      ],
      "metadata": {
        "id": "lIjDZfzRjoYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Javascript for webcam display"
      ],
      "metadata": {
        "id": "QW4bW8xGsNqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##Folllowing code was adapted from TheAIGuysCode. (2020). Colab-webcam. GitHub. https://github.com/theAIGuysCode/colab-webcam\n",
        "\n",
        "#Helper functions\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "__jb3JSvj4YC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    const piX = 480; // The width of the capture canvas - 1080\n",
        "    const piY = 360; // The height of the capture canvas - 720\n",
        "    var video; //Video element to display the webcam stream\n",
        "    var div = null;//Container div for video and other elements\n",
        "    var stream; //MediaStream object to capture video stream\n",
        "    var captureCanvas; // Canvas element for capturing frames\n",
        "    var imgElement; // Image element to display captured frames\n",
        "    var labelElement; //Element to display the label/status\n",
        "    \n",
        "    var pendingResolve = null; // Promise resolve function for capturing frames\n",
        "    var shutdown = false; // Flag to indicate if the video stream should be stopped\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop(); // Stop the video stream\n",
        "       video.remove(); // Remove the video element\n",
        "       div.remove();// Remove the container div\n",
        "       video = null; // Reset variables to null\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame); // Continuously request animation frames\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, piX, piY);//Capture frame from video stream\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8) // Convert captured frame to data URL\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result); // Resolve the promise with the captured frame\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream; //Return the existing stream if it already exists\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div'); //Create a container div\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '1080px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div'); //Create a div to display status/label\n",
        "      //modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      labelElement.style.fontSize = '40px'; // Size of output text\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video'); //Create a video element\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"user\"}});//Request user permission for video stream\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');//Create an image element\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
        "      div.appendChild(imgElement); \n",
        "      \n",
        "      const instruction = document.createElement('div');//Create a div for instructions\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
        "\n",
        "      video.srcObject = stream;  // Set the video source to the captured stream\n",
        "      await video.play();      // Start playing the video\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');  // Create a canvas for capturing frames\n",
        "      captureCanvas.width = piX;  // Set the canvas width\n",
        "      captureCanvas.height = piY; //Set the canvas height\n",
        "      window.requestAnimationFrame(onAnimationFrame);  // Start requesting animation frames\n",
        "      \n",
        "      return stream;  // Return the stream\n",
        "    }\n",
        "\n",
        "    \n",
        "    async function stream_frame(label, imgData) {\n",
        "\n",
        "      if (shutdown) {\n",
        "        removeDom(); // If shutdown flag is set, remove the video stream and elements\n",
        "        shutdown = false;  //Reset the shutdown flag\n",
        "        return '';  // Return an empty string\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();  // Capture the timestamp before creating the DOM\n",
        "      stream = await createDom();  // Create the DOM elements and get the stream\n",
        "      \n",
        "      var preShow = Date.now();  // Capture the timestamp before showing the label and image\n",
        "            \n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;  // Set the label text\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];  // Get the size and position of the video element\n",
        "        imgElement.style.top = videoRect.top + \"px\";  // Set the position of the image element\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;  // Set the source of the image element\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();  // Capture the timestamp before capturing the frame\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;  // Set the pendingResolve function to resolve the promise\n",
        "      });\n",
        "      shutdown = false;  // Reset the shutdown flag\n",
        "\n",
        "      return {'create': preShow - preCreate, // Return the timing information\n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, sentence):\n",
        "  data = eval_js('stream_frame(\"{}\",\"{}\")'.format(label,sentence))#  Call the JavaScript function with label and sentence parameters\n",
        "  return data"
      ],
      "metadata": {
        "id": "AkxSV2BhjliC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Livestreaming"
      ],
      "metadata": {
        "id": "sGfU-HbLkNoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dynamic/Continous signs' Livestream"
      ],
      "metadata": {
        "id": "-iqh0CF4ZYfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'The letter predicted is: '\n",
        "count = 0 \n",
        "\n",
        "# 1. New detection variables\n",
        "sequence = []\n",
        "sentence = []\n",
        "predictions = []\n",
        "threshold = 0.5\n",
        "predicted_letter='...'\n",
        "\n",
        "# Set mediapipe model \n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  #print(min_detection_confidence)\n",
        "  while True:\n",
        "      js_reply = video_frame(label_html,predicted_letter )\n",
        "      if not js_reply:\n",
        "          break\n",
        "      # convert JS response to OpenCV Image\n",
        "      img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "      image, results = mediapipe_detection(img, holistic)\n",
        "      \n",
        "        # Draw landmarks\n",
        "      draw_styled_landmarks(image, results)\n",
        "      \n",
        "      # 2. Prediction logic\n",
        "      keypoints = extract_keypoints(results)\n",
        "      sequence.append(keypoints)\n",
        "      sequence = sequence[-30:]\n",
        "      \n",
        "      if len(sequence) == 30:\n",
        "          res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "          print(dinamyc_alphabets[np.argmax(res)])\n",
        "          predictions.append(np.argmax(res))\n",
        "          \n",
        "          \n",
        "      #3. Viz logic: the following code recognize one out of the ten signs and according to the last 5 recognized sign\n",
        "          if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
        "              if res[np.argmax(res)] > threshold: \n",
        "                  \n",
        "                  if len(sentence) > 0: \n",
        "                      if dinamyc_alphabets[np.argmax(res)] != sentence[-1]:\n",
        "                          sentence.append(dinamyc_alphabets[np.argmax(res)])\n",
        "                          predicted_letter=dinamyc_alphabets[np.argmax(res)]\n",
        "                          \n",
        "                  else:\n",
        "                      sentence.append(dinamyc_alphabets[np.argmax(res)])\n",
        "                      predicted_letter=dinamyc_alphabets[np.argmax(res)]\n",
        "\n",
        "          if len(sentence) > 5: \n",
        "              sentence = sentence[-5:]          \n",
        "\n",
        "  ##cap.release()\n",
        "  ##cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "5aMD8qxbF3ek",
        "colab": {
          "resources": {
            "http://localhost:8080/...": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/ll": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/9": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/rr": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e06857a-f1fd-46cf-bb1b-81436b53a6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    const piX = 1080;\n",
              "    const piY = 720;\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, piX, piY);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '1080px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = piX; //video.videoWidth;\n",
              "      captureCanvas.height = piY; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "9\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "z\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "z\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "ll\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "rr\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "x\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "x\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "x\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "x\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "x\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n          # Viz probabilities\\n          image = prob_viz(res, dinamyc_alphabets, image, colors)\\n          \\n      cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\\n      cv2.putText(image, ' '.join(sentence), (3,30), \\n                      cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\\n    \\n      # Show to screen\\n      cv2_imshow(image)\\n\\n      # Break gracefully\\n      if cv2.waitKey(1) & 0xFF == ord('s'):\\n          break\\n\\n\\n          ['9',\\n'10',\\n'j',\\n'k',\\n'll',\\n'ñ',\\n'q',\\n'rr',\\n'x',\\n'z',])\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Static signs' Livestream"
      ],
      "metadata": {
        "id": "Fup43q7jHCBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'The letter predicted is: '\n",
        "count = 0 \n",
        "\n",
        "# 1. New detection variables\n",
        "sequence = []\n",
        "sentence = []\n",
        "predictions = []\n",
        "threshold = 0.5\n",
        "predicted_letter='...'\n",
        "\n",
        "# Set mediapipe model \n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "  #print(min_detection_confidence)\n",
        "  while True:\n",
        "      js_reply = video_frame(label_html,predicted_letter )\n",
        "      if not js_reply:\n",
        "          break\n",
        "      # convert JS response to OpenCV Image\n",
        "      img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "      image, results = mediapipe_detection(img, holistic)\n",
        "      \n",
        "        # Draw landmarks\n",
        "      draw_styled_landmarks(image, results)\n",
        "      \n",
        "      # 2. Prediction logic\n",
        "      keypoints = extract_keypoints(results)\n",
        "      sequence.append(keypoints)\n",
        "      sequence = sequence[-30:]\n",
        "      \n",
        "      if len(sequence) == 30:\n",
        "          res = loaded_model.predict(np.expand_dims(sequence[-1], axis=0))[0]\n",
        "          print(static_alphabets[res])\n",
        "          #print('<font size=\"30\">' + + '</font>')\n",
        "          predictions.append(res)\n",
        "          \n",
        "          \n",
        "      #3. Viz logic: the following code recognize one out of the 28 signs and according to the last 5 recognized sign\n",
        "          if np.unique(predictions[-10:])[0]==res: \n",
        "              #if res[res] > threshold: \n",
        "                  \n",
        "                  if len(sentence) > 0: \n",
        "                      if static_alphabets[res] != sentence[-1]:\n",
        "                          sentence.append(static_alphabets[res])\n",
        "                          predicted_letter=static_alphabets[res]\n",
        "                          \n",
        "                  else:\n",
        "                      sentence.append(static_alphabets[res])\n",
        "                      predicted_letter=static_alphabets[res]\n",
        "\n",
        "                      \n",
        "\n",
        "\n",
        "          if len(sentence) > 5: \n",
        "              sentence = sentence[-5:]          \n",
        "\n",
        "  ##cap.release()\n",
        "  ##cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "uq43yG_HxQ_c",
        "colab": {
          "resources": {
            "http://localhost:8080/...": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/v": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/p": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            },
            "http://localhost:8080/g": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2a96758-49d6-4ad2-afa5-0a1476d39afa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    const piX = 480; // The width of the capture canvas - 1080\n",
              "    const piY = 360; // The height of the capture canvas - 720\n",
              "    var video; //Video element to display the webcam stream\n",
              "    var div = null;//Container div for video and other elements\n",
              "    var stream; //MediaStream object to capture video stream\n",
              "    var captureCanvas; // Canvas element for capturing frames\n",
              "    var imgElement; // Image element to display captured frames\n",
              "    var labelElement; //Element to display the label/status\n",
              "    \n",
              "    var pendingResolve = null; // Promise resolve function for capturing frames\n",
              "    var shutdown = false; // Flag to indicate if the video stream should be stopped\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop(); // Stop the video stream\n",
              "       video.remove(); // Remove the video element\n",
              "       div.remove();// Remove the container div\n",
              "       video = null; // Reset variables to null\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame); // Continuously request animation frames\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, piX, piY);//Capture frame from video stream\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8) // Convert captured frame to data URL\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result); // Resolve the promise with the captured frame\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream; //Return the existing stream if it already exists\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div'); //Create a container div\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '1080px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div'); //Create a div to display status/label\n",
              "      //modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      labelElement.style.fontSize = '40px'; // Size of output text\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video'); //Create a video element\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"user\"}});//Request user permission for video stream\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');//Create an image element\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
              "      div.appendChild(imgElement); \n",
              "      \n",
              "      const instruction = document.createElement('div');//Create a div for instructions\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };//Set onclick event to stop the demo\n",
              "\n",
              "      video.srcObject = stream;  // Set the video source to the captured stream\n",
              "      await video.play();      // Start playing the video\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');  // Create a canvas for capturing frames\n",
              "      captureCanvas.width = piX;  // Set the canvas width\n",
              "      captureCanvas.height = piY; //Set the canvas height\n",
              "      window.requestAnimationFrame(onAnimationFrame);  // Start requesting animation frames\n",
              "      \n",
              "      return stream;  // Return the stream\n",
              "    }\n",
              "\n",
              "    \n",
              "    async function stream_frame(label, imgData) {\n",
              "\n",
              "      if (shutdown) {\n",
              "        removeDom(); // If shutdown flag is set, remove the video stream and elements\n",
              "        shutdown = false;  //Reset the shutdown flag\n",
              "        return '';  // Return an empty string\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();  // Capture the timestamp before creating the DOM\n",
              "      stream = await createDom();  // Create the DOM elements and get the stream\n",
              "      \n",
              "      var preShow = Date.now();  // Capture the timestamp before showing the label and image\n",
              "            \n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;  // Set the label text\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];  // Get the size and position of the video element\n",
              "        imgElement.style.top = videoRect.top + \"px\";  // Set the position of the image element\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;  // Set the source of the image element\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();  // Capture the timestamp before capturing the frame\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;  // Set the pendingResolve function to resolve the promise\n",
              "      });\n",
              "      shutdown = false;  // Reset the shutdown flag\n",
              "\n",
              "      return {'create': preShow - preCreate, // Return the timing information\n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "v\n",
            "p\n",
            "g\n",
            "g\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "e0IgSxpvoZFP",
        "6hCT1uLOnnQz",
        "FZns7yqqjFd6",
        "mKR4XLFoUYyu",
        "_p_BdvkdUfdx",
        "sMSmJ0qlUuEe",
        "whOOsNzoqu14",
        "amSBuHmwq2BE"
      ]
    },
    "interpreter": {
      "hash": "7edee622b834293ee779dd8d6917a1d3a6cc56ca2a446a7f95b5883c4f6a43a7"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}